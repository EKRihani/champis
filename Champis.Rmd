---
#title: "Application de modèles d'Intelligence Artificielle à la classification des macromycètes"
#author: "Emir Kaïs RIHANI"
#date: "`r format(Sys.time(), '%d %B, %Y')`"
lang: fr
geometry: "left=2.5cm,right=2.5cm,top=1.5cm,bottom=2cm"        # Imposé par la fac
fontsize: 12pt          # Imposé par la fac
output: 
  bookdown::pdf_document2: 
    number_sections: yes
    extra_dependencies: float
    toc: yes
    toc_depth: 3
    includes:
      before_body: couverture.tex
      after_body: quatrieme.tex
header-includes:
  - \renewcommand{\familydefault}{\sfdefault}   # Police sans serif sur tout le doc (imposé par la fac)
  - \renewcommand{\thefootnote}{\alph{footnote}}      # Pieds de page en lettres minuscules (autres: Roman, Alph)
  - \usepackage{pdfpages}   # Pour ajout PDF listes des profs / disclaimer
  - \usepackage{placeins}   # pour bloquer ces %#@$§£ de floats
  - \usepackage{amssymb}   # Symboles mathématiques (loi normale...)
  - \usepackage{sfmath}    # Maths sans serif
#  - \usepackage{sansmathaccent}    # Pour tidles/chapeaux mal alignés avec maths sans accent...
  - \usepackage{svg}       # Pour schémas au format SVG
  - \linespread{1.15}
indent: true
bibliography: [packages.bib, Champis.bib]
csl: https://www.zotero.org/styles/vancouver-superscript
---

```{r setup, include = FALSE, warning=FALSE}
load("EKR-Champis-Valeurs.RData")      # Chargement des valeurs diverses utilisées/calculées dans la thèse
load("EKR-Champis-Intro.RData")      # Chargement des résultats INTRO
load("EKR-Champis-EDA.RData")            # Chargement des résultats ANALYSE EXPLORATOIRE
load("EKR-Champis-AnalyseBi.RData")       # Chargement des résultats CLASSIFICATION BINAIRE
load("EKR-Champis-AnalyseMultiFam.RData")       # Chargement des résultats CLASSIFICATION PAR FAMILLES

library(ggpubr)   # Combiner graphes (ggarrange)
library(rmarkdown)
library(knitr)
library(tidyverse)
library(bookdown)
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, fig.pos = "!H")
knitr::write_bib(c("tidyverse", "microbenchmark",  "caret",  "rmarkdown", "GGally", "plyr", "MASS", "mda", "rpart", "C50", "party", "ranger", "Rborist", "e1071", "rFerns", "knitr", "ggpubr", "SPlit", "DiceDesign", "DiceEval", "DiceKriging", "bookdown", "twinning"), "packages.bib")
```
\pagestyle{plain}

\newpage
# Liste des abréviations
\flushleft

AI : *Artificial Intelligence* (intelligence artificielle)

AUC : *Area Under Curve* (aire sous la courbe)

CART : *Classification And Regression Tree* (arbre de classification et de régression)

CSV : *Comma Separated Values* ([fichier de] valeurs séparées par des virgules)

DOE : *Design of Experiments* (plan d'expériences)

EDA : *Exploratory Data Analysis* (analyse exploratoire des données)

ESE : *Enhanced Stochastic Evolutionnary* ([algorithme] évolutionnaire stochastique amélioré)

GAM : *Generalized Additive Model* (modèle additif généralisé)

IA : Intelligence Artificielle  

<!-- Kd-tree : *K-dimensional tree* (arbre k-dimensionel) -->

LDA : *Linear Discriminant Analysis* (analyse linéaire discriminante)

LHS : *Latin Hypercube Sample* (échantillonnage par hypercube latin)

LOESS : *LOcally Estimated Scatterplot Smoothing* (régression locale)

NN : *Nearest Neighbour* (plus proche voisin)

NOLH : *Nearly Orthogonal Latin Hypercube* (hypercube latin quasi orthogonal)

PDA : *Penalized Discriminant Analysis* (analyse discriminante pénalisée)

RF : *Random Forest* (forêt aléatoire)

ROC : *Receiver Operating Characteristic* (fonction d'efficacité du récepteur)

VCS : *Version Control System* (logiciel de contrôle des versions)

XGB : *eXtreme Gradient Boosting*

\endflushleft

\newpage
# Introduction
## Propos liminaire
\paragraph*{}
L'identification des macromycètes est un sujet difficile, ne devant évidemment pas être pris à la légère. Les espèces rencontrées varient considérablement d'un écosystème à un autre, d'un continent à un autre, et aucun lot de données ni ouvrage sur les champignons ne saurait couvrir toute la diversité du monde fongique.
\paragraph*{}
Le lot de données mycologiques constitué dans cette étude, bien que constituant l'un des lots en libre accès les plus complets du domaine de la *data science*, n'est bien entendu pas exhaustif.
\paragraph*{}
Ce lot se concentre exclusivement sur les champignons habituellement rencontrés au Nord de la France. Plusieurs genres, parfois très connus, ne sont pas présents, parmi lesquels nous pouvons par exemple citer le genre  *psylocybe*, connu pour ses propriétés psychédéliques. Certains critères pourront également varier de manière considérable selon le stade de maturité du champignon : alors que les chapeaux vert-olive de l'*Amanita phalloides* mature sont faciles à reconnaître, les spécimens jeunes sont blancs et pourraient facilement être confondus avec des espèces comestibles (par exemple du genre *Agaricus*).
\paragraph*{}
L'ingestion de certains de ces champignons est *mortelle*, même à de petites doses. Le diagnostic de l'intoxication fongique peut être difficile, et parfois trop tardif pour un traitement efficace. Des composés toxiques tels que les amanitines ne sont pas altérés ou détruits par cuisson ou congélation, et seront absorbés par l'intestin, avant de passer dans la circulation sanguine afin d'être filtrés par le foie, détruisant les cellules hépatiques, puis excrétées dans l'intestin, réabsorbées, refiltrées... chaque passe détruisant les cellules hépatiques ayant survécu à la précédente, dans un cycle connu sous le nom de réabsorption hépato-entérique.
\paragraph*{}
Il ne faut jamais, *sous aucune circonstance*, utiliser ce type de lot de données afin de déterminer si un champignon est comestible ou non.

## But de l'étude
\paragraph*{}
L'identification des plantes et champignons est un problème de classification classique, qui est habituellement effectué manuellement à l'aide de clés d'identification. La plupart de ces clés sont basées sur un processus utilisant des arbres décisionnels, ce qui semble logique car rappelant la logique en arbre de l'évolution. Quoique séduisant, cet argument rencontre quelques limites :
\paragraph*{}
La première limite est le nombre de chaînons manquants. Certaines espèces sont évidemment éteintes, ce qui signifie que certaines branches et n\oe{}uds de l'arbre phylogénétique sont manquants, ce qui peut compliquer l'analyse quand deux espèces apparentées ont un nombre élevé de chaînons et n\oe{}uds communs manquants. Certaines similarités entre espèces peuvent également ne pas être identifiables de façon macroscopique.
\paragraph*{}
La seconde limite, plus profonde, est la logique inhérente au processus évolutionnaire. Deux phénomènes antagonistes sont en jeu : convergence et divergence évolutives. Ces deux phénomènes sont liés à la nécessaire adaptation des espèces à leurs environnements. La divergence évolutive explique par exemple la diversité des mammifères : les chauves-souris, baleines et chevaux sont apparentés, mais ont des aspects très dissemblables en raison de leur adaptation à des environnements très différents. D'un autre côté, la convergence évolutive explique la similarité entre l'aile de la chauve-souris et l'aile de l'abeille. Toutefois, malgré leur apparente dissimilarité, l'aile de la chauve-souris est plus proche de la main humaine ou de la nageoire de la baleine que de l'aile de l'abeille. La façon la plus fiable pour évaluer le processus évolutionnaire et trouver les liens phylogénétiques de la manière la plus précise possible est l'analyse des génomes : les caractéristiques visibles peuvent être trompeuses. Malheureusement, ces caractéristiques sont souvent les seules aisément identifiables.
\paragraph*{}
Le troisième problème est le critère principal de la classification. Ce critère peut être lié ou non au processus évolutionnaire ou aux critères visible, surtout si ce critère principal est vague. Le critère de comestibilité ou de non-comestibilité retenu pour les lots de données mycologiques usuellement utilisés en *data science* souffre de ce problème : il est essentiellement centré sur la toxicité contre les humains, or de nombreux mécanismes de toxicité peuvent exister, et une toxicité ou non-toxicité d'un métabolite fongique ou végétal peut être liée à des variations métaboliques très ténues entre une espèce et une autre.
\paragraph*{}
Pour ces raisons parmi d'autres, la logique arborescente, bien qu'utilisée habituellement dans l'identification des champignons et des plantes, et souvent justifiée par la nature arborescente du processus évolutionnaire, pourrait ne pas nécessairement être l'approche optimale à la classification des espèces basée sur des critères macroscopiques. Le but de cette étude est d'effectuer cette tâche de classification basée sur des indices visuels limités, et d'évaluer les performances relatives de différentes stratégies de classification.

## Etat de l'art des lots de données mycologiques
Le tout premier lot de données mycologiques en libre accès mentionné en data science est probablement le *Mushroom Dataset* créé par Jeff Schlimmer en 1987.[@schlimmer_mushroom_1987]
\paragraph*{}
Un lot de données plus conséquent a été publié par Dennis Wagner en 2021[@wagner_mushroom_2021] et mis en libre accès sous le nom de *Secondary Mushroom Dataset*.

\newpage
# Création du lot de données
## Configuration matérielle et logicielle
\paragraph*{}
\FloatBarrier
Le code d'apprentissage machine, les méthodes d'évaluation, ainsi que cette thèse ont été rédigés sur l'équipement suivant :

* CPU : AMD Ryzen 5 5600G
* RAM : 2x16 Go DDR4-3200
* SSD : Crucial P5 M2 NVMe
* OS : Xubuntu Linux 22.04.2 LTS
* R : version `r paste0(R.version$major, ".", R.version$minor, " (", R.version$year, ")")`
* IDE : RStudio version `r paste0(rstudioapi::versionInfo()$version, ', "', rstudioapi::versionInfo()$release_name, '"')`
* VCS : `r system("git --version", intern = TRUE)`
* Librairies : tidyverse[@R-tidyverse] (v`r packageVersion("tidyverse")`), microbenchmark[@R-microbenchmark] (v`r packageVersion("microbenchmark")`), MASS[@R-MASS] (v`r packageVersion("MASS")`), caret[@R-caret] (v`r packageVersion("caret")`), ?GGally?[@R-GGally] (v`r packageVersion("GGally")`), twinning[@R-twinning] (v`r packageVersion("twinning")`), rpart[@R-rpart] (v`r packageVersion("rpart")`), plyr[@R-plyr] (v`r packageVersion("plyr")`), ?C50?[@R-C50] (v`r packageVersion("C50")`), party[@R-party] (v`r packageVersion("party")`), ranger[@R-ranger] (v`r packageVersion("ranger")`), rFerns[@R-rFerns] (v`r packageVersion("rFerns")`), Rborist[@R-Rborist] (v`r packageVersion("Rborist")`),  rmarkdown[@R-rmarkdown] (v`r packageVersion("rmarkdown")`), knitr[@R-knitr] (v`r packageVersion("knitr")`), ggpubr[@R-ggpubr] (v`r packageVersion("ggpubr")`), DiceDesign[@R-DiceDesign] (v`r packageVersion("DiceDesign")`), DiceEval[@R-DiceEval] (v`r packageVersion("DiceEval")`), bookdown[@R-bookdown] (v`r packageVersion("bookdown")`).

\FloatBarrier
## Principes de conception d'un lot de données synthétiques
### Principes généraux{#generation-data}
\paragraph*{}
Un lot de données synthétiques est un lot de données généré par un algorithme, par opposition aux lots de données issus d'une collecte effectuée en "vie réelle". 
\paragraph*{}
\FloatBarrier
Trois stratégies sont usuellement utilisées :

* Données factices (*dummy data*) : l'ensemble des données est généré aléatoirement.
* Données générées à partir de règles (*rule-based data*) : l'ensemble des données est généré suivant des lois définies au préalable (distribution, valeurs moyennes, minimales, maximales...)
* Données générées par intelligence artificielle (*AI generated*) : l'ensemble des données est généré suivant des lois extraites par l'IA suite à l'analyse d'un échantillon de données obtenues en "vie réelle".

\FloatBarrier
\paragraph*{}
Les données générées par ces stratégies peuvent être de type variés, que nous pouvons grossièrement regrouper en données alphanumériques (quantitatives et qualitatives) et en données d'imagerie.
\paragraph*{}
Pour des raisons pratiques et de maturité des technologies disponibles à l'heure actuelle, la méthode retenue pour créer le lot de données exploité dans notre étude sera la génération de données alphanumériques à partir de règles, extraites d'ouvrages mycologiques de référence.[@courtecuisse_cle_1986; @courtecuisse_champignons_2013; @courtecuisse_initiation_2020]

### Principes de génération des paramètres quantitatifs
\paragraph*{}
\FloatBarrier
Dans le cadre de cette étude, les variables quantitatives générées aléatoirement sont :

* La longueur du stipe $L_{S}$,
* Le diamètre du stipe $D_{S}$,
* Le diamètre du chapeau $D_{C}$.

\FloatBarrier
\paragraph*{}
En première approximation, nous pouvons considérer que toutes ces valeurs sont intrinsèquement liées à la croissance du champignon. Ces trois variables peuvent, dans l'absolu, être susceptibles de varier indépendamment des autres au cours de la croissance du champignon, les variables $L_{S}$, $D_{S}$ et $D_{C}$ obéissant alors aux lois suivantes :

$$\left \{
\begin{array}{l}
L_{S} = L_{S_{max}}.F_{Ls} \\
D_{S} = D_{S_{max}}.F_{Ds} \\
D_{C} = D_{C_{max}}.F_{Dc} \\
\end{array}
\right.$$

Avec :

* $L_{S_{max}}$, $D_{S_{max}}$ et $D_{C_{max}}$ les valeurs maximales de longueur de stipe, diamètre du stipe et diamètre de chapeau de chaque variété de champignon, extraites de la littérature, 
* $F_{Ls}$, $F_{Ds}$, $F_{Dc}$ des variables générées aléatoirement dans l'intervalle $\left] 0 ; 1 \right]$, et représentatives de la croissance du spécimen.

\paragraph*{}
Toutefois, la recherche bibliographique sur la cinétique de croissance des sporophores n'a pas permis de distinguer de différences de la cinétique de croissance de chacun de ces trois paramètres. Nous supposerons donc, en première approximation, que la croissance du stipe en longueur et en largeur, ainsi que la croissance du chapeau s'effectuent à des vitesses identiques. Nous obtenons par conséquent :

$$F_{Ls} = F_{Ds} = F_{Dc} = F_{T}$$
Avec $F_{T}$ un facteur représentatif de la taille globale de chaque spécimen généré aléatoirement.

\paragraph*{}
Ainsi, le problème de génération de nos trois variables aléatoires se simplifie en un problème de génération d'une seule variable aléatoire : le facteur de taille de chaque spécimen. Un certain nombre de distributions d'intérêt sont susceptibles d'être utilisées afin de générer des facteurs de taille $F_{T}$ aléatoires, il convient donc de définir le cahier des charges de la distribution la plus adaptée au sujet de cette étude.
\paragraph*{}
Les critères de sélection retenus afin de choisir la loi la plus appropriée sont :

* Efficience calculatoire,
* Distribution continue,
* Distribution bornée, ou aisément normalisable sur un intervalle $\left[ 0 ; 1 \right]$,
* Distribution asymétrique.

\FloatBarrier
\paragraph*{}
Le premier critère n'est, en pratique, pas un facteur limitant, les temps de calcul pour la génération d'un nombre de facteurs de taille $F_{T}$ suffisant étant typiquement inférieurs à `r chrono_typique` ms (pour `r n_chrono` facteurs générés) avec la plupart des distributions d'intérêt (voir figure \@ref(fig:Lots-Chrono)).


```{r Lots-Chrono, echo = FALSE, fig.height = 4, fig.cap = paste0("Temps de calcul des principales distributions d'intérêt pour ", n_chrono, " facteurs, (", fois_chrono, " iter.)")}
plot(chrono_distrib)
```

\paragraph*{}
Les critères de continuité et de normalité n'appellent que peu de commentaires. Ces critères permettent simplement de garantir la possibilité d'une infinité de valeurs dimensionnelles, dans l'intervalle considéré. Le critère de continuité proscrit toutefois l'utilisation de lois de distributions discrètes telles que la loi binomiale ou la loi de Poisson, et celui de normalité écarte des distributions telles que la loi de Weibull, dont la normalisation est parfois délicate.
\paragraph*{}
\FloatBarrier
Le critère d'asymétrie est un critère permettant de tenir compte des différents paramètres pouvant impacter la distribution de taille des spécimens prélevés, parmi lesquels :

* Différences de cinétique de croissance d'une famille à une autre,
* Particularités de la croissance fongique, notamment par la croissance hyphale, [@money_insights_2008; @porter_hyphal_2022]
* Probabilité de prélèvement variable selon la taille du spécimen (par difficulté de détection, considérations éthiques, intérêt mycologique ou gastronomique...).

\FloatBarrier
\paragraph*{}
Le premier paramètre évoqué précédemment n'a pu être exploité dans le cadre de cette étude en raison du manque de données concernant les cinétiques relatives de croissance des sporophores des différentes familles de macromycètes. Le modèle que nous proposons permet toutefois des développements ultérieurs dans ce domaine.
\paragraph*{}
Les deux derniers paramètres permettent de supposer que la distribution de taille des spécimens d'une même espèce à l'issue d'une récolte en vie réelle ne sera pas symétrique, d'une part en raison de la rapidité de la croissance fongique, et d'autre part parce que le prélèvement se fera préférentiellement en épargnant les spécimens de petite taille.
\paragraph*{}
Ainsi, la génération de la variable aléatoire $F_{T}$ obéira idéalement à une loi de distribution asymétrique vers la droite ($G_{1} < 0$). Ce critère d'asymétrie écarte par conséquent les lois de distribution symétriques telles que la loi normale ou la loi uniforme.
\paragraph*{}

```{r Lots-DistribSym, echo = FALSE, fig.height = 3, fig.cap = "Exemples de distributions de la loi uniforme (à gauche), binomiale (au centre) et normale (à droite)"}
plot(ggarrange(
   ncol = 3,
   distrib_uniforme + ylab("Nombre"),
   distrib_binomiale,
   distrib_normale))
```

```{r Lots-DistribAsym, echo = FALSE, fig.height = 3, fig.cap = "Exemples de distributions de la loi de Poisson (à gauche), de Weibull (au centre) et bêta (à droite)"}
plot(ggarrange(
   ncol = 3,
   distrib_poisson + ylab("Nombre"),
   distrib_weibull,
   distrib_beta
   )
)
```

\paragraph*{}
En raison des contraintes imposées précédemment ainsi que de par sa grande polyvalence,[@johnson_continuous_1995] la loi retenue dans le cadre de cette étude pour la génération des facteurs de taille aléatoires ($F_{T}$) est une loi bêta non-centrale, définie comme la fonction de distribution de :[@johnson_continuous_1995;@r_core_team_r_2021]
$$ X = \frac{\chi^{2}_{2 \alpha} (\lambda)} {\chi^{2}_{2 \alpha} (\lambda) + \chi^{2}_{2 \beta}}$$

Avec, comme paramètres définis empiriquement pour cette étude : 
$$\left \{
\begin{array}{l c c}
\alpha = 6 \, F_{c} & & (shape1)\\
\beta = 4  & & (shape2)\\
\lambda = F_{c}/2  & & (ncp)\\
\end{array}
\right.$$

$F_{c}$ est ici défini comme un facteur de croissance permettant de rendre compte de la cinétique de croissance de chaque variété d'une part, et du prélèvement préférentiel des spécimens de plus grande taille d'autre part, comme l'illustre la figure \@ref(fig:Lots-LoisBeta).

```{r Lots-LoisBeta, echo = FALSE, fig.height = 4, fig.cap = "Distribution de différentes lois bêta, en fonction du facteur de croissance Fc"}
plot(lois_beta)
```

Le modèle défini à ce stade impose une stricte proportionnalité entre diamètre du chapeau $D_{c}$, diamètre du stipe $D_{s}$ et longueur du stipe $L_{s}$.
\paragraph*{}
Dans un souci de réalisme, il apparaît souhaitable d'améliorer ce modèle mathématique en y ajoutant un facteur de dispersion, afin de proposer le modèle suivant :

$$\left \{
\begin{array}{ll} 
L_{S} = L_{Smax}.F_{T}.\delta_{Ls} & ~~~~avec~~ \delta_{Ls} \sim \mathcal{N}(\mu = 1 ; \sigma = 0.05) \\
D_{S} = D_{Smax}.F_{T}.\delta_{Ds} & ~~~~avec~~ \delta_{Ds} \sim \mathcal{N}(\mu = 1 ; \sigma = 0.05) \\
D_{C} = D_{Cmax}.F_{T}.\delta_{Dc} & ~~~~avec~~ \delta_{Dc} \sim \mathcal{N}(\mu = 1 ; \sigma = 0.05) \\
\end{array}
\right.$$

\paragraph*{}
L'impact de cette dispersion sur la distribution des paramètres de taille $L_{S}$, $D_{S}$ et $D_{C}$ est illustré par les figures \@ref(fig:Lots-Dispersion2D) et  \@ref(fig:Lots-DispersionDensite).
\paragraph*{}

```{r Lots-Dispersion2D, echo = FALSE, fig.height = 3, fig.cap = paste0("Nuages de points de 2 paramètres de taille (Ls et Dc), sans dispersion (à gauche) et avec dispersion (à droite), pour ", n_reduit, " champignons")}
plot(ggarrange(
   ncol = 2,
   nuage_sansdispersion,
   nuage_avecdispersion
   )
)
```

\paragraph*{}
La dispersion ainsi créée permet ainsi de créer de légères variations des rapports entre les différents paramètres de taille, tout en se situant à proximité de la première bissectrice et majoritairement dans la zone 50-90% de la taille maximale (voir figure \@ref(fig:Lots-DispersionDensite)). Cette dispersion autorise par ailleurs l'existence d'une faible proportion de spécimens dépassant les valeurs dimensionnelles maximales généralement admises par la littérature.

[faire calcul sur R pour relier aux chiffres]

```{r Lots-DispersionDensite, echo = FALSE, fig.height = 4, fig.cap = "Diagramme de densité de 2 paramètres de taille, avec dispersion"}
plot(densite2d)
```

\paragraph*{}
Une simulation de Monte Carlo unidimensionnelle effectuée sur `r INTRO_n_champis` spécimens nous permet ainsi d’évaluer la proportion de spécimens "hors normes" dépassant la valeur dimensionnelle maximale à environ `r INTRO_taux_gros_diam` % (cf. figure \@ref(fig:HorsNormes)). La même simulation nous permet d'évaluer que la proportion de spécimens "exceptionnels", dépassant de plus de 10% cette valeur maximale, sera quant à elle inférieure à `r INTRO_taux_supergros_diam` %.
\paragraph*{}

```{r HorsNormes, echo = FALSE, fig.height = 3, fig.cap = paste0("Distribution du diamètre de stipe Ds, pour Dsmax = ", Chap.Diam)}
plot(distrib_diametre)
```

\FloatBarrier

### Principes de génération des paramètres qualitatifs
\paragraph*{}
La génération des paramètres qualitatifs, tels que la couleur des spores ou le type d'hyménophore, est nettement moins complexe que celle des paramètres quantitatifs.

L'ensemble des valeurs quantitatives possibles pour un critère et pour une variété donnée est insérée dans un vecteur de valeurs, et une valeur sera tirée aléatoirement parmi celles contenues dans ce vecteur pour caractériser le paramètre en question pour chaque spécimen.

\newpage
\FloatBarrier

# Principes de l'apprentissage machine
## Jeux de données {#chapitre:split}

Les jeux de données dédiés à l'apprentissage machine sont tous construits sur la base de couples données-résultats. Selon l'étape de l'apprentissage machine, le résultat peut être fourni à la machine oului être caché, le but étant dans le premier cas de permettre à la machine d'effectuer son apprentissage, et dans le second cas d'évaluer les performances de la prédiction par rapport au résultat réel.
\paragraph*{}
Le déroulement de l'apprentissage machine se décompose conceptuellement en trois étapes principales, mettant en jeu trois lots de données distincts :

1. Entraînement : le modèle d'apprentissage est exposé à un *jeu de données d'entraînement* (*training data set*), censé être représentatif (cf. section \@ref(generation-data)) des données auquel le modèle sera exposé en utilisation réelle. Cette phase est la phase d'apprentissage du modèle.
2. Validation : le modèle d'apprentissage machine développé à l'étape précédente, est ici soumis à un *jeu de données de validation* (*validation data set*) et tentera d'apporter des prédictions quant à une variable d'intérêt considérée comme le résultat (ex: comestibilité, espèce...), sur la base des informations contenues dans le lot de données de validation (ex : dimensions, couleurs, morphologie du champignon...). Ces prédictions sont comparées avec les valeurs réelles (ex : comestibilité, espèce...), ce qui permet d'évaluer les performances prédictives du modèle proposé en fonction des indicateurs retenus (spécificité, sensibilité, F1-score, temps de calcul...). Les étapes d'apprentissage et de validation sont répétées de manière itérative en explorant l'ensemble des paramètres de configuration du modèle (hyperparamètres) -- idéalement en suivant un plan d'expériences -- à fins d'optimisation.
3. Test : les performances du meilleur modèle (avec hyperparamètres optimaux), sélectionné à l'issue de l'étape de validation, sont évaluées vis-à-vis d'un *jeu de données test* (*test* ou *holdout data set*).

\paragraph*{}
La séparation entre étapes d'optimisation et de test peut sembler artificielle. Le problème est en partie lié à un flou sémantique : si l'étape initiale d'entraînement ou d'apprentissage ne pose que peu de problèmes conceptuels, l'étape intermédiaire, dite de *validation* correspond en réalité à une étape d'*optimisation* du modèle et de ses hyperparamètres. Par ailleurs, l'étape finale de *test* sera parfois qualifiée d'étape de *validation* dans la littérature, ce qui peut entretenir la confusion entre ces étapes.[@brownlee_what_2017]
\paragraph*{}
Une distinction sémantique plus nette entre phases d'*apprentissage*, d'*optimisation* et de *test* permet de comprendre plus aisément le fondement épistémologique de cette dernière phase pouvant parfois sembler superflue : l'optimisation effectuée lors de l'étape de validation aboutit à un modèle potentiellement biaisé (problème dit d'*overfitting*) vis-à-vis du jeu de données utilisé comme référence lors de cette étape. Seule une exposition du modèle à des données n'ayant jamais servi à son entraînement ou son optimisation permettra réellement d'évaluer avec précision son caractère prédictif, donc sa validité.
\paragraph*{}
Dans un souci de clarté, nous utiliserons les termes de lots et de phases d'entraînement, d'optimisation et d'évaluation dans la suite de cette étude.
\paragraph*{}
Les phases d'entraînement, d'optimisation et d'évaluation utilisent chacune un lot de données spécifique. Chacun de ces lots de données est habituellement obtenu suite à dichotomies successives (voir figure \@ref(fig:Split-jeux)) du lot de données intial, avec des proportions pouvant être variables d'une scission à l'autre :

1. Découpage du jeu de données initial, en un jeu d'évaluation d'une part, et un jeu d'entraînement + optimisation d'autre part,
2. Découpage du jeu de données entraînement + optimisation, en un jeu d'entraînement et un jeu d'optimisation.


\begin{figure}
   \centering
   \includegraphics[width=\linewidth]{Split-Jeux}
  \caption{Principe de séparations successives d'un jeu de données initial en jeux d'apprentissage, d'optimisation et d'évaluation.}
  \label{fig:Split-jeux}
\end{figure}

\paragraph*{} \label{paragraphe:split_ratio}
Les rapports de taille entre jeux de données entraînement, optimisation, évaluation de cette étude suivront la loi $p : \sqrt{p} : \sqrt{p}+1$, avec $p$ le nombre de coefficients du modèle.[@joseph_optimal_2022] 
\paragraph*{} 
Ce nombre $p$ de coefficients peut être approché par l'expression $p \approx \sqrt{N_{u}}$, avec $N_{u}$ le nombre de colonnes uniques de notre jeu de données, c'est-à-dire, dans notre cas, le nombre de champignons du lot de données.[@joseph_optimal_2022]
\paragraph*{}
Un rapide calcul nous montre qu'il est possible d'obtenir ce rapport $p : \sqrt{p} : \sqrt{p}+1$ par une première scission entre jeu d'entraînement et optimisation d'une part (de taille relative $p +\sqrt{p}$) et jeu d'évaluation d'autre part (de taille relative $\sqrt{p}+1$), avec, pour ce dernier, une taille représentant la fraction du lot total :
$$f_{test}= \frac{\sqrt{p}+1}{p+2\sqrt{p}+1} = \frac{1}{\sqrt{p}+1} $$
\paragraph*{}
Cette première dichotomie peut être suivie par une seconde dichotomie entre jeu d'entraînement (de taille relative $p$) et jeu d'optimisation (de taille relative $\sqrt{p}$), de fraction :
$$ f_{opti} = \frac{\sqrt{p}}{p + \sqrt{p}} = \frac{1}{\sqrt{p}+1} $$

\paragraph*{}
En pratique, pour notre lot de données contenant $N_{u} = `r BI_n_champis`$ spécimens, nous pouvons calculer $p \approx `r round(BI_split_p,1)`$, soit deux dichotomies successives de ratio `r BI_split_facteur-1`:1.

## Méthodes de construction des jeux de données  {#chapitre:split_methodes}

Les méthodes de division mises en \oe{}uvre dans cette étude appellent quelques précisions, car elles apportent certaines améliorations par rapport à l'utilisation de deux scissions successives effectuées de manière aléatoire.
\paragraph*{}
La première division, entre jeu d'entraînement/optimisation et jeu d'évaluation, mettra en \oe{}uvre une méthode de découpage basée sur les points-supports[@mak_support_2018] (*support-points based splitting*) exploitant un algorithme du plus proche voisin (NN : *Nearest Neighbour*), afin d'optimiser la représentativité des jeux de données par rapport à ceux pouvant être obtenus par un découpage aléatoire.[@joseph_split_2022;@vakayil_data_2022]
\paragraph*{} \label{paragraphe:crossvalid}
Notre seconde division, entre jeu d'entraînement et d'optimisation, exploitera quant à elle la méthode de validation croisée à k blocs (*k-folds cross-validation*). Le principe de la validation croisée repose sur une utilisation tournante de la séparation créée entre jeux d'entraînement et d'optimisation (voir figure \@ref(fig:Cross-validation)).
\paragraph*{}
Le jeu d'entraînement/optimisation est découpé, de façon aléatoire, en k blocs de données de taille égale, dont k-1 sont utilisés pour l'entraînement du modèle prédictif et 1 pour son optimisation. Cette opération est répétée k fois, en utilisant un jeu d'optimisation différent à chaque itération. L'évaluation de la performance globale s'effectue en évaluant la performance moyenne des k itérations. Cette méthode permet de limiter les biais potentiels générés par une simple dichotomie des données d'entraînement et d'optimisation en exploitant la totalité des données du lot afin d'effectuer ces deux tâches.
\paragraph*{}
Comme démontré précédemment, une validation croisée *k-folds* avec $k = `r BI_split_facteur`$ permettrait d'optimiser l'apprentissage et l'optimisation des modèles de cette étude.[@joseph_optimal_2022]

\paragraph*{}
\begin{figure}
   \centering
   \includegraphics[width=\linewidth]{Cross-Validation}
  \caption{Principe de la validation croisée à k blocs (\emph{k-fold cross-validation}), pour \emph{k} = 4.}
  \label{fig:Cross-validation}
\end{figure}

\FloatBarrier

## Modèles utilisés
### Analyses discriminantes

*Développements théoriques sur les modèles d'analyse discriminante linéaire, pénalisée, quadratique*

[A FAIRE]

<!-- [discriminant correspondence analysis???] -->

<!-- https://rpubs.com/markloessi/505575 -->

<!-- https://en.wikipedia.org/wiki/Altman_Z-score -->

<!-- https://towardsdatascience.com/linear-discriminant-analysis-explained-f88be6c1e00b -->

<!-- https://scikit-learn.org/stable/modules/lda_qda.html -->
<!-- \paragraph*{} -->
<!-- Cette étude propose plusieurs classifieurs linéaires s'appuyant sur des méthodes d'analyse discriminante : -->

<!-- * un modèle basé sur l'analyse discriminante linéaire (*Linear Discriminant Analysis*, LDA), -->
<!-- * un modèle basé sur l'analyse discriminante pénalisée (*Penalized Discriminant Analysis*, PDA). -->

<!-- \paragraph*{} -->
<!-- L'analyse linéaire discriminante (LDA) est une méthode utilisée en statistiques et en data science pour trouver une combinaison linéaire d'éléments qui caractérisent des éléments, afin de créer un classifieur linéaire, ou d'effectuer des réductions de dimensionnalité. Cet algorithme fonctionne en créant des combinaisons linéaires (fonctions discriminantes) de prédicteurs. [A FINIR] -->
<!-- \paragraph*{} -->
<!-- L'analyse discriminante pénalisée [A FINIR] -->

### Modèle additif généralisé
<!-- gamLoess -->
*Développements théoriques sur les modèles GAM...*

[A FAIRE]

### Arbres de décision
<!-- rpart, Ctree???, c50tree, Rpartcost -->
*Développements théoriques sur les arbres décisionnels...*

[A FAIRE]

### Forêts aléatoires
<!-- rFerns, Rborist, ranger -->
*Développements théoriques sur les modèles de forêts aléatoires...*

[A FAIRE]

## Optimisation par plans d'expérience (DOE) {#chapitre:doe}

Certains modèles nécessiteront une optimisation de leurs hyperparamètres, qui relève du domaine des plans d'expérience. De nombreux plans et stratégies sont envisageables, le choix dépendra en partie des caractéristiques du processus à optimiser.
\paragraph*{}
En effet, l'optimisation des paramètres d'un modèle informatique présente quelques particularités notables :

* La réalisation d'une expérience supplémentaire a un coût faible,
* Il peut exister plusieurs métriques coexistantes,
* La fonction de réponse peut s'avérer relativement complexe.

\paragraph*{}
Ces particularités imposent d'explorer de manière méthodique la totalité de l'espace expérimental. Il existe une multitude de méthodes permettant de générer des plans expérimentaux, dits SFD (*Space Filling Design*), permettant d'optimiser l'occupation de l'espace expérimental. La méthode retenue pour cette étude sera celle des hypercubes latins, en raison de son utilisation répandue[@santiago_construction_2012] et de sa simplicité conceptuelle.
\paragraph*{}
La méthode des hypercubes latins est une extension du principe des carrés latins. Un carré latin est une grille $n \times n$, remplie de n éléments distincts arrangés de sorte que chaque ligne et chaque colonne ne contienne qu’un seul exemplaire de chacun des n éléments. Dans le domaine des plans d'expériences, l'application des carrés latins revient à diviser un domaine expérimental bidimensionnel en une grille $n \times n$, et à placer une expérience et une seule sur chaque ligne et chaque colonne.
\paragraph*{}
L'application du concept de carré latin dans un domaine expérimental à trois dimensions aboutit au cube latin. La généralisation dans un espace n-dimensionnel mène au concept d'hypercube latin.
\paragraph*{}
De nombreux plans expérimentaux basés sur les hypercubes latins peuvent être générés. Nous pouvons citer principalement trois types d'hypercubes latins :

* Aléatoires,
* Optimisés, afin d'optimiser l'occupation spatiale,
* Orthogonaux, visant à minimiser la corrélation des estimateurs des effets principaux.

```{r Carres-Latins, echo = FALSE, fig.height = 2.5, fig.cap = "Carré latin aléatoire (à gauche), carré latin avec optimisation évolutive ESE maximin (au milieu), carré latin quasi-orthogonal (à droite)"}
plot(ggarrange(
   widths = c(1.05,1,1),
   ncol = 3,
   graphe_LHS + ylab("X2"),
   graphe_optiLHS,
   graphe_NOHLD
   )
)
```

Dans le cadre de cette étude, nous utiliserons des hypercubes latins quasi-orthogonaux, dont les propriétés nous permettront de modéliser de façon plus précise les performances de nos modèles en fonction de leurs paramètres de configuration (*hyperparamètres*).
\paragraph*{}
Le but des plans expérimentaux de cette étude ne sera pas l'obtention d'une prédictive exacte de la réponse, mais la recherche des facteurs permettant d'obtenir cette réponse optimale. A cet effet, la modélisation de la performance s'effectuera à l'aide d'un modèle quadratique, de formule générale :
$$ Y = \beta_{0}  + \sum_{i = 1}^{k} \beta_{i}.X_{i} + \sum_{i <j}^{k} \sum_{j>1}^{k} \beta_{ij}.X_{i}.X_{j} + \sum_{i = 1}^{k} + \beta_{ii}.X_{i}^2 + \varepsilon$$
Avec $\beta_{n}$ les coefficients des effets principaux et $X_{n}$ les facteurs réduits.
\FloatBarrier

## Evaluation des performances des modèles {#chapitre:perf}

L'optimisation des modèles ainsi que la comparaison de leurs performances relatives implique nécessairement de définir quel sera le critère vis-à-vis duquel cette performance sera évaluée.
\paragraph*{}
De nombreux critères sont utilisables, en fonction du cahier des charges, mais également du type de tâche effectuée : régression, classification binaire, classification multiclasse.
\paragraph*{}
Dans une tâche de classification binaire, les critères usuels sont la spécificité, la sensibilité, et l'aire sous la courbe de fonction d'efficacité du récepteur (*AUC ROC*, parfois abrégé en *ROC*). Il conviendra bien évidemment, avant d'utiliser des indicateurs tels que la spécificité et la sensibilité, de définir la notion de test positif et test négatif.
\paragraph*{}
D'autres indicateurs d'intérêt existent, nous retiendrons ici l'index J de Youden[@youden_index_1950] pondéré, qui permet de d'ajuster les pondérations de la spécificité et la sensibilité au sein d'un index synthétique.[@rucker_summary_2010] Cet indicateur présente un intérêt particulier lorsqu'il apparaît souhaitable de tenir compte de la différence d'impact entre un faux positif et un faux négatif, sans pour autant autoriser des sensibilités ou spécificités trop faibles.
\paragraph*{}
En l'espèce, l'index J de Youden pondéré nous permet donc de construire un indice synthétique tenant compte du fait qu'il est plus grave de classer à tort comme comestible un champignon toxique que d'écarter à tort un champignon parfaitement comestible, sans pour autant autoriser le modèle à écarter un nombre inconsidéré de champignons comestibles.
\paragraph*{}
L'index J de Youden pondéré est donné par :[@rucker_summary_2010]
$$ J_{w} = 2.\left(w.Sen+ \left(1-w\right).Spe \right) -1 ~~~~~~~~ avec ~~~~ w \in \left[0;1\right]$$ 

\paragraph*{}
Dans la classification binaire de cette étude, problème qui revient classiquement en mycologie à classer les espèces en fonction de leur toxicité, la valeur positive sera ici arbitrairement attribuée à la valeur "champignon toxique". Nous cherchons donc à maximiser la sensibilité de la détection, afin d'écarter les espèces toxiques, la spécificité -- c'est-à-dire la capacité à ne pas écarter trop d'espèces comestibles -- apparaissant alors comme un critère relativement secondaire. En établissant arbitrairement un index J de Youden pondéré accordant `r Jw_ratio` fois plus d'importance à la sensibilité qu'à la spécificité, nous pouvons établir $w = `r Jw_ratio`/`r Jw_ratio+1`$.
\paragraph*{}
Le problème de classification binaire étant relativement simple (*comestible* ou *non-comestible*), nous fixerons arbitrairement le critère de performance minimum à atteindre à $J_{w} \geq `r Jw_min`$, soit :
$$\left \{
\begin{array}{l}
Sen_{max} = 1 \Leftrightarrow Spe_{min} = `r Jw_Spec_min` \\
Spe_{max} = 1 \Leftrightarrow Sen_{min} = `r Jw_Sens_min` \\
\end{array}
\right.$$

\paragraph*{}
Dans les tâches de classification multiclasse, d'autres indicateurs d'intérêt pourront être utilisés, tels que le kappa de Cohen, l'indice de Rand (*accuracy*), mais aussi la sensibilité et la spécificité moyennes.
\paragraph*{}
Nous retiendrons dans le cadre de notre étude le kappa de Cohen,[@cohen_coefficient_1960] calculé à partir de la matrice de confusion (cf. figure \ref{fig:Matrice-Confusion}), et donné par :
$$\kappa{} = \frac{\pi_{0}-\pi_{e}}{1-\pi_{e}}$$
\paragraph*{}
Avec $\pi_{0}$ la probabilité d'accord entre notre modèle et la classe réelle du champignon, et $\pi_{e}$ la probabilité d'un même accord résultant du pur hasard.
\paragraph*{}
\begin{figure}
   \centering
   \includegraphics[width=\linewidth]{Matrice-Confusion}
  \caption{Extrait d'une matrice de confusion, pour une classification multiclasse}
  \label{fig:Matrice-Confusion}
\end{figure}

\paragraph*{}
Landis et Koch ont élaboré une échelle de validité du kappa de Cohen, avec un accord qualifié de *quasi-parfait* pour $\kappa > 0.80$.[@landis_measurement_1977] Nous considérerons donc que ce critère sera le minimum requis pour qu'un modèle de classifieur multiclasse élaboré au cours de cette étude puisse être considéré comme ayant des performances acceptables.
\paragraph*{}
L'interprétation du kappa pouvant parfois être assez contre-intuitive, cette étude la complétera parfois par la précision (*accuracy*), métrique moins robuste en présence de données non-équilibrées (i.e. lors d'une surreprésentation de certaines classes dans le lot de données), mais présentant l'avantage d'être plus intuitive, car représentant le pourcentage de prédictions exactes.
\paragraph*{}




\newpage

# Apprentissage machine et classification binaire

*Brouillon, le lot de données utilisé ici est le Secondary Mushroom Dataset de D.Wagner.*

## Analyse exploratoire des données (EDA)

*A voir si cette partie mérite d'être conservée et/ou nécessite un éventuel approfondissement vers une EDA sur un lot biclasse ou multiclasse...*

\FloatBarrier
\paragraph*{}

```{r EDA-structure, out.width = "90%", echo = FALSE}
kable(structure_dataset, caption = "Structure du lot de données initial")
```

\paragraph*{}
Le lot de données d'origine contient `r EDA_n_champis` spécimens de champignons, caractérisés par `r EDA_n_cols` propriétés morphologiques ou environnementales. La structure de ce lot de données est résumé dans le tableau \@ref(tab:EDA-structure).
\paragraph*{}
Ce lot de données original a été découpé en un jeu d'apprentissage/optimisation et un jeu de données d'évaluation, avec un rapport `r EDA_split_facteur-1`:1, conformément aux principes mentionnés dans nos développements précédents.\footnote{cf. section \ref{chapitre:split}, page \pageref{paragraphe:split_ratio}.}
\paragraph*{}
Toutes les distributions des variables du lot d'entraînement ont ensuite été tracées par histogrammes pour les variables numériques, et diagrammes en barres pour les variables alphabétiques et catégorielles.
\paragraph*{}
Les diagrammes en barres n'ont rien illustré de particulièrement remarquable et n'ont pas été inclus dans le rapport. Toutefois, les distributions dimensionnelles sont plus intéressantes : à première vue, elles semblent suivre une courbe en cloche (figure \@ref(fig:EDA-distrib)), avec une longue queue à droite. Une transformation logarithmique (figure \@ref(fig:EDA-distrib-log)) montre plus nettement la forme de cette queue.

```{r EDA-distrib, echo = FALSE, fig.height = 2.5, fig.cap = "Distribution des diamètres de chapeau, longueur de stipe, diamètre de stipe"}
plot(ggarrange(
   ncol = 3,
   study_distrib_cap.diameter + ggtitle("") + ylab("") + scale_y_continuous(labels = NULL),
   study_distrib_stem.height + ggtitle("") + ylab("") + scale_y_continuous(labels = NULL),
   study_distrib_stem.width + ggtitle("") + ylab("") + scale_y_continuous(labels = NULL)
   )
)
```

```{r EDA-distrib-log, echo = FALSE, fig.height = 2.5, fig.cap = "Distribution des diamètres de chapeau, longueur de stipe, diamètre de stipe (échelle logarithmique en ordonnée)"}
plot(ggarrange(
   ncol = 3,
   study_distrib_cap.diameter + ggtitle("") + ylab("") + scale_y_log10(labels = NULL),
   study_distrib_stem.height + ggtitle("") + ylab("") + scale_y_log10(labels = NULL),
   study_distrib_stem.width + ggtitle("") + ylab("") + scale_y_log10(labels = NULL)
   )
)
```

La distribution du diamètre du chapeau $D_{C}$ a l'apparence d'une courbe en cloche, avec une longue queue à droite, mais est en réalité bimodale, avec un mode principal à 5 cm, et un mode secondaire beaucoup plus petit pour $D_{C} \approx$ 50 cm. Cette taille exceptionnelle est attribuable à des variétés telles que *Polyporus squamosus*.[@courtecuisse_champignons_2013]
\paragraph*{}
La distribution de la longueur de stipe $L_{S}$ a également une forme de courbe en cloche avec une longue queue à droite, un mode principal à 5 cm et un mode secondaire à 0 cm. Cette valeur peut également sembler surprenante, mais certains champignons du lot n'ont pas de pied, ce qui explique cette valeur.
\paragraph*{}
La distribution du diamètre de stipe $D_{S}$ a aussi l'apparence d'une courbe en cloche avec une longueur queue à droite, et un pic à $D_{S} \approx$ 10-15 mm. Dans toutes ces distributions, la longue queue à droite peut probablement s'expliquer par l'utilisation, dans le *Secondary Mushroom Dataset*, d'une distribution normale pour chaque variété, associée à l'impossibilité d'avoir des valeur dimensionnelles négatives.

\newpage
## Optimisation et sélection des modèles
\paragraph*{}
Il existe une grande variété de modèles exploitables pour bâtir un système d'apprentissage machine. Cette section expliquera la stratégie utilisée pour l'évaluation de certains de ces modèles. Les modèles sélectionnés pour cette étude sont de types variés :

* Analyse discriminante linéaire (LDA) : *Linear Discriminant Analysis* (lda2), *Penalized Discriminant Analysis* (pda)
* Modèle additif généralisé (GAM) : *Generalized Additive Model using LOESS* (gamLoess)
* Modèle arborescent : *Classification And Regression Tree* (CART) (rpart, rpartCost), *Single C5.0 Tree* (ctree)
* Forêt aléatoire : *Random Ferns* (rferns), *Random Forest* (ranger, Rborist)

### Stratégie d'optimisation

L'algorithme d'apprentissage machine développé au cours de cette étude met en \oe{}uvre les méthodes présentées dans les sections précédentes afin d'effectuer automatiquement les tâches suivantes :

1. Découpage du lot de données en un jeu d'entraînement/optimisation et en un jeu de validation, avec adaptation des rapports de taille en fonction du volume de données du lot initial\footnote{cf. section \ref{chapitre:split}, page \pageref{paragraphe:split_ratio}},
2. Apprentissage sur le jeu d'entraînement, exploitant une validation croisée à k blocs, avec adaptation du nombre de blocs à la taille du lot de données\footnote{cf. section \ref{chapitre:split_methodes}, page \pageref{paragraphe:crossvalid}},
3. Exploration de l'ensemble de l'espace expérimental des hyperparamètres du modèle, via la méthode des hypercubes latins quasi-orthogonaux\footnote{\label{note:doe}cf. section \ref{chapitre:doe}},
4. Mesure des performances en exploitant une métrique adaptée\footnote{cf. section \ref{chapitre:perf}}
5. Modélisation des performances en fonction des hyperparamètres, via un modèle quadratique avec interactions\footnotemark[\value{footnote}],
6. Sélection des hyperparamètres permettant d'optimiser les performances du modèle,
7. Mesure des performances de chaque modèle avec les hyperparamètres optimaux,
8. Pour les modèles les plus performants : prédiction et mesure finale des performances contre le lot d'évaluation.

### Modèles d'analyse discriminante{#chapitre:BI_lda}
\paragraph*{}
Les modèles d'analyse discriminante linéaire (LDA) choisis pour cette étude sont lda2 (*Linear Discriminant Analysis*) et pda (*Penalized Discriminant Analysis*). Le modèle lda2 dispose d'un hyperparamètre (*dimen*, nombre de fonctions discriminantes). Le modèle pda a également un unique hyperparamètre (*lambda*, pénalité de réduction des coefficients).  

```{r, lda-pda, echo = FALSE, fig.height = 3, fig.cap = "Performances des modèles lda2 (à gauche) et pda (à droite)"}
plot(ggarrange(widths = c(1, 1.5),
   ncol = 2,
   BI_fit_lda2_dim_graphe + theme(legend.position="none"),
   BI_fit_pda_lambda_graphe
   )
)
```
\paragraph*{}
Comme l'illustre la figure \ref{fig:lda-pda}, les performances des modèles PDA et LDA sont très proches, et relativement constantes sur la totalité de l'espace expérimental de leurs hyperparamètres.
\paragraph*{}
Le paramètre *dimen* du modèle lda2 ne semble en effet pas avoir d'effet significatif sur ses performances, avec un index J de Youden pondéré relativement constant ($J_{w_{moy}} = `r round(mean(BI_fit_lda2_dim_resultats[,"Jw"]), 3)`$). 
\paragraph*{}
De même, le paramètre *lambda* du modèle pda n'impacte ses performances que de matière très marginale, avec des lambdas faibles donnant une légère amélioration des résultats ($J_{w_{max}} = `r round(max(BI_fit_pda_lambda_resultats["Jw"]),3)`$).
\paragraph*{}
Toutefois, les performances de ces deux modèles restent malheureusement insuffisante pour notre étude, aussi bien en sensibilité qu'en spécificité :
$$\left \{
\begin{array}{l}
Sen \approx `r round(mean(c(BI_fit_lda2_dim_resultats[,"Sens"], BI_fit_pda_lambda_resultats[,"Sens"])),3)` \\
Spe \approx `r round(mean(c(BI_fit_lda2_dim_resultats[,"Sens"], BI_fit_pda_lambda_resultats[,"Spec"])),3)` \\
\end{array}
\right.$$

\paragraph*{}
Ces performances médiocres s'expliquent par le fonctionnement même des modèles d'analyse discriminante qui, s'ils peuvent analyser des données qualitatives à fins de classifications, ne peuvent le faire que si une quantification sous-jacente est possible, par exemple :

* Données binaires ou booléennes
* Données catégorielles basées sur des données numériques

\paragraph*{}
L'inclusion de ces modèles, présentant ici des performances très modestes, a un intérêt essentiellement didactique, permettant de souligner l'intérêt d'une connaissance élémentaire des fondamentaux mathématiques et algorithmiques des modèles d'apprentissage machine mis en \oe{}uvre, afin d'en connaître les limites ou d'évaluer les besoins de nettoyage préalable des données avant déploiement de l'apprentissage machine, afin d'éviter de confronter certains modèles face à des problèmes de classification pour lesquels ils n'ont pas été conçus.

\FloatBarrier
### Modèle additif généralisé  
\paragraph*{}
Le seul modèle additif généralisé choisi pour cette étude est gamLoess (*Generalized Additive Model using Locally Weighted Linear Regression*). La documentation de la librairie indique que le modèle gamLoess dispose de deux hyperparamètres : *span* (fraction de points utilisés dans l'environnement local) and *degree* (degré de linéarisation).

```{r, echo = FALSE, fig.height = 3, fig.cap = "Performances de gamLoess en fonction du span (gauche) and du degré (droite)"}
plot(ggarrange(widths = c(1, 1.5),
   ncol = 2,
   BI_fit_gamLoess_span_graphe + theme(legend.position="none"),
   BI_fit_gamLoess_degree_graphe
   )
)
```

\paragraph*{}
L'hyperparamètre *degree* du modèle gamLoess a un impact mineur sur ses performances, avec un écart entre indices J de Youden maximal et minimal de $\Delta J_{w} = `r round(max(BI_fit_gamLoess_degree_resultats[,"Jw"]) - min(BI_fit_gamLoess_degree_resultats[,"Jw"]), 3)`$.
\paragraph*{}
L'hyperparamètre *span* affecte marginalement la sensibilité de gamLoess, avec une valeur optimale de $span = `r BI_fit_gamLoess_span_resultats[which.max(BI_fit_gamLoess_span_resultats[,"Jw"]), "span"]`$, aboutissant à un index J de Youden maximal de $J_{w_{max}} = `r round(max(BI_fit_gamLoess_span_resultats["Jw"]), 3)`$.
\paragraph*{}
Les performances de ce modèle n'atteignent pas le critère posé pour notre étude. Le modèle additif généralisé s'est avéré inférieur aux modèles d'analyse discriminante linéaire, aussi bien en en sensibilité (`r round(max(BI_fit_gamLoess_span_resultats["Sens"]), 3)` vs `r round(mean(c(BI_fit_lda2_dim_resultats$Sens, BI_fit_pda_lambda_resultats$Sens)), 3)`) qu'en spécificité (`r round(max(BI_fit_gamLoess_span_resultats["Spec"]), 3)` vs `r round(mean(c(BI_fit_lda2_dim_resultats$Spec, BI_fit_pda_lambda_resultats$Spec)), 3)`).
\paragraph*{}
Les performances médiocres de ce modèle s'expliquent par les mêmes raisons que celles des modèles d'analyse discriminante (cf. section \ref{chapitre:BI_lda})

\FloatBarrier
### Modèles d'arbres de décision
\paragraph*{}
Les modèles basés sur des arbres de décision ont un intérêt tout particulier pour cette étude, pour deux raisons majeures :

* La logique en arbre de décision est habituellement usitée pour la classification manuelle des champignons,
* Les arbres de décision obtenus peuvent être tracés, et facilement interprétés par l'humain.

\paragraph*{}
Les premiers modèles présentés dans le cadre de notre étude sont deux modèles CART (*Classification And Regression Tree*). Le modèle CART le plus simple proposé dans notre étude (rpart) ne dispose que d'un seul hyperparamètre  : *cp* (complexité).
\FloatBarrier
\paragraph*{}
```{r, echo = FALSE, fig.height = 3, fig.cap = "Performances du modèle rpart en fonction du paramètre de complexité (cp)"}
plot(BI_fit_rpart_cp_graphe)
```


\paragraph*{}
Le modèle CART le plus simple n'atteint jamais les performances requises, le critère étant $Jw \geq `r Jw_min`$. Toutefois, ce modèle s'en approche, et donne de bons résultats globaux, avec :
$$\left \{
\begin{array}{l}
J_{w_{max}} = `r round(max(BI_fit_rpart_cp_resultats["Jw"]),4)` \\
Spe_{Jw_{max}} = `r round(BI_fit_rpart_cp_resultats[which.max(BI_fit_rpart_cp_resultats[,"Jw"]),"Spec"],4)` \\
Sen_{Jw_{max}} = `r round(BI_fit_rpart_cp_resultats[which.max(BI_fit_rpart_cp_resultats[,"Jw"]),"Sens"],4)` \\
\end{array}
\right.$$

\FloatBarrier
\paragraph*{}
Le second modèle CART utilisé dans cette étude (rpartCost) associe des hyperparamètres de complexité (*cp*) et de coût (*Cost*). Les graphiques de sensibilité et de spécificité en fonction des hyperparamètres illustrent bien, dans leur partie supérieure ($cp \geq 0.05$) la notion classique de compromis entre sensibilité et spécificité : dans cette zone, toute amélioration de la sensibilité se fera inévitablement au détriment de la spécificité, et inversement.
\paragraph*{}
En pratique, pour $cp \geq 0.05$, notre modèle d'IA basé sur ce type d'arbre de décision se montrera soit excessivement sévère, rejetant un nombre considérable de champignons comestibles (quadrant supérieur gauche, $cost \leq 1.5$), soit au contraire excessivement laxiste, admettant un nombre important de champignons non-comestibles (quadrant supérieur droit, $cost \geq 1.5$).
\paragraph*{}
C'est dans la section inférieure de ces graphiques ($cp \leq 0.025$) que le modèle montre une performance acceptable tant en sensibilité qu'en spécificité.


```{r, echo = FALSE, fig.height = 4, fig.cap = "Sensibilité (à gauche) et spécificité (à droite) de rpartCost en fonction de la complexité et du coût (interpolation quadratique, points expérimentaux encadrés en noir)"}
plot(ggarrange(
   ncol = 2,
   BI_fit_rpartcost_sens_graphe,
   BI_fit_rpartcost_spec_graphe
   )
)
```

```{r, echo = FALSE, fig.height = 4, fig.width = 5.2, fig.cap = "Performances (index J de Youden pondéré 10:1) de rpartCost en fonction des paramètres réduits de complexité X1 et de coût X2 (interpolation quadratique, points expérimentaux encadrés en noir)"}
plot(BI_fit_rpartcost_jw_graphe + theme(legend.position='right'))
```

\FloatBarrier
\paragraph*{}
La modélisation selon le modèle quadratique avec interaction\footnote{cf. section \ref{chapitre:doe}} donne le modèle suivant :
$$ Y = b_{0} + b_{1}.X_{1} + b_{2}.X_{2} + b_{12}.X_{1}.X_{2} + b_{11}.X_{1}^{2} + b_{22}.X_{2}^{2}$$
Avec Y l'indice J de Youden pondéré, $X_{1}$ le facteur réduit dans la plage [0;1] associé au paramètre de complexité (*cp*), $X_{2}$ le facteur réduit associé au paramètre de coût (*Cost*) et $\beta_{n}$ les coefficients des effets. La modélisation permet de calculer les effets suivants:

$$\left \{
\begin{array}{l}
b_{0} = `r round(BI_mod_rpartcost_jw$model@trend.coef[1],4)` \\
b_{1} = `r round(BI_mod_rpartcost_jw$model@trend.coef[2],4)` \\
b_{2} = `r round(BI_mod_rpartcost_jw$model@trend.coef[3],4)` \\
b_{12} = `r round(BI_mod_rpartcost_jw$model@trend.coef[6],4)` \\
b_{11} = `r round(BI_mod_rpartcost_jw$model@trend.coef[4],4)` \\
b_{22} = `r round(BI_mod_rpartcost_jw$model@trend.coef[5],4)` \\
\end{array}
\right.$$

\paragraph*{}
Les performances maximales seront ici atteintes pour :

$$\left \{
\begin{array}{lcl}
X_{1} = `r BI_modelquad_rpartcost_top["X1"]` & soit & cp = `r BI_modelquad_rpartcost_top["cp"]` \\
X_{2} = `r BI_modelquad_rpartcost_top["X2"]` & soit & Cost = `r round(BI_modelquad_rpartcost_top["Cost"],2)` \\
\end{array}
\right.$$

Ces hyperparamètres optimaux permettent au modèle d'atteindre :
$$\left \{
\begin{array}{l}
J_{w_{max}} = `r round(BI_fit_rpartcost_best_resultats["Jw"],4)` \\
Spe_{Jw_{max}} = `r round(BI_fit_rpartcost_best_resultats["Spec"],4)` \\
Sen_{Jw_{max}} = `r round(BI_fit_rpartcost_best_resultats["Sens"],4)` \\
\end{array}
\right.$$

\paragraph*{}
Les performances du modèle rpartCost, bien qu'excellentes, ne permettent pas d'atteindre l'index J de Youden requis.
\paragraph*{}
Le dernier modèle d'arbre décisionnel proposé dans notre étude est C5.0 tree (c50tree). Ce modèle ne dispose d'aucun hyperparamètre. \paragraph*{}
Les performances obtenues sont :
$$\left \{
\begin{array}{l}
J_{w} = `r round(BI_fit_c50tree_resultats["Jw"],4)` \\
Spe = `r round(BI_fit_c50tree_resultats["Spec"],4)` \\
Sen = `r round(BI_fit_c50tree_resultats["Sens"],4)` \\
\end{array}
\right.$$
\paragraph*{}
De manière assez surprenante, bien que ne disposant d'aucun hyperparamètre, ce modèle a donné d'excellents résultats sans aucune optimisation nécessaire. Toutefois, le modèle C5.0 tree n'a pas rempli l'objectif posé par le critère $J_w \geq `r Jw_min`$.
\paragraph*{}
Les modèles d'arbres de classification sont particulièrement adaptés aux problèmes de classification avec variables qualitatives et surtout quantitatives, et ont pu s'illustrer dans cette étude en fournissant des résultats très acceptables ($Spe \geq `r round(min(BI_fit_c50tree_resultats["Spec"], 
    BI_fit_rpartcost_resultats[which.max(BI_fit_rpartcost_resultats[,"Jw"]),"Spec"], 
    BI_fit_rpart_cp_resultats[which.max(BI_fit_rpart_cp_resultats[,"Jw"]),"Spec"]),3)`$, $Sen \geq `r round(min(BI_fit_c50tree_resultats["Sens"], 
    BI_fit_rpartcost_resultats[which.max(BI_fit_rpartcost_resultats[,"Jw"]),"Sens"], 
    BI_fit_rpart_cp_resultats[which.max(BI_fit_rpart_cp_resultats[,"Jw"]),"Sens"]),3)`$), mais n'atteignant pas pour autant les exigences imposées par le critère de performance que nous avons défini pour les classifieurs binaires de notre étude.

### Forêts aléatoires
\paragraph*{}
\FloatBarrier
Le premier modèle de forêt aléatoire évalué dans notre étude est le modèle de fougères aléatoires rFerns (*Random Ferns*). Ce modèle ne possède qu'un seul hyperparamètre, la profondeur (*depth*).

```{r, echo = FALSE, fig.height = 3, fig.cap = "Performances du modèle de fougères aléatoires"}
BI_fit_rFerns_depth_graphe + theme_bw()
```

\paragraph*{}
Quoique très efficient sur le plan calculatoire, le modèle de fougères aléatoires a fourni des résultats assez peu satisfaisants, avec :
$$\left \{
\begin{array}{l}
J_{w_{max}} = `r round(max(BI_fit_rFerns_depth_resultats["Jw"]),3)` \\
Spe_{Jw_{max}} = `r round(BI_fit_rFerns_depth_resultats[which.max(BI_fit_rFerns_depth_resultats[,"Jw"]),"Spec"],3)` \\
Sen_{Jw_{max}} = `r round(BI_fit_rFerns_depth_resultats[which.max(BI_fit_rFerns_depth_resultats[,"Jw"]),"Sens"],3)` \\
\end{array}
\right.$$
\FloatBarrier

\paragraph*{}
Le second modèle de forêt aléatoire évalué dans cette étude est Rborist. Deux hyperparamètres régissent ce modèle : le nombre de prédicteurs testés pour une scission (*predFixed*) et le nombre minimal de lignes-références distinctes avant de scinder un n\oe{}ud (*minNode*).

```{r, echo = FALSE, fig.height = 4, fig.cap = "Sensibilité (à gauche) et spécificité (à droite) du modèle Rborist en fonction de ses deux hyperparamètres (interpolation quadratique, points expérimentaux encadrés en noir)"}
plot(ggarrange(
   ncol = 2,
   BI_fit_Rborist_sens_graphe,
   BI_fit_Rborist_spec_graphe
   )
)
```

```{r, echo = FALSE, fig.height = 4, fig.width = 5.2, fig.cap = "Sensibilité (à gauche) et spécificité (à droite) du modèle Rborist en fonction de ses deux hyperparamètres (interpolation quadratique, points expérimentaux encadrés en noir)"}
plot(BI_fit_Rborist_sens_graphe)
```


\paragraph*{}
En posant comme facteurs réduits :

* $X_{1} \in [0;1]$ pour le paramètre *minNode*,
* $X_{2} \in [0;1]$ pour le paramètre *predFixed*,

Nous pouvons modéliser la réponse avec un modèle quadratique
$$ Y = \beta _{0} + \beta _{1}.X_{1} + \beta _{2}.X_{2} + \beta _{12}.X_{1}.X_{2} + \beta _{11}.X_{1}^{2} + \beta _{22}.X_{2}^{2}$$


\paragraph*{}
Ici encore, les étapes d'optimisation ont montré des résultats prometteurs : sur ce modèle également, la spécificité requise a été atteinte sur plusieurs occurences, en utilisant seulement une optimisation monoparamétrique. 
\paragraph*{}
Avec des paramètres optimaux ($predFixed = `r BI_best_Rboristgrid["predFixed"]`$ et $minNode = `r BI_best_Rboristgrid["minNode"]`$), la performance est estimée à :
$$\left \{
\begin{array}{l}
J_{w_{max}} = `r round(BI_fit_Rborist_best_results["Jw"],5)` \\
Spe_{Jw_{max}} = `r round(BI_fit_Rborist_best_results["Spec"],5)` \\
Sen_{Jw_{max}} = `r round(BI_fit_Rborist_best_results["Sens"],5)` \\
\end{array}
\right.$$
\FloatBarrier
Ce modèle s'est comporté de façon excellente, donnant une sensibilité et une spécificité remarquables dans cette phrase d'évaluation.
\paragraph*{}
Le dernier modèle de forêt aléatoire que nous évaluons dans cette étude est le modèle ranger. La documentation de la librairie caret mentionne trois hyperparamètres : la taille minimale de n\oe{}ud (*min.node.size*), le nombre de caractéristiques à séparer à chaque n\oe{}ud (*mtry*) et la règle contrôlant cette séparation (*splitrule*).

```{r, BI-ranger-gini, echo = FALSE, fig.height = 4, fig.cap = "Sensibilité (à gauche) et spécificité (à droite) du modèle Ranger, en fonction des 2 hyperparamètres (algorithme de scission : gini)"}
plot(ggarrange(
   ncol = 2,
   BI_fit_ranger_Gini_sens_graphe,
   BI_fit_ranger_Gini_spec_graphe
   )
)
```

```{r, BI-ranger-ET, echo = FALSE, fig.height = 4, fig.cap = "Sensibilité (à gauche) et spécificité (à droite) du modèle Ranger, en fonction des 2 hyperparamètres (algorithme de scission : extratrees)"}
plot(ggarrange(
   ncol = 2,
   BI_fit_ranger_ET_sens_graphe,
   BI_fit_ranger_ET_spec_graphe
   )
)
```


```{r, BI-ranger-Jw, echo = FALSE, fig.height = 4, fig.cap = "Performances du modèle Ranger en fonction de l'algorithme de scission (extratrees à gauche, gini à droite) et des paramètres réduits : caractéristiques à séparer X1 et taille minimale de noeud X2 (interpolation quadratique, points expérimentaux encadrés en noir)"}
plot(ggarrange(
   ncol = 2,
   BI_fit_ranger_ET_jw_graphe,
   BI_fit_ranger_Gini_jw_graphe
   )
)
```

\FloatBarrier
\paragraph*{}
Nous pouvons proposer pour ce modèle la modélisation quadratique suivante
$$ Y = b_{0} + b_{1}.X_{1} + b_{2}.X_{2} + b_{3}.X_{3} + b_{12}.X_{1}.X_{2} + b_{23}.X_{2}.X_{3} + b_{13}.X_{1}.X_{3} + b_{11}.X_{1}^{2} + b_{22}.X_{2}^{2}$$
Avec Y l'indice J de Youden pondéré, $X_{1}$ le facteur réduit dans l'intervalle [0;1] associé au paramètre de taille minimale de n\oe{}ud (*min.node.size*), $X_{2}$ le facteur réduit associé au paramètre de nombre de caractéristiques à séparer à chaque n\oe{}ud (*mtry*) et $X_{3}$ le facteur régissant la règle de séparation (*splitrule*, la valeur 0 étant attribuée à *gini*, 1 à *extratrees*) et $\beta_{n}$ les coefficients des effets. Le facteur $X_{3}$ n'ayant que deux niveaux, il est évidemment impossible de lui attribuer une composante quadratique.
\paragraph*{}
La modélisation permet de calculer les effets suivants:

$$\left \{
\begin{array}{l}
b_{0} = `r round(BI_mod_ranger_jw$model@trend.coef[1],4)` \\
b_{1} = `r round(BI_mod_ranger_jw$model@trend.coef[2],4)` \\
b_{2} = `r round(BI_mod_ranger_jw$model@trend.coef[3],4)` \\
b_{3} = `r round(BI_mod_ranger_jw$model@trend.coef[4],4)` \\
b_{12} = `r round(BI_mod_ranger_jw$model@trend.coef[7],4)` \\
b_{23} = `r round(BI_mod_ranger_jw$model@trend.coef[8],4)` \\
b_{13} = `r round(BI_mod_ranger_jw$model@trend.coef[9],4)` \\
b_{11} = `r round(BI_mod_ranger_jw$model@trend.coef[5],4)` \\
b_{22} = `r round(BI_mod_ranger_jw$model@trend.coef[6],4)` \\
\end{array}
\right.$$

\paragraph*{}
Le modèle ranger semble déjà, par simple interprétation graphique (voir figures \@ref(fig:BI-ranger-gini), \@ref(fig:BI-ranger-ET) et \@ref(fig:BI-ranger-Jw)), donner de bons résultats sur une très large plage de l'espace expérimental de ses hyperparamètres, même avec un nombre réduit d'arbres ($n=6$). Une optimisation des hyperparamètres grâce à la modélisation quadratique  ($min.node.size = `r BI_modelquad_ranger_top["min.node.size"]`$, $mtry = `r BI_modelquad_ranger_top["mtry"]`$ et $splitrule = `r BI_modelquad_ranger_top["splitrule"]`$) a donné d'excellents résultats :
$$\left \{
\begin{array}{l}
J_{w_{max}} = `r round(BI_fit_ranger_best_resultats["Jw"],5)` \\
Spe_{Jw_{max}} = `r round(BI_fit_ranger_best_resultats["Spec"],5)` \\
Sen_{Jw_{max}} = `r round(BI_fit_ranger_best_resultats["Sens"],5)` \\
\end{array}
\right.$$

\paragraph*{}
Le modèle Ranger a donné des résultats similaires à ceux du modèle Rborist, avec une sensibilité et une spécificité excellentes.
\paragraph*{}
Ces résultats soulignent un fait intéressant : tous les modèles de forêts aléatoires ne sont pas égaux. Notre étude montre une différence considérable en sensibilité et spécificité entre les forêts aléatoires de type rFerns, Ranger et Rborist. Lors des étapes préliminaires de cette étude, d'autres algorithmes de forêts aléatoires se sont également montrés extrêmement inefficients sur le plan calculatoire et ont été écartés pour des raisons pratiques, alors que d'autres se sont avérés sensiblement plus rapides et ont donc pu être retenus pour notre étude.


## Résultats
### Protocole d'évaluation
\paragraph*{}
Les modèles ayant atteint les performances requises ($J_{w} \geq `r Jw_min`$) lors de l'étape d'optimisation ont été choisis pour l'évaluation. Les deux modèles retenus sont deux modèles de type forêt aléatoire :

* Forêt aléatoire avec algorithme de type Ranger,
* Forêt aléatoire avec algorithme de type Rborist.

\paragraph*{}
Tous les modèles ont été entraînés sur le jeu de données d'apprentissage, réglés avec les meilleurs hyperparamètres obtenus par mesure des performances face au jeu de données d'optimisation. Leurs performances face au jeu de données d'évaluation seront analysées avec le même critère que précédemment : $J_{w} \geq `r Jw_min`$

### Performances des modèles de forêts aléatoires  

\FloatBarrier
L'évaluation finale du modèle ranger donne la matrice de confusion suivante :

```{r out.width = "100%", echo = FALSE}
kable(BI_CM_ranger_final$table, caption = "Matrice de confusion du modèle Ranger")
```  

La précision finale est égale à `r round(BI_CM_ranger_final$overall["Accuracy"], 4)`, avec un intervalle de confiance à 95% de [`r round(BI_CM_ranger_final$overall["AccuracyLower"], 4)` ; `r round(BI_CM_ranger_final$overall["AccuracyUpper"], 4)`]. La forêt aléatoire de type Ranger a donné d'excellents résultats, en un temps très contenu (`r BI_temps_ranger` min), preuve de sa grande efficience calculatoire.
\paragraph*{}
La forêt aléatoire de type Rborist a donné des résultats similaires, avec une précision finale égale à `r BI_CM_Rborist_final$overall["Accuracy"]`, avec un intervalle de confiance à 95% de [`r round(BI_CM_Rborist_final$overall["AccuracyLower"], 4)` ; `r round(BI_CM_Rborist_final$overall["AccuracyUpper"], 4)`]. Le modèle Rborist, donnant des résultats sensiblement identiques à Ranger, s'est avéré extrêmement efficient sur le plan calculatoire (`r BI_temps_Rborist` min).

```{r out.width = "100%", echo = FALSE}
kable(BI_RF_resultat, digits = 5, caption = "Performances des modèles Ranger et Rborist (évaluation)")
```

\FloatBarrier

\newpage
# Apprentissage machine et classification multiclasse

*Brouillon, le lot de données utilisé ici est un lot synthétique créé par moi-même (avec algorithme de création fonctionnel), mais à partir des données primaires du Secondary Mushroom Dataset de D.Wagner.*
\paragraph*{}
Etant données des performances qu'ont montré les différents modèles lors de la classification binaire, seuls les modèles basés sur les arbres décisionnels et les forêts aléatoires seront évalués dans cette section.
\FloatBarrier

## Classification par familles

### Modèles d'arbres de décision
\paragraph*{}

\paragraph*{}
Les premiers modèles présentés dans le cadre de notre étude sont deux modèles CART (*Classification And Regression Tree*). Le modèle CART basique (rpart) n'a qu'un hyperparamètre  : *cp* (complexité).

```{r, echo = FALSE, fig.height = 4, fig.cap = "Performances du modèle CART (rpart) en fonction du paramètre de complexité"}
plot(MULFAM_fit_rpart_cp_graphe)
```
*[A CORRIGER]*
Le modèle CART le plus simple donne de très bons résultats globaux, avec ($\kappa_{max} =$ `r round(max(MULFAM_fit_rpart_cp_resultats["Kappa"]),3)` et $Prec._{max} =$ `r round(max(MULFAM_fit_rpart_cp_resultats["Accuracy"]),3)`).

<!-- Le second modèle CART utilisé dans cette étude (rpartCost) associe des hyperparamètres de complexité (*cp*) et de coût (*Cost*). -->
<!-- *NE FONCTIONNE PAS !!! * -->

<!-- ```{r, echo = FALSE, fig.height = 4, fig.cap = "Sensibilité (à gauche) et spécificité (à droite) de rpartCost en fonction de la complexité et du coût (interpolation quadratique, points expérimentaux encadrés en noir)"} -->
<!-- plot(ggarrange( -->
<!--    ncol = 2, -->
<!--    MULFAM_fit_rpartcost_sens_graphe, -->
<!--    MULFAM_fit_rpartcost_spec_graphe -->
<!--    ) -->
<!-- ) -->
<!-- ``` -->

<!-- Les performances maximales sont atteintes pour *cp =* `r #MULFAM_best_rpartcostgrid['cp']` et *Cost = * `r #MULFAM_best_rpartcostgrid['Cost']`. -->

<!-- ```{r, echo = FALSE} -->
<!-- kable(MULFAM_fit_rpartcost_best_results[,c(1:2,4:5)], digits = 5, caption = "Performance du modèle CART (rpartCost)") -->
<!-- ``` -->

<!-- Les performances du modèle rpartCost, quoi qu'excellentes, ne permettent pas d'atteindre la spécificité requise. -->
<!-- \paragraph*{} -->
<!-- Le dernier modèle d'arbre décisionnel est C5.0 tree (c50tree). Ce modèle ne dispose d'aucun hyperparamètre. -->

<!-- ```{r, echo = FALSE} -->
<!-- kable(MULFAM_fit_c50tree_results[,2:4], digits = 5, caption = "Performance du modèle C5.0 tree") -->
<!-- ``` -->

<!-- De manière assez surprenante, bien que ne disposant d'aucun hyperparamètre, ce modèle a donné d'excellents résultats sans optimisation nécessaire, avec de très hautes sensibilité et spécificité. Toutefois, le modèle C5.0 tree n'a pas rempli l'objectif posé par le critère $Spec = 1$. -->

### Forêts aléatoires

\paragraph*{}
Le premier modèle de forêt aléatoire évalué dans cette partie est le modèle ranger, qui possède trois hyperparamètres : la taille minimale de n\oe{}ud (*min.node.size*), le nombre de caractéristiques à séparer à chaque n\oe{}ud (*mtry*) et la règle contrôlant cette séparation (*splitrule*).

```{r, echo = FALSE, fig.height = 4, fig.cap = "Performances du modèle Ranger, en fonction de ses 2 hyperparamètres (algorithme de scission : gini à gauche, extratrees à droite)"}
plot(ggarrange(
   ncol = 2,
   MULFAM_fit_ranger_Gini_kappa_graphe,
   MULFAM_fit_ranger_ET_kappa_graphe
   )
)
```

Les étapes préliminaires de l'optimisation du modèle se sont avérées prometteuses : même avec un très faible nombre d'arbres (*n* = 6), la spécificité requise était déjà atteinte à plusieurs reprises lors de l'optimisation uniparamètre. L'optimisation de la totalité des hyperparamètres (*min.node.size* = `r MULFAM_best_rangergrid$min.node.size`, *mtry* = `r MULFAM_best_rangergrid$mtry` et *splitrule* = `r MULFAM_best_rangergrid$splitrule`) a donné d'excellents résultats.

```{r, echo = FALSE}
kable(MULFAM_fit_ranger_best_resultats[c(1,2,3,7,8)], digits = 5, caption = "Performances du modèle Ranger (hyperparamètres optimaux)")
```

Ce modèle s'est comporté de façon excellente, donnant une spécificité et une sensibilité remarquables dans cette phrase d'évaluation.
\paragraph*{}
Le dernier modèle de forêt aléatoire est Rborist. Deux hyperparamètres régissent ce modèle : le nombre de prédicteurs testés pour une scission (*predFixed*) et le nombre minimal de lignes-références distinctes avant de scinder un n\oe{}ud (*minNode*).

```{r, echo = FALSE, fig.height = 4, fig.cap = "Performances du modèle Rborist en fonction de ses deux hyperparamètres (interpolation quadratique, points expérimentaux encadrés en noir)"}
plot(MULFAM_fit_Rborist_kappa_graphe)
```

\paragraph*{}
Ici encore, les étapes d'optimisation ont montré des résultats prometteurs : sur ce modèle également, la spécificité requise a été atteintes sur plusieurs occurences, en utilisant seulement une optimisation monoparamétrique.
\paragraph*{}
Avec des paramètres optimaux (*predFixed* = `r MULFAM_best_Rboristgrid$predFixed` et *minNode* = `r MULFAM_best_Rboristgrid$minNode`), la performance est estimée à :
\FloatBarrier

```{r, echo = FALSE}
kable(MULFAM_fit_Rborist_best_resultats[c(1,2,6,7)], digits = 5, caption = "Performances du modèle Rborist (hyperparamètres optimaux)")
```
\FloatBarrier
\paragraph*{}
Le modèle Rborist a donné des résultats similaires à ceux du modèle Ranger, avec une sensibilité et une spécificité excellentes.
\paragraph*{}
Ces résultats soulignent un fait intéressant : tous les modèles de forêts aléatoires ne sont pas égaux. Notre étude montre une différence considérable en sensibilité et spécificité entre les forêts aléatoires de type rFerns, Ranger et Rborist. Lors des étapes préliminaires de cette étude, d'autres modèles de forêts aléatoires disponibles dans la librairie caret se sont également montrés extrêmement inefficients sur le plan calculatoire, alors que d'autres se sont avérés sensiblement plus rapides.

### Résultats
Les critères et le protocole de l'évaluation sont les mêmes que ceux évoqués précédemment.

\FloatBarrier
L'évaluation finale du modèle ranger donne la matrice de confusion suivante :

```{r out.width = "100%", echo = FALSE}
kable(MULFAM_CM_ranger_final$table, caption = "Matrice de confusion du modèle Ranger")
```

La précision finale est égale à `r round(MULFAM_CM_ranger_final$overall["Accuracy"], 4)`, avec un intervalle de confiance à 95% de [`r round(MULFAM_CM_ranger_final$overall["AccuracyLower"], 4)` ; `r round(MULFAM_CM_ranger_final$overall["AccuracyUpper"], 4)`]. La forêt aléatoire de type Ranger a donné d'excellents résultats, en un temps très contenu (`r MULFAM_temps_ranger` min), preuve de sa grande efficience calculatoire.
\paragraph*{}
La forêt aléatoire de type Rborist a donné des résultats similaires, avec une précision finale égale à `r MULFAM_CM_Rborist_final$overall["Accuracy"]`, avec un intervalle de confiance à 95% de [`r round(MULFAM_CM_Rborist_final$overall["AccuracyLower"], 4)` ; `r round(MULFAM_CM_Rborist_final$overall["AccuracyUpper"], 4)`]. Le modèle Rborist, donnant des résultats sensiblement identiques à Ranger, s'est avéré extrêmement efficient sur le plan calculatoire (`r MULFAM_temps_Rborist` min).

```{r out.width = "100%", echo = FALSE}
kable(MULFAM_RF_resultat, digits = 5, caption = "Performances des modèles Ranger et Rborist (évaluation)")
```

\FloatBarrier

## Classification par espèce

\newpage
# Robustesse de la classification
texte

\FloatBarrier
\newpage

# Références bibliographiques
<div id="refs"></div>

\newpage
# (APPENDIX) Appendix {-} 

# Annexe : développement d'un algorithme de génération de lot synthétique

\paragraph*{}
*Plus de détails concrets sur la méthode utilisée en pratique, avec extraits de code...*
\paragraph*{}
*Pour l'instant, l'algorithme est écrit et fonctionne, à partir des données primaires du Secondary Dataset de Dennis Wagner. C'est cet algorithme qui a servi à créer le lot de données de la classification multiclasse.*
\paragraph*{}
*Pour avoir mes propres lots de données, il ne me reste plus qu'à avoir mes propres données primaires, c'est à dire entrer manuellement les caractéristiques clés de mes 400+ champignons, un par un...*
\paragraph*{} 
La seule bibliothèque utilisée lors de la création du lot de données synthétique est le *tidyverse*[@R-tidyverse], collection de bibliothèques spécialisées dans le domaine de la *data science* et notamment dédiées au traitement, au nettoyage et à la visualisation de données.

```{r, eval = FALSE}
library(tidyverse)
```

Nous chargeons ensuite le fichier zip, incluant le fichier csv contenant les caractéristiques typiques des macromycètes (type de sporophore, dimensions maximales du stipe, du chapeau, type de lames, couleur de sporée, etc.), qui est lu et attribué à un *dataframe*. Les lignes commentées correspondent à l'utilisation d'un fichier identique hébergé à distance sur un dépôt GitHub.

```{r, eval = FALSE}
fichier_data <- tempfile()
#URL <- "https://github.com/EKRihani/mushrooms/raw/master/MushroomDataset.zip"
#download.file(URL, fichier_data)
fichier_data <- "~/projects/champis/MushroomDataset.zip"       # Fichier local
fichier_data <- unzip(fichier_data, "MushroomDataset/primary_data.csv")
data_champis <- read.csv(fichier_data, 
                         header = TRUE, 
                         sep = ";", 
                         stringsAsFactors = TRUE)
```

etc etc.

\newpage

# Annexe : outils d'analyse exploratoire des données (EDA)

*Code EDA...*

\newpage


# Annexe : développement des algorithmes d'apprentissage machine

*Le gros du code...*

\paragraph*{}
Nous détaillerons ici principalement les algorithmes utilisés pour le classifieur binaire. Les particularités d'intérêt des classifieurs multiples seront évoquées brièvement lors des développements de cette section.

## Initialisation

\paragraph*{}
Les bibliothèques utilisées lors des étapes d'apprentissage machine sont :

* tidyverse[@R-tidyverse], collection de bibliothèques spécialisées dans le domaine de la *data science*,
* DiceDesign[@R-DiceDesign], bibliothèque spécialisée dans la création de plans d'expériences hypercubiques,
* DiceEval[@R-DiceEval], bibliothèque spécialisée dans la modélisation des résultats de plans d'expériences hypercubiques,
* caret[@R-caret], collection d'outils dédiés à l'apprentissage machine.

```{r, eval = FALSE}
library(tidyverse)
library(DiceDesign)
library(DiceEval)
library(caret)
```

\paragraph*{}
Le chargement des données s'effectue de la même façon que lors des sections précédentes. Dans le cadre d'une classification binaire, nous attribuons arbitrairement, à l'aide de la fonction *relevel*, la valeur positive à la classe *"toxique"*.

```{r, eval = FALSE}
fichier_data <- tempfile()
fichier_data <- "~/projects/champis/MushroomDataset.zip"
fichier_data <- unzip(fichier_data, "MushroomDataset/secondary_data.csv")
dataset <- read.csv(fichier_data, 
                    header = TRUE, 
                    sep = ";", 
                    stringsAsFactors = TRUE)
dataset$class <- relevel(dataset$class, ref = "toxique")
```

## Création des jeux d'entraînement, optimisation et évaluation

La création du jeu d'évaluation s'effectue par dichotomie du jeu de données avec un ratio 92/8.

```{r, eval = FALSE}
set.seed(7)
split1 <- 0.08
index1 <- createDataPartition(y = dataset$cap.diameter, 
                              times = 1, 
                              p = split1, 
                              list = FALSE)
BI_lot_appr_opti <- dataset[-index1,]
BI_lot_evaluation <- dataset[index1,]
```
