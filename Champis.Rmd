---
#title: "Application de modèles d'Intelligence Artificielle à la classification des macromycètes"
#author: "Emir Kaïs RIHANI"
#date: "`r format(Sys.time(), '%d %B, %Y')`"
lang: fr
geometry: "left=2.5cm,right=2.5cm,top=1.5cm,bottom=2cm"        # Imposé par la fac
fontsize: 12pt          # Imposé par la fac
output: 
  bookdown::pdf_document2: 
    number_sections: yes
    extra_dependencies: ["float", "placeins", "pdfpages", "svg", "amssymb", "sfmath" ]
    toc: yes
    toc_depth: 3
    includes:
      before_body: couverture.tex
      after_body: quatrieme.tex
header-includes:
   - \renewcommand{\familydefault}{\sfdefault}   # Police sans serif sur tout le doc (imposé par la fac)
   - \renewcommand{\thefootnote}{\alph{footnote}}      # Pieds de page en lettres minuscules (autres: Roman, Alph)
#  - \usepackage{sansmathaccent}    # Pour tidles/chapeaux mal alignés avec maths sans accent...
   - \linespread{1.15}
indent: true
bibliography: [packages.bib,Champis.bib]
csl: https://www.zotero.org/styles/vancouver-superscript
---

```{r setup, include = FALSE, warning=FALSE}
load("EKR-Champis-CodeSourceBi-Light.RData")   # Chargement des données du code source (graphiques)
load("EKR-Champis-Valeurs.RData")      # Chargement des valeurs diverses utilisées/calculées dans la thèse
load("EKR-Champis-Intro-Light.RData")      # Chargement des résultats INTRO
load("EKR-Champis-EDA.RData")            # Chargement des résultats ANALYSE EXPLORATOIRE
load("EKR-Champis-AnalyseBi-Light.RData")       # Chargement des résultats CLASSIFICATION BINAIRE
load("EKR-Champis-AnalyseMultiFam-Light.RData")       # Chargement des résultats CLASSIF PAR FAMILLES
load("EKR-Champis-AnalyseMultiEsp-Light.RData")       # Chargement des résultats CLASSIF PAR ESPECES
load("EKR-Champis-CodeSourceBi-Light.RData")   # Chargement des données du code source (graphiques)

library(ggpubr)   # Combiner graphes (ggarrange)
library(kableExtra)  # BLOQUER ces %#@$§£%#@$§£ de tables en float
library(rmarkdown)
library(knitr)
library(tidyverse)
library(bookdown)
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, fig.pos = "!H")
knitr::write_bib(c("tidyverse", "microbenchmark",  "caret",  "rmarkdown", "GGally", "plyr", "MASS", "mda", "rpart", "C50", "party", "ranger", "Rborist", "e1071", "rFerns", "knitr", "ggpubr", "SPlit", "DiceDesign", "DiceEval", "DiceKriging", "bookdown", "twinning"), "packages.bib")
```
\pagestyle{plain}

\newpage
# Liste des abréviations

\begingroup
\flushleft
AI : \emph{Artificial Intelligence} (intelligence artificielle)

AUC : *Area Under Curve* (aire sous la courbe)

CART : *Classification And Regression Tree* (arbre de classification et de régression)

CSV : *Comma Separated Values* ([fichier de] valeurs séparées par des virgules)

DOE : *Design of Experiments* (plan d'expériences)

EDA : *Exploratory Data Analysis* (analyse exploratoire des données)

ESE : *Enhanced Stochastic Evolutionnary* ([algorithme] évolutionnaire stochastique amélioré)

GAM : *Generalized Additive Model* (modèle additif généralisé)

IA : Intelligence Artificielle  

LDA : *Linear Discriminant Analysis* (analyse linéaire discriminante)

LHS : *Latin Hypercube Sample* (échantillonnage par hypercube latin)

LOESS : *LOcally Estimated Scatterplot Smoothing* (régression locale)

ML : *Machine Learning* (apprentissage machine)

NOLH : *Nearly Orthogonal Latin Hypercube* (hypercube latin quasi orthogonal)

PDA : *Penalized Discriminant Analysis* (analyse discriminante pénalisée)

RF : *Random Forest* (forêt aléatoire)

ROC : *Receiver Operating Characteristic* (fonction d'efficacité du récepteur)

VCS : *Version Control System* (logiciel de contrôle des versions)

XGB : *eXtreme Gradient Boosting*

\endflushleft
\endgroup

\newpage
# Introduction
## Propos liminaire
\paragraph*{}
L'identification des macromycètes est un sujet difficile, ne devant évidemment pas être pris à la légère. Les espèces rencontrées varient considérablement d'un écosystème à un autre, d'un continent à un autre, et aucun lot de données ni ouvrage sur les champignons ne saurait couvrir toute la diversité du monde fongique.
\paragraph*{}
Le lot de données mycologiques constitué dans cette étude, bien que constituant l'un des lots en libre accès les plus complets du domaine de la *data science*, n'est bien entendu pas exhaustif.
\paragraph*{}
Ce lot se concentre exclusivement sur les champignons habituellement rencontrés au Nord de la France. Nombre de variétés, parfois très connues, ne sont donc pas présentes, parmi lesquelles nous pouvons par exemple citer les représentants du genre  *psilocybe*, connus pour leurs propriétés psychédéliques. Certains critères pourront également varier de manière considérable selon le stade de maturité du champignon : alors que les chapeaux vert-olive de l'*Amanita phalloides* mature sont faciles à reconnaître, les spécimens jeunes sont blancs et pourraient facilement être confondus avec des espèces comestibles (par exemple du genre *Agaricus*).
\paragraph*{}
L'ingestion de certains de ces champignons est *mortelle*, même en faible quantité. Le diagnostic de l'intoxication fongique peut être difficile, et parfois trop tardif pour un traitement efficace. Des composés toxiques tels que les amanitines ne sont pas altérés ou détruits par cuisson ou congélation, et seront absorbés par l'intestin, avant de passer dans la circulation sanguine afin d'être filtrés par le foie, détruisant les cellules hépatiques, puis excrétées dans l'intestin, réabsorbées, refiltrées... chaque passe détruisant les cellules hépatiques ayant survécu à la précédente, dans un cycle connu sous le nom de réabsorption hépato-entérique.
\paragraph*{}
Il ne faut jamais, *sous aucune circonstance*, utiliser les lots de données générés par des méthodes similaires à celles de notre études dans le but de déterminer si un champignon est comestible ou non.

## But de l'étude
\paragraph*{}
L'identification des plantes et champignons est un problème de classification classique, qui est usuellement effectué de façon manuelle, à l'aide de clés d'identification. La plupart de ces clés sont basées sur un processus utilisant des arbres décisionnels, ce qui pourrait sembler logique car rappelant la logique en arbre de l'évolution. Quoique séduisant, cet argument rencontre certaines limites :
\paragraph*{}
La première limite est le nombre de chaînons manquants. Certaines espèces sont évidemment éteintes, ce qui signifie que certaines branches et n\oe{}uds de l'arbre phylogénétique seront manquants, ce qui peut compliquer l'analyse quand deux espèces apparentées ont un nombre élevé de chaînons et n\oe{}uds communs manquants. Certaines similarités entre espèces peuvent également ne pas être identifiables de façon macroscopique.
\paragraph*{}
La seconde limite, plus profonde, est la logique inhérente au processus évolutionnaire. Deux phénomènes antagonistes sont en jeu : convergence et divergence évolutives. Ces deux phénomènes sont liés à la nécessaire adaptation des espèces à leurs environnements. La divergence évolutive explique par exemple la diversité des mammifères : les chauves-souris, baleines et chevaux sont apparentés, mais ont des aspects très dissemblables en raison de leur adaptation à des environnements très différents. D'un autre côté, la convergence évolutive explique la similarité entre l'aile de la chauve-souris et celle de l'abeille. Toutefois, malgré leur apparente dissimilarité, l'aile de la chauve-souris est plus proche de la main humaine ou de la nageoire de la baleine que de l'aile de l'abeille. La façon la plus fiable pour évaluer le processus évolutionnaire et trouver les liens phylogénétiques de la manière la plus précise possible est l'analyse des génomes : les caractéristiques visibles peuvent être trompeuses. Malheureusement, ces caractéristiques sont souvent les seules aisément identifiables.
\paragraph*{}
Le troisième problème est le critère principal de la classification. Ce critère peut être lié ou non au processus évolutionnaire ou aux critères visible, surtout si ce critère principal est vague. Le critère de comestibilité ou de non-comestibilité retenu pour les lots de données mycologiques usuellement utilisés en *data science* souffre de ce problème : il est essentiellement centré sur la toxicité contre les humains, or de nombreux mécanismes de toxicité peuvent exister, et une toxicité ou non-toxicité d'un métabolite fongique ou végétal peut être liée à des variations métaboliques très ténues entre une espèce et une autre.
\paragraph*{}
Pour ces raisons parmi d'autres, la logique arborescente, bien qu'utilisée habituellement dans l'identification des champignons et des plantes, et souvent justifiée par la nature arborescente du processus évolutionnaire, pourrait ne pas nécessairement être l'approche optimale à la classification des espèces basée sur des critères macroscopiques. Le but de cette étude est notamment de déployer des algorithmes d'apprentissage machine afin d'effectuer cette tâche de classification basée sur des indices visuels limités, et d'évaluer les performances relatives de différentes stratégies de classification.

## État de l'art des lots de données mycologiques
Le tout premier lot de données mycologiques en libre accès mentionné en data science est probablement le *Mushroom Dataset* créé par Jeff Schlimmer en 1987.[@schlimmer_mushroom_1987]
\paragraph*{}
Un lot de données plus conséquent a été publié par Dennis Wagner en 2021[@wagner_mushroom_2021] et mis en libre accès sous le nom de *Secondary Mushroom Dataset*.

\newpage
# Création du lot de données
## Configuration matérielle et logicielle
\paragraph*{}
\FloatBarrier
Le code d'apprentissage machine, les méthodes d'évaluation, ainsi que cette thèse ont été rédigés sur l'équipement suivant :

* CPU : AMD Ryzen 5 5600G
* RAM : 2x16 Go DDR4-3200
* SSD : Crucial P5 M2 NVMe
* OS : Xubuntu Linux 22.04.2 LTS
* R : version `r paste0(R.version$major, ".", R.version$minor, " (", R.version$year, ")")`
* IDE : RStudio version `r paste0(rstudioapi::versionInfo()$version, ', "', rstudioapi::versionInfo()$release_name, '"')`
* VCS : `r system("git --version", intern = TRUE)`
* Librairies : tidyverse[@R-tidyverse] (v`r packageVersion("tidyverse")`), microbenchmark[@R-microbenchmark] (v`r packageVersion("microbenchmark")`), MASS[@R-MASS] (v`r packageVersion("MASS")`), caret[@R-caret] (v`r packageVersion("caret")`), ?GGally?[@R-GGally] (v`r packageVersion("GGally")`), twinning[@R-twinning] (v`r packageVersion("twinning")`), rpart[@R-rpart] (v`r packageVersion("rpart")`), ?C50?[@R-C50] (v`r packageVersion("C50")`), party[@R-party] (v`r packageVersion("party")`), ranger[@R-ranger] (v`r packageVersion("ranger")`), rFerns[@R-rFerns] (v`r packageVersion("rFerns")`), Rborist[@R-Rborist] (v`r packageVersion("Rborist")`),  rmarkdown[@R-rmarkdown] (v`r packageVersion("rmarkdown")`), knitr[@R-knitr] (v`r packageVersion("knitr")`), ggpubr[@R-ggpubr] (v`r packageVersion("ggpubr")`), DiceDesign[@R-DiceDesign] (v`r packageVersion("DiceDesign")`), DiceEval[@R-DiceEval] (v`r packageVersion("DiceEval")`), bookdown[@R-bookdown] (v`r packageVersion("bookdown")`).

\FloatBarrier
## Principes de conception d'un lot de données synthétiques
### Principes généraux{#chapitre:lotsynth}
\paragraph*{}
Un lot de données synthétiques est un lot de données généré par un algorithme, par opposition aux lots de données issus d'une collecte effectuée en "vie réelle". 
\paragraph*{}
\FloatBarrier
Trois stratégies sont usuellement utilisées :

* Données factices (*dummy data*) : l'ensemble des données est généré aléatoirement.
* Données générées à partir de règles (*rule-based data*) : l'ensemble des données est généré suivant des lois définies au préalable (distribution, valeurs moyennes, minimales, maximales...)
* Données générées par intelligence artificielle (*AI generated*) : l'ensemble des données est généré suivant des lois extraites par l'IA suite à l'analyse d'un échantillon de données obtenues en "vie réelle".

\FloatBarrier
\paragraph*{}
Les données générées par ces stratégies peuvent être de type variés, que nous pouvons grossièrement regrouper en données alphanumériques (quantitatives et qualitatives), en séries temporelles, et en données d'imagerie.
\paragraph*{}
Pour des raisons pratiques et de maturité des technologies disponibles à l'heure actuelle, la méthode retenue pour créer le lot de données exploité dans notre étude sera la génération de données alphanumériques à partir de règles, extraites d'ouvrages mycologiques de référence.[@courtecuisse_cle_1986; @courtecuisse_champignons_2013; @courtecuisse_initiation_2020]

### Principes de génération des paramètres quantitatifs
\paragraph*{}
\FloatBarrier
Dans le cadre de cette étude, les variables quantitatives générées aléatoirement sont :

* La longueur du stipe $L_{S}$,
* Le diamètre du stipe $D_{S}$,
* Le diamètre du chapeau $D_{C}$.

\FloatBarrier
\paragraph*{}
En première approximation, nous pouvons considérer que toutes ces valeurs sont intrinsèquement liées à la croissance du champignon. Ces trois variables peuvent, dans l'absolu, être susceptibles de varier indépendamment des autres au cours de la croissance du champignon, les variables $L_{S}$, $D_{S}$ et $D_{C}$ obéissant alors aux lois suivantes :

$$\left \{
\begin{array}{l}
L_{S} = L_{S_{max}}.F_{Ls} \\
D_{S} = D_{S_{max}}.F_{Ds} \\
D_{C} = D_{C_{max}}.F_{Dc} \\
\end{array}
\right.$$

Avec :

* $L_{S_{max}}$, $D_{S_{max}}$ et $D_{C_{max}}$ les valeurs maximales de longueur de stipe, diamètre du stipe et diamètre de chapeau de chaque variété de champignon, extraites de la littérature, 
* $F_{Ls}$, $F_{Ds}$, $F_{Dc}$ des variables générées aléatoirement dans l'intervalle $\left] 0 ; 1 \right]$, et représentatives de la croissance du spécimen.

\paragraph*{}
Toutefois, nos recherches bibliographiques concernant la cinétique de croissance des sporophores n'ont pas permis de distinguer de différences de la cinétique de croissance de chacun de ces trois paramètres. Nous supposerons donc, en première approximation, que la croissance du stipe en longueur et en largeur, ainsi que la croissance du chapeau s'effectuent à des vitesses identiques. Nous obtenons par conséquent :

$$F_{Ls} = F_{Ds} = F_{Dc} = F_{T}$$
Avec $F_{T}$ un facteur représentatif de la taille globale de chaque spécimen, généré aléatoirement.

\paragraph*{}
Ainsi, le problème de génération de nos trois variables aléatoires se simplifie en un problème de génération d'une seule variable aléatoire : le facteur de taille de chaque spécimen. Un certain nombre de distributions d'intérêt sont susceptibles d'être utilisées afin de générer des facteurs de taille $F_{T}$ aléatoires, il convient donc de définir le cahier des charges de la distribution la plus adaptée au sujet de cette étude.
\paragraph*{}
Les critères de sélection retenus afin de choisir la loi la plus appropriée sont :

* Efficience calculatoire,
* Distribution continue,
* Distribution bornée, ou aisément normalisable sur un intervalle $\left[ 0 ; 1 \right]$,
* Distribution asymétrique.

\FloatBarrier
\paragraph*{}
Le premier critère n'est, en pratique, pas un facteur limitant, les temps de calcul pour la génération d'un nombre de facteurs de taille $F_{T}$ suffisant étant typiquement inférieurs à `r chrono_typique` ms (pour `r n_chrono` facteurs générés) avec la plupart des distributions d'intérêt (voir figure \@ref(fig:Lots-Chrono)).


```{r Lots-Chrono, echo = FALSE, fig.height = 4, fig.cap = paste0("Temps de calcul des principales distributions d'intérêt pour ", n_chrono, " facteurs, (", fois_chrono, " iter.)")}
plot(chrono_distrib)
```

\paragraph*{}
Les critères de continuité et de normalité n'appellent que peu de commentaires. Ces critères permettent simplement de garantir la possibilité d'une infinité de valeurs dimensionnelles, dans l'intervalle considéré. Le critère de continuité proscrit toutefois l'utilisation de lois de distributions discrètes telles que la loi binomiale ou la loi de Poisson, et celui de normalité écarte des distributions telles que la loi de Weibull, dont la normalisation est parfois délicate.
\paragraph*{}
\FloatBarrier
Le critère d'asymétrie est un critère permettant de tenir compte des différents paramètres pouvant impacter la distribution de taille des spécimens prélevés, parmi lesquels :

* Différences de cinétique de croissance d'une famille à une autre,
* Particularités de la croissance fongique, notamment par la croissance hyphale, [@money_insights_2008; @porter_hyphal_2022]
* Probabilité de prélèvement variable selon la taille du spécimen (par difficulté de détection, considérations éthiques, intérêt mycologique ou gastronomique...).

\FloatBarrier
\paragraph*{}
Le premier paramètre évoqué précédemment n'a pu être exploité dans le cadre de cette étude en raison du manque de données concernant les cinétiques relatives de croissance des sporophores des différentes familles de macromycètes. Le modèle que nous proposons permet toutefois des développements ultérieurs dans ce domaine.
\paragraph*{}
Les deux derniers paramètres permettent de supposer que la distribution de taille des spécimens d'une même espèce à l'issue d'une récolte en vie réelle ne sera pas symétrique, d'une part en raison de la rapidité de la croissance fongique, et d'autre part parce que le prélèvement se fera préférentiellement en épargnant les spécimens de petite taille.
\paragraph*{}
Ainsi, la génération de la variable aléatoire $F_{T}$ obéira idéalement à une loi de distribution asymétrique vers la droite ($G_{1} < 0$). Ce critère d'asymétrie écarte par conséquent les lois de distribution symétriques telles que la loi normale ou la loi uniforme.
\paragraph*{}

```{r Lots-DistribSym, echo = FALSE, fig.height = 3, fig.cap = "Exemples de distributions de la loi uniforme (à gauche), binomiale (au centre) et normale (à droite)"}
plot(ggarrange(
   ncol = 3,
   distrib_uniforme + ylab("Nombre"),
   distrib_binomiale,
   distrib_normale))
```

```{r Lots-DistribAsym, echo = FALSE, fig.height = 3, fig.cap = "Exemples de distributions de la loi de Poisson (à gauche), de Weibull (au centre) et bêta (à droite)"}
plot(ggarrange(
   ncol = 3,
   distrib_poisson + ylab("Nombre"),
   distrib_weibull,
   distrib_beta
   )
)
```

\paragraph*{}
En raison des contraintes imposées précédemment ainsi que de par sa grande polyvalence,[@johnson_continuous_1995] la loi retenue dans le cadre de cette étude pour la génération des facteurs de taille aléatoires ($F_{T}$) est une loi bêta non-centrale, définie comme la fonction de distribution de[@johnson_continuous_1995;@r_core_team_r_2021] :
$$ X = \frac{\chi^{2}_{2 \alpha} (\lambda)} {\chi^{2}_{2 \alpha} (\lambda) + \chi^{2}_{2 \beta}}$$

Avec, comme paramètres définis empiriquement pour cette étude : 
$$\left \{
\begin{array}{l c c}
\alpha = 6 \, F_{c} & & (shape1)\\
\beta = 4  & & (shape2)\\
\lambda = F_{c}/2  & & (ncp)\\
\end{array}
\right.$$

$F_{c}$ est ici défini comme un facteur de croissance permettant de rendre compte de la cinétique de croissance de chaque variété d'une part, et du prélèvement préférentiel des spécimens de plus grande taille d'autre part, comme l'illustre la figure \@ref(fig:Lots-LoisBeta).

```{r Lots-LoisBeta, echo = FALSE, fig.height = 4, fig.cap = "Distribution de différentes lois bêta, en fonction du facteur de croissance Fc"}
plot(lois_beta)
```

Le modèle défini à ce stade impose une stricte proportionnalité entre diamètre du chapeau $D_{c}$, diamètre du stipe $D_{s}$ et longueur du stipe $L_{s}$.
\paragraph*{}
Dans un souci de réalisme, il apparaît souhaitable d'améliorer ce modèle mathématique en y ajoutant un facteur de dispersion, afin de proposer le modèle suivant :

$$\left \{
\begin{array}{ll} 
L_{S} = L_{Smax}.F_{T}.\delta_{Ls} & ~~~~avec~~ \delta_{Ls} \sim \mathcal{N}(\mu = 1 ; \sigma = 0.05) \\
D_{S} = D_{Smax}.F_{T}.\delta_{Ds} & ~~~~avec~~ \delta_{Ds} \sim \mathcal{N}(\mu = 1 ; \sigma = 0.05) \\
D_{C} = D_{Cmax}.F_{T}.\delta_{Dc} & ~~~~avec~~ \delta_{Dc} \sim \mathcal{N}(\mu = 1 ; \sigma = 0.05) \\
\end{array}
\right.$$

\paragraph*{}
L'impact de cette dispersion sur la distribution des paramètres de taille $L_{S}$, $D_{S}$ et $D_{C}$ est illustré par les figures \@ref(fig:Lots-Dispersion2D) et  \@ref(fig:Lots-DispersionDensite).
\paragraph*{}

```{r Lots-Dispersion2D, echo = FALSE, fig.height = 3, dev = "png", dpi = 300, fig.cap = paste0("Nuages de points de 2 paramètres de taille (Ls et Dc), sans dispersion (à gauche) et avec dispersion (à droite), pour ", n_reduit, " champignons")}
plot(ggarrange(
   ncol = 2,
   nuage_sansdispersion,
   nuage_avecdispersion
   )
)
```


\paragraph*{}
La dispersion ainsi créée permet ainsi de créer de légères variations des rapports entre les différents paramètres de taille, tout en se situant à proximité de la première bissectrice et majoritairement dans la zone 50-90% de la taille maximale (voir figure \@ref(fig:Lots-DispersionDensite)). Cette dispersion autorise par ailleurs l'existence d'une faible proportion de spécimens dépassant les valeurs dimensionnelles maximales généralement admises par la littérature.
<!-- [FAIRE CALCULS SUR R POUR RELIER AUTOMATIQUEMENT AUX CHIFFRES ?] -->


```{r Lots-DispersionDensite, echo = FALSE, fig.height = 4, fig.cap = "Diagramme de densité de 2 paramètres de taille, avec dispersion"}
plot(densite2d)
```

\paragraph*{}
Une simulation de Monte Carlo unidimensionnelle effectuée sur `r INTRO_n_champis` spécimens nous permet ainsi d’évaluer la proportion de spécimens "hors normes" dépassant la valeur dimensionnelle maximale à environ `r INTRO_taux_gros_diam` % (cf. figure \@ref(fig:HorsNormes)). La même simulation nous permet d'évaluer que la proportion de spécimens "exceptionnels", dépassant de plus de 10% cette valeur maximale, sera quant à elle inférieure à `r INTRO_taux_supergros_diam` %.
\paragraph*{}

```{r HorsNormes, echo = FALSE, fig.height = 3, fig.cap = paste0("Distribution du diamètre de stipe Ds, pour Dsmax = ", Chap.Diam)}
plot(distrib_diametre)
```

\FloatBarrier

### Principes de génération des paramètres qualitatifs
\paragraph*{}
La génération des paramètres qualitatifs, tels que la couleur des spores ou le type d'hyménophore, est nettement moins complexe que celle des paramètres quantitatifs.
\paragraph*{}
L'ensemble des valeurs quantitatives possibles pour un critère et pour une variété donnée est insérée dans un vecteur de valeurs, et une valeur sera tirée aléatoirement parmi celles contenues dans ce vecteur afin de caractériser le paramètre en question pour chaque spécimen.
\paragraph*{}

\newpage
\FloatBarrier

# Principes de l'apprentissage machine
## Jeux de données {#chapitre:split}

Les jeux de données dédiés à l'apprentissage machine sont tous construits sur la base de couples données-résultats. Selon l'étape de l'apprentissage machine, le résultat peut être fourni à la machine ou lui être caché, le but étant dans le premier cas de permettre à la machine d'effectuer son apprentissage, et dans le second cas d'évaluer les performances de la prédiction par rapport au résultat réel.
\paragraph*{}
Le déroulement de l'apprentissage machine se décompose conceptuellement en trois étapes principales, mettant en jeu trois lots de données distincts :

1. Entraînement : le modèle d'apprentissage est exposé à un *jeu de données d'entraînement* (*training data set*), censé être représentatif (cf. section \@ref(chapitre:lotsynth)) des données auquel le modèle sera exposé en utilisation réelle. Cette phase est la phase d'apprentissage du modèle.
2. Validation : le modèle d'apprentissage machine élaboré à l'étape précédente, est ici soumis à un *jeu de données de validation* (*validation data set*) et tentera d'apporter des prédictions quant à une variable d'intérêt considérée comme le résultat (ex: comestibilité, espèce...), sur la base des informations contenues dans le lot de données de validation (ex : dimensions, couleurs, morphologie du champignon...). Ces prédictions sont comparées avec les valeurs réelles (ex : comestibilité, espèce...), ce qui permet d'évaluer les performances prédictives du modèle proposé en fonction des indicateurs retenus (spécificité, sensibilité, F1-score, temps de calcul...). Les étapes d'apprentissage et de validation sont répétées de manière itérative en explorant l'ensemble des paramètres de configuration du modèle (hyperparamètres) à fins d'optimisation.
3. Test : les performances du meilleur modèle (avec hyperparamètres optimaux), sélectionné à l'issue de l'étape de validation, sont évaluées vis-à-vis d'un *jeu de données test* (*test* ou *holdout data set*).

\paragraph*{}
La séparation entre étapes d'optimisation et de test peut sembler artificielle. Le problème est en partie lié à un flou sémantique : si l'étape initiale d'entraînement ou d'apprentissage ne pose que peu de problèmes conceptuels, l'étape intermédiaire, dite de *validation* correspond en réalité à une étape d'*optimisation* du modèle et de ses hyperparamètres. Par ailleurs, l'étape finale de *test* sera parfois qualifiée d'étape de *validation* dans la littérature, ce qui peut entretenir la confusion entre ces étapes.[@brownlee_what_2017]
\paragraph*{}
Une distinction sémantique plus nette entre phases d'*apprentissage*, d'*optimisation* et de *test* permet de comprendre plus aisément le fondement épistémologique de cette dernière phase pouvant parfois sembler superflue : l'optimisation effectuée lors de l'étape de validation aboutit à un modèle potentiellement biaisé (problème dit d'*overfitting*) vis-à-vis du jeu de données utilisé comme référence lors de cette étape. Seule une exposition du modèle à des données n'ayant jamais servi à son entraînement ou son optimisation permettra réellement d'évaluer avec précision son caractère prédictif, donc sa validité.
\paragraph*{}
Dans un souci de clarté, nous utiliserons les termes de lots et de phases d'entraînement, d'optimisation et d'évaluation dans la suite de cette étude.
\paragraph*{}
Les phases d'entraînement, d'optimisation et d'évaluation utilisent chacune un lot de données spécifique. Chacun de ces lots de données est habituellement obtenu suite à dichotomies successives (voir figure \@ref(fig:Split-jeux)) du lot de données initial, avec des proportions pouvant être variables d'une scission à l'autre :

1. Découpage du jeu de données initial, en un jeu d'évaluation d'une part, et un jeu d'entraînement + optimisation d'autre part,
2. Découpage du jeu de données entraînement + optimisation, en un jeu d'entraînement et un jeu d'optimisation.


\begin{figure}
   \centering
   \includegraphics[width=\linewidth]{Split-Jeux}
  \caption{Principe de séparations successives d'un jeu de données initial en jeux d'apprentissage, d'optimisation et d'évaluation.}
  \label{fig:Split-jeux}
\end{figure}

\paragraph*{} \label{paragraphe:split_ratio}
Les rapports de taille entre jeux de données d'entraînement, d'optimisation et d'évaluation de cette étude suivront la loi $p : \sqrt{p} : \sqrt{p}+1$, avec $p$ le nombre de coefficients du modèle.[@joseph_optimal_2022] 
\paragraph*{} 
Ce nombre $p$ de coefficients peut être approché par l'expression $p \approx \sqrt{N_{u}}$, avec $N_{u}$ le nombre de lignes uniques de notre jeu de données, c'est-à-dire, dans notre cas, le nombre de champignons contenus dans le lot de données.[@joseph_optimal_2022]
\paragraph*{}
Un rapide calcul nous montre qu'il est possible d'obtenir ce rapport $p : \sqrt{p} : \sqrt{p}+1$ par une première scission entre jeu d'entraînement et optimisation d'une part (de taille relative $p +\sqrt{p}$) et jeu d'évaluation d'autre part (de taille relative $\sqrt{p}+1$), avec, pour ce dernier, une taille représentant la fraction du lot total :
$$f_{test}= \frac{\sqrt{p}+1}{p+2\sqrt{p}+1} = \frac{1}{\sqrt{p}+1} $$
\paragraph*{}
Cette première dichotomie peut être suivie par une seconde dichotomie entre jeu d'entraînement (de taille relative $p$) et jeu d'optimisation (de taille relative $\sqrt{p}$), de fraction :
$$ f_{opti} = \frac{\sqrt{p}}{p + \sqrt{p}} = \frac{1}{\sqrt{p}+1} $$

\paragraph*{}
En pratique, pour notre lot de données contenant $N_{u} = `r BI_n_champis`$ spécimens, nous pouvons calculer $p \approx `r round(BI_split_p,1)`$, soit deux dichotomies successives de ratio `r BI_split_facteur-1`:1.

## Méthodes de construction des jeux de données  {#chapitre:split_methodes}

Les méthodes de division mises en \oe{}uvre dans cette étude appellent quelques précisions, car elles apportent certaines améliorations par rapport à l'utilisation de deux scissions successives effectuées de manière purement aléatoire.
\paragraph*{}
La première division, entre jeu d'entraînement/optimisation et jeu d'évaluation, mettra en \oe{}uvre une méthode de découpage basée sur les points-supports[@mak_support_2018] (*support-points based splitting*) exploitant un algorithme du plus proche voisin (*nearest neighbour*), afin d'optimiser la représentativité des jeux de données par rapport à ceux pouvant être obtenus par un découpage aléatoire.[@joseph_split_2022;@vakayil_data_2022]
\paragraph*{} \label{paragraphe:crossvalid}
Notre seconde division, entre jeu d'entraînement et d'optimisation, exploitera quant à elle la méthode de validation croisée à k blocs (*k-folds cross-validation*). Le principe de la validation croisée repose sur une rotation de la séparation créée entre jeux d'entraînement et d'optimisation (voir figure \@ref(fig:Cross-validation)).
\paragraph*{}
Le jeu d'entraînement/optimisation est découpé, de façon aléatoire, en k blocs de données de taille égale, dont k-1 sont utilisés pour l'entraînement du modèle prédictif et 1 pour son optimisation. Cette opération est répétée k fois, en utilisant un jeu d'optimisation différent à chaque itération. L'évaluation de la performance globale s'effectue en évaluant la performance moyenne des k itérations. Cette méthode permet de limiter les biais potentiels générés par une simple dichotomie des données d'entraînement et d'optimisation en exploitant la totalité des données du lot afin d'effectuer ces deux tâches.
\paragraph*{}
Comme démontré précédemment, une validation croisée *k-folds* avec $k = `r BI_split_facteur`$ permettrait d'optimiser l'apprentissage et l'optimisation des modèles de cette étude.[@joseph_optimal_2022]

\paragraph*{}
\begin{figure}
   \centering
   \includegraphics[width=\linewidth]{Cross-Validation}
  \caption{Principe de la validation croisée à k blocs (\emph{k-fold cross-validation}), pour \emph{k} = 4.}
  \label{fig:Cross-validation}
\end{figure}

\FloatBarrier

## Modèles utilisés
### Analyses discriminantes

\paragraph*{}
Cette étude proposera plusieurs classifieurs linéaires s'appuyant sur des méthodes d'analyse discriminante, en particulier l'analyse discriminante linéaire (*Linear Discriminant Analysis*, LDA).

\FloatBarrier

\paragraph*{}
L'analyse discriminante linéaire est une méthode ayant été proposée par Ronald Fisher en 1936[@fisher_use_1936;@anderson_r_1996] pour résoudre des problèmes de classification taxonomique dans le domaine de la botanique.\footnote{Cette étude, proposant une méthode de classification des variétés \emph{Iris setosa}, \emph{Iris virginica} et \emph{Iris versicolor} est par ailleurs à l'origine du célèbre jeu de données \emph{Iris}.} La LDA est basée sur la construction de l'hyperplan de projection permettant de maximiser la distance entre les moyennes projetées des différentes classes et de minimiser la variance intraclasse (voir figure \@ref(fig:Principe-LDA))[@hastie_elements_2016]. La LDA peut être utilisée à fins de classification, mais aussi pour effectuer des réductions de dimensionnalité ou encore pour l'interprétation de l'importance de certaines caractéristiques.

\paragraph*{}
\begin{figure}
   \centering
   \includegraphics[width=\linewidth]{LDA}
  \caption{Séparation par distance maximale des moyennes interclasses (à gauche), et par projection sur l'hyperplan optimal tenant compte des variances intraclasses (LDA, à droite)}
  \label{fig:Principe-LDA}
\end{figure}

\FloatBarrier

#### Approche matricielle...

\paragraph*{}
En pratique, la LDA consiste à déterminer le meilleur ensemble de caractéristiques séparant deux classes, en réduisant la dimensionalité du problème (nombre de caractéristiques) par construction d'un sous-espace de dimensionalité réduite, dans lequel les points du problème originel deviennent "séparables".
\paragraph*{}
Considérons deux échantillons $\mathbf{x}_{1}^{(1)}, \,...\,, \mathbf{x}_{n_{1}}^{(1)}$ et $\mathbf{x}_{1}^{(2)}, \,...\,, \mathbf{x}_{n_{2}}^{(2)}$, issus de deux distributions multivariées. La LDA pose implicitement l'hypothèse que ces distributions ont une matrice de covariance commune. Il est possible de définir la différence $\mathbf{d}$ entre les moyennes des deux échantillons (correspondant à la notion de distance interclasse) par :
$$ \mathbf{d} = \mathbf{\overline{x}}^{(1)} - \mathbf{\overline{x}}^{(2)} $$ et de calculer la somme des carrés intragroupes $\mathbf{A}$ telle que :

$$\mathbf{A} = \sum^{2}_{i=1} \sum^{n_{i}}_{j=1} \left( \mathbf{\overline{x}}^{(i)}_{j} - \mathbf{\overline{x}}^{(i)} \right) \left( \mathbf{\overline{x}}^{(i)}_{j} - \mathbf{\overline{x}}^{(i)} \right) ^\intercal$$

d'où la matrice de covariance : 

$$\mathbf{S} = \frac{1}{ddl}\,\mathbf{A}, \; \; \; \mathrm{avec} \; ddl = n_{1} + n_{2} - 2$$

Soit une combinaison linéaire arbitraire des variables observées : $\mathbf{X} = \mathbf{b}^{T}\mathbf{x}$. Alors les différences de moyennes interclasses de cette combinaison linéaire et la variance intraclasse de X se définissent respectivement par : 

$$ \mathbf{\overline{X}}^{(1)} - \mathbf{\overline{X}}^{(2)} = \mathbf{b}^\intercal\mathbf{d} \; \; \mathrm{et \; Var}(X) = \mathbf{b}^\intercal\mathbf{S}\mathbf{b} $$

L'objectif de la LDA est d'optimiser cette combinaison linéaire $X$ en maximisant le rapport entre le carré de la distance interclasse (écart des moyennes) et la dispersion intraclasse (variance intraclasse) par rapport à $\mathbf{b}$  c'est à dire de maximiser le rapport :
$$\frac{\left(\mathbf{\overline{X}}^{(1)} - \mathbf{\overline{X}}^{(2)}\right)^{2}}{\mathrm{Var}(X)} = \frac{\left(\mathbf{b}^\intercal\mathbf{d}\right)^{2}}{\mathbf{b}^\intercal\mathbf{S}\mathbf{b}} $$
Une solution algébrique est $\mathbf{b} = \mathbf{S}^{-1}\mathbf{d}$. La fonction linéaire optimale ainsi obtenue, $\mathbf{X} = \mathbf{b}^\intercal \mathbf{x}$ est alors la fonction discriminante linéaire, et peut être utilisée pour classifier une future observation comme venant de :
$$- \mathrm{\;la \; population \; (1) \; si \; : \; \;} \mathbf{b}^\intercal \mathbf{x} > \frac{\mathbf{\overline{x}}^{(1)} + \mathbf{\overline{x}}^{(2)}}{2} $$

$$ - \mathrm{\; la \; population \; (2) \; si \; : \; \;} \mathbf{b}^\intercal \mathbf{x} < \frac{\mathbf{\overline{x}}^{(1)} + \mathbf{\overline{x}}^{(2)}}{2}$$

#### Approche non-matricielle...

\paragraph*{}
En pratique, la LDA consiste à construire un indice synthétique, combinaison linéaire des caractéristiques des classes, dont les coefficients permettent de rendre les points du problème originel le plus aisément "séparables".
\paragraph*{}
Pour un classifieur binaire, la LDA vise ainsi à définir la fonction linéaire :

$$X = \sum_{i=1}^n \lambda{}_{i}.x_{i}$$
avec $n$ le nombre de paramètres, $x_{i}$ les caractéristiques mesurées pour chaque paramètre $i$, et $\lambda{}_{i}$ des coefficients à déterminer, telle que $X$ maximise le rapport entre les différences des moyennes de chaque classe $D$ et la somme des produits des caractéristiques intraclasses $S$ (proportionnelle à la variance intraclasse), définis par :

\paragraph*{}

$$D = \sum_{i=1}^n \lambda{}_{i}.d_{i}$$
avec $d_{i}$ la différence des caractéristiques moyennes pour chaque paramètre $i$, et
$$S = \sum_{p=1}^n \sum_{q=1}^n \lambda{}_{p}.\lambda{}_{q}.S_{pq}$$
avec $S$ la somme des carrés intraclasse de $X$ (proportionnelle à la variance intraclasse) et $S_{pq}$ la somme des produits des caractéristiques intraclasses pour chaque combinaison de paramètres $p$ et $q$.
\paragraph*{}
La maximisation du rapport entre distances des moyennes interclasses et variances intraclasses revient à maximiser $D^{2}/S$ pour chaque coefficient $\lambda{}_{i}$ soit, par dérivation, pour chaque $\lambda{}_{i}$ :
$$\frac{d}{d\lambda{}_{i}} \frac{D^2}{S} = 0 \Leftrightarrow{} \frac{1}{S} \frac{\partial}{\partial{}\lambda{}_{i}} D^{2} + D^{2} \frac{\partial}{\partial{}\lambda{}_{i}} \frac{1}{S} = 0 \Leftrightarrow{} \frac{D}{S^{2}}\left(2S\frac{\partial{}D}{\partial{}\lambda{}_{i}} - D \frac{\partial{}S}{\partial{}\lambda{}_{i}} \right) = 0 \Leftrightarrow{} \frac{1}{2} \frac{\partial{}S}{\partial{}\lambda{}_{i}} = \frac{S}{D} \frac{\partial{}D}{\partial{}\lambda{}_{i}} $$

Le rapport $S/D$ étant un facteur supposé constant pour tous les coefficients $\lambda_{i}$ inconnus, ces coefficients sont donc les solutions du système \boldmath$S.\lambda = D$ \unboldmath avec $\mathbf{S}$ la matrice des $S_{pq}$, $\mathbf{D}$ le vecteur des différences des moyennes $d_{i}$ et \boldmath$\lambda{}\,$\unboldmath celui des coefficients $\lambda_{i}$.
\paragraph*{}

<!-- L'analyse discriminante pénalisée [A FINIR] -->

### Modèle additif généralisé
<!-- gamLoess -->
*Développements théoriques sur les modèles GAM...*

[A FAIRE]

### Arbres de décision
<!-- rpart, Ctree???, c50tree, Rpartcost -->
*Développements théoriques sur les arbres décisionnels...*

[A FAIRE]

### Forêts aléatoires
<!-- rFerns, Rborist, ranger -->
*Développements théoriques sur les modèles de forêts aléatoires...*

[A FAIRE]

## Optimisation par plans d'expérience (DOE) {#chapitre:doe}

Certains modèles nécessiteront une optimisation de leurs hyperparamètres, afin d'obtenir des performances maximales. Cette optimisation relève du domaine des plans d'expérience. De nombreux plans et stratégies sont envisageables, le choix dépendant en partie des caractéristiques du processus à optimiser.
\paragraph*{}
En effet, l'optimisation des paramètres d'un modèle informatique présente quelques particularités notables ayant un impact sur l'utilisation des plans d'expérience :

* La réalisation d'une expérience supplémentaire a un coût faible,
* Plusieurs métriques relatives aux performances peuvent coexister,\footnote{cf. section \ref{chapitre:perf}}
* La fonction de réponse peut s'avérer relativement complexe.

\paragraph*{}
Ces particularités imposent d'explorer de manière méthodique la totalité de l'espace expérimental. Il existe une multitude de méthodes permettant de générer des plans expérimentaux dits SFD (*Space Filling Design*), afin d'optimiser l'occupation de l'espace expérimental. La méthode retenue pour cette étude sera celle des hypercubes latins, en raison de son utilisation répandue[@santiago_construction_2012] et de sa simplicité conceptuelle.
\paragraph*{}
La méthode des hypercubes latins est une extension du principe des carrés latins. Un carré latin est une grille $n \times n$, remplie de $n$ éléments distincts arrangés de sorte que chaque ligne et chaque colonne ne contienne qu’un seul exemplaire de chacun des $n$ éléments. Dans le domaine des plans d'expériences, l'application des carrés latins revient à diviser un domaine expérimental bidimensionnel en une grille $n \times n$, et à placer une expérience et une seule sur chaque ligne et chaque colonne.
\paragraph*{}
L'application du concept de carré latin dans un domaine expérimental à trois dimensions aboutit au cube latin. La généralisation dans un espace n-dimensionnel mène au concept d'hypercube latin.
\paragraph*{}
De nombreux plans expérimentaux basés sur les hypercubes latins peuvent être générés. Nous pouvons citer principalement trois types d'hypercubes latins :

* Aléatoires,
* Optimisés, afin d'améliorer l'occupation spatiale,
* Orthogonaux, visant à minimiser la corrélation des estimateurs des effets principaux.

```{r Carres-Latins, echo = FALSE, fig.height = 2.5, fig.cap = "Carré latin aléatoire (à gauche), carré latin avec optimisation évolutive ESE maximin (au milieu), carré latin quasi-orthogonal (à droite)"}
plot(ggarrange(
   widths = c(1.05,1,1),
   ncol = 3,
   graphe_LHS + ylab("X2"),
   graphe_optiLHS,
   graphe_NOHLD
   )
)
```

Dans le cadre de cette étude, nous utiliserons des hypercubes latins quasi-orthogonaux, dont les propriétés nous permettront de modéliser de façon plus précise les performances de nos modèles en fonction de leurs paramètres de configuration (*hyperparamètres*).
\paragraph*{}
Le but des plans expérimentaux de cette étude ne sera pas l'obtention d'une prédiction exacte de la valeur de la réponse, mais plus modestement la recherche des facteurs permettant d'obtenir cette réponse optimale. A cet effet, la modélisation de la performance pourra s'effectuer à l'aide d'un modèle quadratique avec interactions, de formule générale :
$$ Y = \beta_{0}  + \sum_{i = 1}^{k} \beta_{i}.X_{i} + \sum_{i <j}^{k} \sum_{j>1}^{k} \beta_{ij}.X_{i}.X_{j} + \sum_{i = 1}^{k} + \beta_{ii}.X_{i}^2 + \varepsilon$$
Avec $\beta_{n}$ les coefficients des effets principaux et $X_{n}$ les facteurs réduits.
\FloatBarrier

## Évaluation des performances des modèles {#chapitre:perf}

L'optimisation des modèles ainsi que la comparaison de leurs performances relatives implique nécessairement de définir quel sera le critère vis-à-vis duquel cette performance sera évaluée.
\paragraph*{}
De nombreux critères sont utilisables, en fonction du cahier des charges défini pour la résolution du problème, mais également du type de tâche effectuée : régression, classification binaire, classification multiclasse.
\paragraph*{}
Dans une tâche de classification binaire, les critères usuels sont la spécificité, la sensibilité, et l'aire sous la courbe de fonction d'efficacité du récepteur (*AUC ROC*, parfois abrégé en *ROC*). Il conviendra bien évidemment, avant d'utiliser des indicateurs tels que la spécificité et la sensibilité, de définir la notion de test positif et test négatif.
\paragraph*{}
D'autres indicateurs d'intérêt existent, nous retiendrons ici l'index J de Youden[@youden_index_1950] pondéré, qui permet de d'ajuster l'importance relative accordée à la spécificité et à la sensibilité, au sein d'un index synthétique.[@rucker_summary_2010] Cet indicateur présente un intérêt particulier lorsqu'il apparaît souhaitable de tenir compte de la différence d'impact entre un faux positif et un faux négatif, sans pour autant autoriser des sensibilités ou spécificités trop faibles.
\paragraph*{}
En l'espèce, l'index J de Youden pondéré nous permet d'élaborer un indice synthétique tenant compte du fait qu'il est plus grave de classer à tort comme comestible un champignon toxique que d'écarter à tort un champignon parfaitement comestible -- sans pour autant autoriser le modèle à écarter un nombre inconsidéré de champignons comestibles.
\paragraph*{}
L'index J de Youden pondéré est donné par :[@rucker_summary_2010]
$$ J_{w} = 2.\left(w.Sen+ \left(1-w\right).Spe \right) -1 ~~~~~~~~ avec ~~~~ w \in \left[0;1\right]$$ 

\paragraph*{}
Dans la classification binaire de cette étude, problème qui revient classiquement en mycologie à classer les espèces en fonction de leur toxicité, la valeur positive sera ici arbitrairement attribuée à la valeur "champignon toxique". Nous cherchons donc à maximiser la sensibilité de la détection, afin d'écarter les espèces toxiques, la spécificité -- c'est-à-dire la capacité à ne pas écarter trop d'espèces comestibles -- apparaissant alors comme un critère relativement secondaire. En établissant arbitrairement un index J de Youden pondéré accordant `r Jw_ratio` fois plus d'importance à la sensibilité qu'à la spécificité, nous pouvons établir $w = `r Jw_ratio`/`r Jw_ratio+1`$.
\paragraph*{}
Le problème de classification binaire étant relativement simple (*comestible* ou *non-comestible*), nous fixerons arbitrairement le critère de performance minimum à atteindre à $J_{w} \geq `r Jw_min`$, soit :
$$\left \{
\begin{array}{l}
Sen_{max} = 1 \Leftrightarrow Spe_{min} = `r Jw_Spec_min` \\
Spe_{max} = 1 \Leftrightarrow Sen_{min} = `r Jw_Sens_min` \\
\end{array}
\right.$$

\paragraph*{}
Dans les tâches de classification multiclasse, d'autres indicateurs d'intérêt pourront être utilisés, tels que le kappa de Cohen, l'indice de Rand (*accuracy*, ou précision), mais aussi la sensibilité et la spécificité moyennes.
\paragraph*{}
Nous retiendrons dans le cadre de notre étude le kappa de Cohen,[@cohen_coefficient_1960] calculé à partir de la matrice de confusion (cf. figure \ref{fig:Matrice-Confusion}), et donné par :
$$\kappa{} = \frac{\pi_{0}-\pi_{e}}{1-\pi_{e}}$$
\paragraph*{}
Avec $\pi_{0}$ la probabilité d'accord entre notre modèle et la classe réelle du champignon, et $\pi_{e}$ la probabilité d'un même accord résultant du pur hasard.

\begin{figure}
   \centering
   \includegraphics[width=\linewidth]{Matrice-Confusion}
  \caption{Extrait d'une matrice de confusion, pour une classification multiclasse}
  \label{fig:Matrice-Confusion}
\end{figure}

\paragraph*{}
Landis et Koch ont élaboré une échelle de validité du kappa de Cohen, avec un accord qualifié de *quasi-parfait* pour $\kappa > 0.80$.[@landis_measurement_1977] Nous considérerons donc que ce critère sera le minimum requis pour qu'un modèle de classifieur multiclasse élaboré au cours de cette étude puisse être considéré comme ayant des performances acceptables.
\paragraph*{}
L'interprétation du kappa pouvant parfois être assez contre-intuitive, cette étude la complétera parfois par l'indice de Rand $R$, métrique moins robuste en présence de données non-équilibrées\footnote{Ce cas se présente habituellement lors d'une surreprésentation de certaines classes dans les jeux de données.}, mais présentant l'avantage d'être de compréhension plus aisée, car représentant le pourcentage de prédictions exactes.
\paragraph*{}




\newpage

# Apprentissage machine et classification binaire

*BROUILLON, le lot de données utilisé ici est le Secondary Mushroom Dataset de D.Wagner.*

## Analyse exploratoire des données (EDA)

*Partie permettant de présenter globalement le lot de données synthétiques créé dans cette étude (cf. section \@ref(chapitre:lotsynth)) avant utilisation des IA.*

*La génération du lot de données fonctionne, la génération des graphiques aussi, mais le texte sera à retravailler en fonction du lot de données synthétiques obtenu...*

\FloatBarrier
\paragraph*{}

```{r EDA-structure, echo = FALSE}
kable(structure_dataset, caption = "Structure du lot de données initial")
```

\paragraph*{}
Le lot de données d'origine contient `r EDA_n_champis` spécimens de champignons, caractérisés par `r EDA_n_cols` propriétés morphologiques ou environnementales. La structure de ce lot de données est résumé dans le tableau \@ref(tab:EDA-structure).
\paragraph*{}
Ce lot de données original a été découpé en un jeu d'apprentissage/optimisation et un jeu de données d'évaluation, avec un rapport `r EDA_split_facteur-1`:1, conformément aux principes mentionnés dans nos développements précédents.\footnote{cf. section \ref{chapitre:split}, page \pageref{paragraphe:split_ratio}.}
\paragraph*{}
Toutes les distributions des variables du lot d'entraînement ont ensuite été tracées par histogrammes pour les variables numériques, et diagrammes en barres pour les variables alphabétiques et catégorielles.
\paragraph*{}
Les diagrammes en barres n'ont rien illustré de particulièrement remarquable et n'ont pas été inclus dans le rapport. Toutefois, les distributions dimensionnelles sont plus intéressantes : à première vue, elles semblent suivre une courbe en cloche (figure \@ref(fig:EDA-distrib)), avec une longue queue à droite. Une transformation logarithmique (figure \@ref(fig:EDA-distrib-log)) montre plus nettement la forme de cette queue.

```{r EDA-distrib, echo = FALSE, fig.height = 2.5, fig.cap = "Distribution des diamètres de chapeau, longueur de stipe, diamètre de stipe"}
plot(ggarrange(
   ncol = 3,
   study_distrib_cap.diameter + ggtitle("") + ylab("") + scale_y_continuous(labels = NULL),
   study_distrib_stem.height + ggtitle("") + ylab("") + scale_y_continuous(labels = NULL),
   study_distrib_stem.width + ggtitle("") + ylab("") + scale_y_continuous(labels = NULL)
   )
)
```

```{r EDA-distrib-log, echo = FALSE, fig.height = 2.5, fig.cap = "Distribution des diamètres de chapeau, longueur de stipe, diamètre de stipe (échelle logarithmique en ordonnée)"}
plot(ggarrange(
   ncol = 3,
   study_distrib_cap.diameter + ggtitle("") + ylab("") + scale_y_log10(labels = NULL),
   study_distrib_stem.height + ggtitle("") + ylab("") + scale_y_log10(labels = NULL),
   study_distrib_stem.width + ggtitle("") + ylab("") + scale_y_log10(labels = NULL)
   )
)
```

La distribution du diamètre du chapeau $D_{C}$ a l'apparence d'une courbe en cloche, avec une longue queue à droite, mais est en réalité bimodale, avec un mode principal à 5 cm, et un mode secondaire beaucoup plus petit pour $D_{C} \approx$ 50 cm. Cette taille exceptionnelle est attribuable à des variétés telles que *Polyporus squamosus*.[@courtecuisse_champignons_2013]
\paragraph*{}
La distribution de la longueur de stipe $L_{S}$ a également une forme de courbe en cloche avec une longue queue à droite, un mode principal à 5 cm et un mode secondaire à 0 cm. Cette valeur peut également sembler surprenante, mais certains champignons du lot n'ont pas de pied, ce qui explique cette valeur.
\paragraph*{}
La distribution du diamètre de stipe $D_{S}$ a aussi l'apparence d'une courbe en cloche avec une longueur queue à droite, et un pic à $D_{S} \approx$ 10-15 mm. Dans toutes ces distributions, la longue queue à droite peut probablement s'expliquer par l'utilisation, dans le *Secondary Mushroom Dataset*, d'une distribution normale pour chaque variété, associée à l'impossibilité d'avoir des valeur dimensionnelles négatives.

\paragraph*{}

\newpage

## Optimisation et sélection des modèles
\paragraph*{}
Il existe une grande variété de modèles exploitables pour bâtir un système d'apprentissage machine. Cette section expliquera la stratégie utilisée pour l'évaluation de certains de ces modèles, ainsi que pour l'exploration de l'espace de leurs hyperparamètres à fins d'optimisation et la mesure de leurs performances. 
\paragraph*{}
Les modèles sélectionnés pour cette étude sont de types variés :

* Analyse discriminante linéaire (LDA) : *Linear Discriminant Analysis* (lda2), *Penalized Discriminant Analysis* (pda)
* Modèle additif généralisé (GAM) : *Generalized Additive Model using LOESS* (gamLoess)
* Modèle arborescent : *Classification And Regression Tree* (CART) (rpart, rpartCost), *Single C5.0 Tree* (ctree)
* Forêt aléatoire : *Random Ferns* (rferns), *Random Forest* (ranger, Rborist)

### Stratégie d'optimisation

Les algorithme d'apprentissage machine développés au cours de cette étude mettent en \oe{}uvre les méthodes présentées dans les sections précédentes afin d'effectuer automatiquement les tâches suivantes :

1. Découpage du lot de données en un jeu d'entraînement/optimisation et en un jeu de validation, avec adaptation des rapports de taille en fonction du volume de données du lot initial,\footnote{cf. section \ref{chapitre:split}, page \pageref{paragraphe:split_ratio}}
2. Apprentissage sur le jeu d'entraînement, exploitant une validation croisée à k blocs, avec adaptation du nombre de blocs à la taille du lot de données,\footnote{cf. section \ref{chapitre:split_methodes}, page \pageref{paragraphe:crossvalid}}
3. Exploration de l'ensemble de l'espace expérimental des hyperparamètres du modèle, via la méthode des hypercubes latins quasi-orthogonaux,\footnote{\label{note:doe}cf. section \ref{chapitre:doe}, page \pageref{chapitre:doe}
4. Mesure des performances en exploitant une métrique adaptée,\footnote{cf. section \ref{chapitre:perf}, page \pageref{chapitre:perf}}
5. Modélisation des performances en fonction des hyperparamètres, via un modèle quadratique avec interactions,\footnotemark[\value{footnote}]
6. Sélection des hyperparamètres permettant d'optimiser les performances du modèle,
7. Mesure des performances de chaque modèle avec les hyperparamètres optimaux,
8. Sélection des modèles les plus performants pour prédiction et mesure finale des performances contre le lot d'évaluation,
9. Génération, sauvegarde et insertion automatique de tous les graphiques et données numériques dans le texte de la présente étude.

### Modèles d'analyse discriminante{#chapitre:BI_lda}
\paragraph*{}
Les modèles d'analyse discriminante choisis pour cette étude sont lda2 (LDA : *Linear Discriminant Analysis*) et pda (*Penalized Discriminant Analysis*). Le modèle lda2 dispose d'un seul hyperparamètre (*dimen*, nombre de fonctions discriminantes). Le modèle pda a également un unique hyperparamètre (*lambda*, pénalité de réduction des coefficients).  

```{r, lda-pda, echo = FALSE, fig.height = 3, fig.cap = "Performances des modèles lda2 (à gauche) et pda (à droite), dans une tâche de classification binaire"}
plot(ggarrange(widths = c(1, 1.5),
   ncol = 2,
   BI_fit_lda2_dim_graphe + theme(legend.position="none"),
   BI_fit_pda_lambda_graphe
   )
)
```
\paragraph*{}
Comme l'illustre la figure \ref{fig:lda-pda}, les performances des modèles PDA et LDA sont très proches, et relativement constantes sur la totalité de l'espace expérimental de leurs hyperparamètres.
\paragraph*{}
Le paramètre *dimen* du modèle lda2 ne semble en effet pas avoir d'effet significatif sur ses performances, avec un index J de Youden pondéré relativement constant ($J_{w_{moy}} = `r round(mean(BI_fit_lda2_dim_resultats[,"Jw"]), 3)`$). 
\paragraph*{}
De même, le paramètre *lambda* du modèle pda n'impacte ses performances que de matière très marginale, avec des lambdas faibles donnant une légère amélioration des résultats ($J_{w_{max}} = `r round(max(BI_fit_pda_lambda_resultats["Jw"]),3)`$).
\paragraph*{}
Toutefois, les performances de ces deux modèles restent malheureusement insuffisantes pour notre étude, aussi bien en sensibilité qu'en spécificité :
$$\left \{
\begin{array}{l}
Sen \approx `r round(mean(c(BI_fit_lda2_dim_resultats[,"Sens"], BI_fit_pda_lambda_resultats[,"Sens"])),3)` \\
Spe \approx `r round(mean(c(BI_fit_lda2_dim_resultats[,"Sens"], BI_fit_pda_lambda_resultats[,"Spec"])),3)` \\
\end{array}
\right.$$

\paragraph*{}
Ces performances médiocres s'expliquent par le fonctionnement même des modèles d'analyse discriminante qui, s'ils peuvent analyser des données qualitatives à fins de classifications, ne peuvent le faire que si une quantification sous-jacente est possible, par exemple :

* Données binaires ou booléennes,
* Données catégorielles basées sur des données quantitatives.

\paragraph*{}
L'inclusion de ces modèles, présentant ici des performances très modestes, a un intérêt essentiellement didactique, permettant de souligner l'intérêt d'une connaissance élémentaire des fondamentaux mathématiques et algorithmiques des modèles d'apprentissage machine mis en \oe{}uvre, pour en connaître les limites ou évaluer les besoins de nettoyage préalable des données avant déploiement de l'apprentissage machine, afin d'éviter de confronter certains modèles face à des problèmes de classification pour lesquels ils n'ont pas été conçus.

\FloatBarrier
### Modèle additif généralisé  
\paragraph*{}
Le seul modèle additif généralisé choisi pour cette étude est gamLoess (*Generalized Additive Model using Locally Weighted Linear Regression*). Le modèle gamLoess dispose de deux hyperparamètres : *span* (fraction de points utilisés dans l'environnement local) and *degree* (degré de linéarisation).

```{r, echo = FALSE, fig.height = 3, fig.cap = "Performances de gamLoess en classification binaire, en fonction du span (gauche) and du degré (droite)"}
plot(ggarrange(widths = c(1, 1.5),
   ncol = 2,
   BI_fit_gamLoess_span_graphe + theme(legend.position="none"),
   BI_fit_gamLoess_degree_graphe
   )
)
```

\paragraph*{}
L'hyperparamètre *degree* du modèle gamLoess a un impact mineur sur ses performances, avec un écart entre indices J de Youden maximal et minimal de $\Delta J_{w} = `r round(max(BI_fit_gamLoess_degree_resultats[,"Jw"]) - min(BI_fit_gamLoess_degree_resultats[,"Jw"]), 3)`$.
\paragraph*{}
L'hyperparamètre *span* affecte marginalement la sensibilité de gamLoess, avec une valeur optimale de $span = `r BI_fit_gamLoess_span_resultats[which.max(BI_fit_gamLoess_span_resultats[,"Jw"]), "span"]`$, aboutissant à un index J de Youden maximal de $J_{w_{max}} = `r round(max(BI_fit_gamLoess_span_resultats["Jw"]), 3)`$.
\paragraph*{}
Les performances de ce modèle n'atteignent pas le critère posé pour notre étude. Le modèle additif généralisé s'est avéré inférieur aux modèles d'analyse discriminante linéaire, aussi bien en en sensibilité (`r round(max(BI_fit_gamLoess_span_resultats["Sens"]), 3)` vs `r round(mean(c(BI_fit_lda2_dim_resultats$Sens, BI_fit_pda_lambda_resultats$Sens)), 3)`) qu'en spécificité (`r round(max(BI_fit_gamLoess_span_resultats["Spec"]), 3)` vs `r round(mean(c(BI_fit_lda2_dim_resultats$Spec, BI_fit_pda_lambda_resultats$Spec)), 3)`).
\paragraph*{}
Les performances médiocres de ce modèle s'expliquent par les mêmes raisons que celles des modèles d'analyse discriminante.\footnote{cf. section \ref{chapitre:BI_lda})

\FloatBarrier
### Modèles d'arbres de décision
\paragraph*{}
Les modèles basés sur des arbres de décision ont un intérêt tout particulier pour cette étude, pour deux raisons majeures :

* La logique en arbre de décision est habituellement usitée pour la classification manuelle des champignons,
* Les arbres de décision obtenus peuvent être tracés, et facilement interprétés par l'humain.

\paragraph*{}
Les premiers modèles présentés dans le cadre de notre étude sont deux modèles CART (*Classification And Regression Tree*). Le modèle CART le plus simple proposé dans notre étude (rpart) ne dispose que d'un seul hyperparamètre  : *cp* (complexité).
\FloatBarrier
\paragraph*{}
```{r, BIrpart, echo = FALSE, fig.height = 3, fig.cap = "Performances du modèle rpart en classification binaire, en fonction du paramètre de complexité (cp)"}
plot(BI_fit_rpart_cp_graphe)
```


\paragraph*{}
Le modèle CART le plus simple n'atteint jamais les performances requises, le critère étant $Jw \geq `r Jw_min`$. Toutefois, ce modèle s'en approche, et donne de bons résultats globaux, avec :
$$\left \{
\begin{array}{l}
J_{w_{max}} = `r round(max(BI_fit_rpart_cp_resultats["Jw"]),4)` \\
Spe_{Jw_{max}} = `r round(BI_fit_rpart_cp_resultats[which.max(BI_fit_rpart_cp_resultats[,"Jw"]),"Spec"],4)` \\
Sen_{Jw_{max}} = `r round(BI_fit_rpart_cp_resultats[which.max(BI_fit_rpart_cp_resultats[,"Jw"]),"Sens"],4)` \\
\end{array}
\right.$$

\FloatBarrier
\paragraph*{}
Le second modèle CART utilisé dans cette étude (rpartCost) associe des hyperparamètres de complexité (*cp*) et de coût (*Cost*). Les graphiques de sensibilité et de spécificité en fonction des hyperparamètres (figure  \ref{fig:BIrpartcostSenSpe}) illustrent bien, dans leur partie supérieure ($cp \geq 0.05$) la notion classique de compromis entre sensibilité et spécificité : dans cette zone, toute amélioration de la sensibilité se fera inévitablement au détriment de la spécificité, et réciproquement.
\paragraph*{}
En pratique, pour $cp \geq 0.05$, notre modèle d'IA basé sur ce type d'arbre de décision se montrera soit excessivement sévère, rejetant un nombre considérable de champignons comestibles (quadrant supérieur gauche, $cost \leq 1.5$), soit au contraire excessivement laxiste, admettant un nombre important de champignons non-comestibles (quadrant supérieur droit, $cost \geq 1.5$).
\paragraph*{}
C'est dans la section inférieure de ces graphiques ($cp \leq 0.025$) que le modèle montre une performance acceptable tant en sensibilité qu'en spécificité.


```{r, BIrpartcostSenSpe, echo = FALSE, fig.height = 4, fig.cap = "Sensibilité (à gauche) et spécificité (à droite) de rpartCost en classification binaire, en fonction de la complexité et du coût (interpolation quadratique, points expérimentaux encadrés en noir)"}
plot(ggarrange(
   ncol = 2,
   BI_fit_rpartcost_sens_graphe,
   BI_fit_rpartcost_spec_graphe
   )
)
```


```{r, echo = FALSE, fig.height = 4, fig.width = 5.2, fig.cap = paste0("Performances (index J de Youden pondéré ", Jw_ratio,":1) de rpartCost en classification binaire, en fonction des hyperparamètres réduits de complexité X1 et de coût X2 (interpolation quadratique, points expérimentaux encadrés en noir)")}
plot(BI_fit_rpartcost_jw_graphe + theme(legend.position='right') + theme(legend.text = element_text(angle = 0, vjust = 1, hjust = 0)))
```

\FloatBarrier
\paragraph*{}
En posant comme facteurs réduits :

* $X_{1} \in [0;1]$ pour le paramètre *minNode*,
* $X_{2} \in [0;1]$ pour le paramètre *predFixed*,

Nous pouvons modéliser la réponse Y ($J_{w}$) par un modèle quadratique avec interaction\footnote{cf. section \ref{chapitre:doe}, page \pageref{chapitre:doe}} :

$$ Y = b_{0} + b_{1}.X_{1} + b_{2}.X_{2} + b_{12}.X_{1}.X_{2} + b_{11}.X_{1}^{2} + b_{22}.X_{2}^{2}$$

Avec Y l'indice J de Youden pondéré, $X_{1}$ le facteur réduit dans la plage [0;1] associé à l'hyperparamètre de complexité (*cp*), $X_{2}$ le facteur réduit associé à l'hyperparamètre de coût (*Cost*) et $b_{n}$ les coefficients des effets. La modélisation permet de calculer les effets suivants:

\begin{minipage}{0.4 \textwidth}
$$\left \{
\begin{array}{l}
b_{0} = `r round(BI_mod_rpartcost_jw$model@trend.coef[1],4)` \\
b_{1} = `r round(BI_mod_rpartcost_jw$model@trend.coef[2],4)` \\
b_{2} = `r round(BI_mod_rpartcost_jw$model@trend.coef[3],4)` \\
\end{array}
\right.$$
\end{minipage}
\begin{minipage}{0.4 \textwidth}
$$\left \{
\begin{array}{l}
b_{12} = `r round(BI_mod_rpartcost_jw$model@trend.coef[6],4)` \\
b_{11} = `r round(BI_mod_rpartcost_jw$model@trend.coef[4],4)` \\
b_{22} = `r round(BI_mod_rpartcost_jw$model@trend.coef[5],4)` \\
\end{array}
\right.$$
\end{minipage}

  \paragraph*{}
Les performances maximales seront ici atteintes pour :

$$\left \{
\begin{array}{lcl}
X_{1} = `r BI_modelquad_rpartcost_top["X1"]` & soit & cp = `r BI_modelquad_rpartcost_top["cp"]` \\
X_{2} = `r BI_modelquad_rpartcost_top["X2"]` & soit & Cost = `r round(BI_modelquad_rpartcost_top["Cost"],2)` \\
\end{array}
\right.$$

Ces hyperparamètres optimaux permettent au modèle d'atteindre :
$$\left \{
\begin{array}{l}
J_{w_{max}} = `r round(BI_fit_rpartcost_best_resultats["Jw"],4)` \\
Spe_{Jw_{max}} = `r round(BI_fit_rpartcost_best_resultats["Spec"],4)` \\
Sen_{Jw_{max}} = `r round(BI_fit_rpartcost_best_resultats["Sens"],4)` \\
\end{array}
\right.$$

\paragraph*{}
Les performances du modèle rpartCost, bien qu'excellentes, ne permettent pas d'atteindre l'index J de Youden requis.
\paragraph*{}
Le dernier modèle d'arbre décisionnel proposé dans notre étude est C5.0 tree (c50tree). Ce modèle ne dispose d'aucun hyperparamètre. \paragraph*{}
Les performances obtenues sont :
$$\left \{
\begin{array}{l}
J_{w} = `r round(BI_fit_c50tree_resultats["Jw"],4)` \\
Spe = `r round(BI_fit_c50tree_resultats["Spec"],4)` \\
Sen = `r round(BI_fit_c50tree_resultats["Sens"],4)` \\
\end{array}
\right.$$
\paragraph*{}
De manière assez surprenante, bien que ne disposant d'aucun hyperparamètre, ce modèle a donné d'excellents résultats sans aucune optimisation nécessaire. Toutefois, le modèle C5.0 tree n'a pas rempli l'objectif posé par le critère $J_w \geq `r Jw_min`$.
\paragraph*{}
Les modèles d'arbres de classification sont particulièrement adaptés aux problèmes de classification avec variables quantitatives et surtout qualitatives, et ont pu s'illustrer dans cette étude en fournissant des résultats très acceptables ($Spe \geq `r round(min(BI_fit_c50tree_resultats["Spec"], 
    BI_fit_rpartcost_resultats[which.max(BI_fit_rpartcost_resultats[,"Jw"]),"Spec"], 
    BI_fit_rpart_cp_resultats[which.max(BI_fit_rpart_cp_resultats[,"Jw"]),"Spec"]),3)`$, $Sen \geq `r round(min(BI_fit_c50tree_resultats["Sens"], 
    BI_fit_rpartcost_resultats[which.max(BI_fit_rpartcost_resultats[,"Jw"]),"Sens"], 
    BI_fit_rpart_cp_resultats[which.max(BI_fit_rpart_cp_resultats[,"Jw"]),"Sens"]),3)`$), mais n'atteignant pas pour autant les exigences imposées par le critère de performance que nous avons défini pour les classifieurs binaires de notre étude.
\paragraph*{}

\newpage

### Forêts aléatoires {#chapitre:BI-RF}
\paragraph*{}
\FloatBarrier
Le premier modèle de forêt aléatoire évalué dans notre étude est le modèle de fougères aléatoires rFerns (*Random Ferns*). Ce modèle ne possède qu'un seul hyperparamètre, la profondeur (*depth*).

```{r, echo = FALSE, fig.height = 3, fig.cap = "Performances du modèle de fougères aléatoires, en classification binaire"}
BI_fit_rFerns_depth_graphe + theme_bw()
```

\paragraph*{}
Quoique très efficient sur le plan calculatoire, le modèle de fougères aléatoires a fourni des résultats assez peu satisfaisants, avec :
$$\left \{
\begin{array}{l}
J_{w_{max}} = `r round(max(BI_fit_rFerns_depth_resultats["Jw"]),3)` \\
Spe_{Jw_{max}} = `r round(BI_fit_rFerns_depth_resultats[which.max(BI_fit_rFerns_depth_resultats[,"Jw"]),"Spec"],3)` \\
Sen_{Jw_{max}} = `r round(BI_fit_rFerns_depth_resultats[which.max(BI_fit_rFerns_depth_resultats[,"Jw"]),"Sens"],3)` \\
\end{array}
\right.$$
\FloatBarrier

\paragraph*{}
Le second modèle de forêt aléatoire évalué dans cette étude est Rborist. Deux hyperparamètres régissent ce modèle : le nombre de prédicteurs testés pour une scission (*predFixed*) et le nombre minimal de lignes-références distinctes avant de scinder un n\oe{}ud (*minNode*).

```{r, echo = FALSE, fig.height = 4, fig.cap = "Sensibilité (à gauche) et spécificité (à droite) du modèle Rborist en classification binaire, en fonction de ses deux hyperparamètres (interpolation quadratique, points expérimentaux encadrés en noir)"}
plot(ggarrange(
   ncol = 2,
   BI_fit_Rborist_sens_graphe,
   BI_fit_Rborist_spec_graphe
   )
)
```

```{r, echo = FALSE, fig.height = 4, fig.width = 5.2, fig.cap = "Performance (indice J de Youden pondéré) du modèle Rborist en classification binaire, en fonction de ses deux hyperparamètres réduits de nombre de prédicteurs X1 et de nombre de références avant scission X2 (interpolation quadratique, points expérimentaux encadrés en noir)"}
plot(BI_fit_Rborist_jw_graphe + theme(legend.position='right') + theme(legend.text = element_text(angle = 0, vjust = 1, hjust = 0)))
```

\FloatBarrier
\paragraph*{}
Nous pouvons modéliser la réponse par un modèle quadratique avec interaction\footnote{cf. section \ref{chapitre:doe}, page \pageref{chapitre:doe}} :
$$ Y = b _{0} + b _{1}.X_{1} + b_{2}.X_{2} + b_{12}.X_{1}.X_{2} + b _{11}.X_{1}^{2} + b_{22}.X_{2}^{2}$$
\paragraph*{}
Avec $Y$ l'indice J de Youden pondéré $J_{w}$, $X_{1}$ le facteur réduit dans la plage [0;1] associé à l'hyperparamètre de nombre de prédicteurs testés par scission (*predFixed*), $X_{2}$ le facteur réduit associé à l'hyperparamètre de nombre minimal de références distinctes avant scission (*minNode*) et $b_{n}$ les coefficients des effets. La modélisation permet de calculer les effets suivants:
\paragraph*{}
Le calcul numérique nous permet d'obtenir les estimation des effets :

\begin{minipage}{0.4 \textwidth}
$$\left \{
\begin{array}{l}
b_{0} = `r round(BI_mod_Rborist_jw$model@trend.coef[1],4)` \\
b_{1} = `r round(BI_mod_Rborist_jw$model@trend.coef[2],4)` \\
b_{2} = `r round(BI_mod_Rborist_jw$model@trend.coef[3],4)` \\
\end{array}
\right.$$
\end{minipage}
\begin{minipage}{0.4 \textwidth}
$$\left \{
\begin{array}{l}
b_{12} = `r round(BI_mod_Rborist_jw$model@trend.coef[6],4)` \\
b_{11} = `r round(BI_mod_Rborist_jw$model@trend.coef[4],4)` \\
b_{22} = `r round(BI_mod_Rborist_jw$model@trend.coef[5],4)` \\
\end{array}
\right.$$
\end{minipage}

\paragraph*{}
Ce modèle quadratique avec interactions permet d'évaluer les hyperparamètres optimaux permettant de maximiser l'indice J de Youden pondéré ($minNode = `r BI_modelquad_Rborist_top["minNode"]`$ et $predFixed = `r BI_modelquad_Rborist_top["predFixed"]`$) afin de lancer la prédiction sur un modèle optimisé. Les performances obtenues sont excellentes :

$$\left \{
\begin{array}{l}
J_{w_{max}} = `r round(BI_fit_Rborist_best_resultats["Jw"],5)` \\
Spe_{Jw_{max}} = `r round(BI_fit_Rborist_best_resultats["Spec"],5)` \\
Sen_{Jw_{max}} = `r round(BI_fit_Rborist_best_resultats["Sens"],5)` \\
\end{array}
\right.$$


\paragraph*{}
Le dernier modèle de forêt aléatoire que nous évaluons dans cette étude est le modèle ranger. Celui-ci dispose de trois hyperparamètres : la taille minimale de n\oe{}ud (*min.node.size*), le nombre de caractéristiques à séparer à chaque n\oe{}ud (*mtry*) et la règle contrôlant cette séparation (*splitrule*).

```{r, BI-ranger-gini, echo = FALSE, fig.height = 4, fig.cap = "Sensibilité (à gauche) et spécificité (à droite) du modèle Ranger en classification binaire, en fonction des 2 hyperparamètres (algorithme de scission : gini)"}
plot(ggarrange(
   ncol = 2,
   BI_fit_ranger_Gini_sens_graphe,
   BI_fit_ranger_Gini_spec_graphe
   )
)
```

```{r, BI-ranger-ET, echo = FALSE, fig.height = 4, fig.cap = "Sensibilité (à gauche) et spécificité (à droite) du modèle Ranger en classification binaire, en fonction des 2 hyperparamètres (algorithme de scission : extratrees)"}
plot(ggarrange(
   ncol = 2,
   BI_fit_ranger_ET_sens_graphe,
   BI_fit_ranger_ET_spec_graphe
   )
)
```


```{r, BI-ranger-Jw, echo = FALSE, fig.height = 4, fig.cap = "Performances du modèle Ranger en classification binaire, en fonction de l'algorithme de scission (extratrees à gauche, gini à droite) et des hyperparamètres réduits : caractéristiques à séparer X1 et taille minimale de noeud X2 (interpolation quadratique, points expérimentaux encadrés en noir)"}
plot(ggarrange(
   ncol = 2,
   BI_fit_ranger_ET_jw_graphe,
   BI_fit_ranger_Gini_jw_graphe
   )
)
```

\FloatBarrier
\paragraph*{}
Nous pouvons proposer pour ce modèle la modélisation quadratique suivante :
$$ Y = b_{0} + b_{1}.X_{1} + b_{2}.X_{2} + b_{3}.X_{3} + b_{12}.X_{1}.X_{2} + b_{23}.X_{2}.X_{3} + b_{13}.X_{1}.X_{3} + b_{11}.X_{1}^{2} + b_{22}.X_{2}^{2}$$
Avec Y l'indice J de Youden pondéré, $X_{1}$ le facteur réduit associé au paramètre de taille minimale de n\oe{}ud (*min.node.size*), $X_{2}$ le facteur réduit associé au paramètre de nombre de caractéristiques à séparer à chaque n\oe{}ud (*mtry*), $X_{3}$ le facteur régissant la règle de séparation (*splitrule*, la valeur 0 étant attribuée à *gini*, 1 à *extratrees*) et $b_{n}$ les estimations des coefficients des effets. Le facteur $X_{3}$ n'ayant que deux niveaux, il est évidemment impossible de lui attribuer une composante quadratique.
\paragraph*{}
La modélisation permet de calculer les effets suivants :

\begin{minipage}{0.4 \textwidth}
$$\left \{
\begin{array}{l}
b_{0} = `r round(BI_mod_ranger_jw$model@trend.coef[1],4)` \\
b_{1} = `r round(BI_mod_ranger_jw$model@trend.coef[2],4)` \\
b_{2} = `r round(BI_mod_ranger_jw$model@trend.coef[3],4)` \\
b_{3} = `r round(BI_mod_ranger_jw$model@trend.coef[4],4)` \\
\end{array}
\right.$$
\end{minipage}
\begin{minipage}{0.4 \textwidth}
$$\left \{
\begin{array}{l}
b_{12} = `r round(BI_mod_ranger_jw$model@trend.coef[7],4)` \\
b_{23} = `r round(BI_mod_ranger_jw$model@trend.coef[8],4)` \\
b_{13} = `r round(BI_mod_ranger_jw$model@trend.coef[9],4)` \\
b_{11} = `r round(BI_mod_ranger_jw$model@trend.coef[5],4)` \\
b_{22} = `r round(BI_mod_ranger_jw$model@trend.coef[6],4)` \\
\end{array}
\right.$$
\end{minipage}


\paragraph*{}
Le modèle ranger semble déjà, par simple interprétation graphique (voir figures \@ref(fig:BI-ranger-gini), \@ref(fig:BI-ranger-ET) et \@ref(fig:BI-ranger-Jw)), donner de bons résultats sur une très large plage de l'espace expérimental de ses hyperparamètres, même avec un nombre réduit d'arbres ($n=6$). Une optimisation des hyperparamètres grâce à la modélisation quadratique  ($min.node.size = `r BI_modelquad_ranger_top["min.node.size"]`$, $mtry = `r BI_modelquad_ranger_top["mtry"]`$ et $splitrule = `r BI_modelquad_ranger_top[1,"splitrule"]`$) a donné d'excellents résultats :
$$\left \{
\begin{array}{l}
J_{w_{max}} = `r round(BI_fit_ranger_best_resultats["Jw"],5)` \\
Spe_{Jw_{max}} = `r round(BI_fit_ranger_best_resultats["Spec"],5)` \\
Sen_{Jw_{max}} = `r round(BI_fit_ranger_best_resultats["Sens"],5)` \\
\end{array}
\right.$$

\paragraph*{}
Le modèle Ranger a donné des résultats similaires à ceux du modèle Rborist, avec une sensibilité, une spécificité et un indice de Youden excellents.
\paragraph*{}
Ces résultats soulignent un fait intéressant : tous les modèles de forêts aléatoires ne sont pas égaux. Notre étude montre une différence considérable en sensibilité et spécificité entre les forêts aléatoires de type rFerns, Ranger et Rborist. Lors des étapes préliminaires de cette étude, d'autres algorithmes de forêts aléatoires ont montré de grandes disparités d'efficience sur le plan calculatoire, ce qui nous a conduit à écarter certains modèles pour des raisons pratiques, alors que d'autres se sont avérés sensiblement plus rapides et ont donc pu être retenus pour notre étude.
\paragraph*{}

\newpage

## Résultats
### Protocole d'évaluation
\paragraph*{}
Les modèles ayant atteint les performances requises ($J_{w} \geq `r Jw_min`$) lors de l'étape d'optimisation ont été choisis pour l'évaluation. Les deux modèles retenus sont deux modèles de type forêt aléatoire :

* Forêt aléatoire avec algorithme de type Ranger,
* Forêt aléatoire avec algorithme de type Rborist.

\paragraph*{}
Tous les modèles ont été entraînés sur le jeu de données d'apprentissage, après application des hyperparamètres optimaux obtenus précédemment\footnote{cf. section \ref{chapitre:BI-RF}} par modélisation des performances via un modèle quadratique avec interactions. Les performances de nos modèles face au jeu de données d'évaluation, auquel ils n'ont encore jamais été exposés\footnote{cf. section \ref{chapitre:split_methodes}, \pageref{chapitre:split_methodes}}, seront évaluées avec le même critère que précédemment : $J_{w} \geq `r Jw_min`$

### Performances des modèles de forêts aléatoires  

La matrice de confusion du modèle ranger (table \ref{tab:BI-CM}) donne les résultats détaillés de ses prédictions.
\FloatBarrier

```{r BI-CM, echo = FALSE}
kable(BI_CM_ranger_final$table, caption = "Matrice de confusion du modèle Ranger (prédictions à gauche, référence en haut)") %>%
   kable_styling(latex_options = c("striped", "hold_position"),full_width = F)
```  

\FloatBarrier
\paragraph*{}
La forêt aléatoire de type Ranger a donné d'excellents résultats, sa précision finale étant égale à `r round(BI_CM_ranger_final$overall["Accuracy"], 4)`, avec un intervalle de confiance à 95% de [`r round(BI_CM_ranger_final$overall["AccuracyLower"], 4)` ; `r round(BI_CM_ranger_final$overall["AccuracyUpper"], 4)`], le tout en un temps raisonnable ($`r BI_temps_ranger` min$), preuve de son efficience calculatoire.
\paragraph*{}
La forêt aléatoire de type Rborist a donné des résultats similaires, atteignant une précision finale égale à `r BI_CM_Rborist_final$overall["Accuracy"]`, avec un intervalle de confiance à 95% de [`r round(BI_CM_Rborist_final$overall["AccuracyLower"], 4)` ; `r round(BI_CM_Rborist_final$overall["AccuracyUpper"], 4)`]. Le modèle Rborist, donnant des résultats sensiblement identiques à Ranger, s'est de plus avéré extrêmement efficient sur le plan calculatoire ($`r BI_temps_Rborist` min$).

\FloatBarrier

```{r, echo = FALSE, fig.pos="H"}
kable(BI_RF_resultat, digits = 4, caption = "Performances des modèles Ranger et Rborist (jeu d'évaluation)") %>%
   kable_styling(latex_options = c("striped", "hold_position"), full_width = F)
```

\FloatBarrier

\paragraph*{}

\newpage

# Apprentissage machine et classification multiclasse

*Brouillon, le lot de données utilisé ici est un lot synthétique créé par moi-même (avec algorithme de création fonctionnel), mais à partir des données primaires du Secondary Mushroom Dataset de D.Wagner.*
\paragraph*{}
Étant données les performances qu'ont montré les différents modèles lors de la classification binaire, seuls les modèles basés sur les arbres décisionnels et les forêts aléatoires seront évalués dans cette section.
\FloatBarrier

## Classification par familles

### Modèles d'arbres de décision

*Brouillon, à étoffer et finir, peut-être avec plus de modèles.*

\paragraph*{}
Le modèle d'arbre de décision présenté dans cette partie est rpart, le plus simple des modèles CART.

\FloatBarrier
```{r, echo = FALSE, fig.height = 4, fig.cap = "Performances du modèle CART (rpart) dans une classification par familles, en fonction du paramètre de complexité"}
plot(MULFAM_fit_rpart_cp_graphe)
```

Ce modèle, pourtant très simple, donne déjà de très bons résultats globaux, avec ($\kappa_{max} =$ `r round(max(MULFAM_fit_rpart_cp_resultats["Kappa"]),3)` et une précision $R_{max} =$ `r round(max(MULFAM_fit_rpart_cp_resultats["Accuracy"]),3)`).

\FloatBarrier

### Forêts aléatoires

\paragraph*{}
Le premier modèle de forêt aléatoire évalué dans cette partie est ranger, que nous avons déjà présenté précédemment. Les graphiques des performances en fonction des hyperparamètres laissent entrevoir d'excellentes caractéristiques sur une large plage d'hyperparamètres.

```{r, echo = FALSE, fig.height = 4, fig.cap = "Performances du modèle Ranger dans une classification par familles, en fonction de ses 2 hyperparamètres (algorithme de scission : gini à gauche, extratrees à droite)"}
plot(ggarrange(
   ncol = 2,
   MULFAM_fit_ranger_Gini_kappa_graphe,
   MULFAM_fit_ranger_ET_kappa_graphe
   )
)
```

Après optimisation des hyperparamètres (*min.node.size* = `r MULFAM_best_rangergrid$min.node.size`, *mtry* = `r MULFAM_best_rangergrid$mtry` et *splitrule* = `r MULFAM_best_rangergrid$splitrule`), ce modèle a donné d'excellents résultats.

```{r, echo = FALSE}
kable(MULFAM_fit_ranger_best_resultats[c(1,2,3,7,8)], digits = 5, caption = "Performances du modèle Ranger (hyperparamètres optimaux)") %>%
   kable_styling(latex_options = c("striped", "hold_position"),full_width = F)
```

\paragraph*{}
Le dernier modèle de forêt aléatoire est Rborist.

```{r, echo = FALSE, fig.height = 4, fig.width = 5.2, fig.cap = "Performances du modèle Rborist dans une classification par familles, en fonction de ses deux hyperparamètres (interpolation quadratique, points expérimentaux encadrés en noir)"}
plot(MULFAM_fit_Rborist_kappa_graphe + theme(legend.position='right')+ theme(legend.text = element_text(angle = 0, vjust = 1, hjust = 0)))
```

\paragraph*{}
Avec des paramètres optimaux (*predFixed* = `r MULFAM_best_Rboristgrid$predFixed` et *minNode* = `r MULFAM_best_Rboristgrid$minNode`), la performance est estimée à :
\FloatBarrier

```{r, echo = FALSE}
kable(MULFAM_fit_Rborist_best_resultats[c(1,2,6,7)], digits = 5, caption = "Performances du modèle Rborist (hyperparamètres optimaux)") %>%
   kable_styling(latex_options = c("striped", "hold_position"),full_width = F)
```
\FloatBarrier
\paragraph*{}
Le modèle Rborist a donné des résultats similaires à ceux du modèle Ranger, avec d'excellentes performances.


### Résultats
Les critères et le protocole de l'évaluation sont les mêmes que ceux évoqués précédemment.

\FloatBarrier
L'évaluation finale du modèle ranger donne la matrice de confusion de la table \ref{tab:FAM-CM}.

```{r FAM-CM, echo = FALSE}
kable(MULFAM_CM_ranger_final$table, caption = "Matrice de confusion du modèle Ranger (prédictions à gauche, références en haut)") %>%
   kable_styling(latex_options = c("striped", "hold_position"),full_width = F, font_size = 5) %>%
  row_spec(0, angle = -90)
```

La précision finale est égale à $R = `r round(MULFAM_CM_ranger_final$overall["Accuracy"], 4)`$, avec un intervalle de confiance à 95% de [`r round(MULFAM_CM_ranger_final$overall["AccuracyLower"], 4)` ; `r round(MULFAM_CM_ranger_final$overall["AccuracyUpper"], 4)`]. La forêt aléatoire de type Ranger a donné d'excellents résultats, en un temps très raisonnable (`r MULFAM_temps_ranger` min).
\paragraph*{}
La forêt aléatoire de type Rborist a donné des résultats similaires, avec une précision finale égale à `r MULFAM_CM_Rborist_final$overall["Accuracy"]`, avec un intervalle de confiance à 95% de [`r round(MULFAM_CM_Rborist_final$overall["AccuracyLower"], 4)` ; `r round(MULFAM_CM_Rborist_final$overall["AccuracyUpper"], 4)`]. Le modèle Rborist, donnant des résultats sensiblement identiques à Ranger, s'est avéré plutôt efficient sur le plan calculatoire (`r MULFAM_temps_Rborist` min).
\paragraph*{}
Nous pouvons noter que le modèle ranger s'est ici avéré plus rapide que Rborist.

```{r, echo = FALSE}
kable(MULFAM_RF_resultat, digits = 5, caption = "Performances des modèles Ranger et Rborist (évaluation)") %>%
   kable_styling(latex_options = c("striped", "hold_position"),full_width = F)

```

\FloatBarrier

\paragraph*{}

\newpage

## Classification par espèce

Dans cette partie, la difficulté de la classification augmente sensiblement, les modèles ne sont plus chargés de classifier les champignons par familles, mais de déterminer précisément l'espèce de chaque spécimen du lot de données. Les modèles utilisés dans cette partie sont les mêmes que ceux de la classification par familles.

### Modèles d'arbres de décision

\paragraph*{}
Comme précédemment, le modèle d'arbre de décision retenu pour la classification par espèces est rpart.

\FloatBarrier
```{r, echo = FALSE, fig.height = 4, fig.cap = "Performances du modèle CART (rpart) dans une classification par espèces, en fonction du paramètre de complexité"}
plot(MULESP_fit_rpart_cp_graphe)
```

Ce modèle, bien que relativement simple, donne encore des résultats honorables, bien que le kappa ($\kappa_{max} =$ `r round(max(MULESP_fit_rpart_cp_resultats["Kappa"]),3)`) comme la une précision ($R_{max} =$ `r round(max(MULESP_fit_rpart_cp_resultats["Accuracy"]),3)`) n'atteignent pas les objectifs de cette étude.

\FloatBarrier

### Forêts aléatoires

\paragraph*{}
Comme lors de la classification par familles, notre premier modèle de forêt aléatoire évalué dans cette partie est ranger. L'exploration de l'espace expérimental des hyperparamètres de ce modèle laisse entrevoir de très bonnes performances sur une large plage d'hyperparamètres.

```{r, echo = FALSE, fig.height = 4, fig.cap = "Performances du modèle Ranger dans une classification par espèces, en fonction de ses 2 hyperparamètres (algorithme de scission : gini à gauche, extratrees à droite)"}
plot(ggarrange(
   ncol = 2,
   MULESP_fit_ranger_Gini_kappa_graphe,
   MULESP_fit_ranger_ET_kappa_graphe
   )
)
```

Après optimisation des hyperparamètres (*min.node.size* = `r MULESP_best_rangergrid$min.node.size`, *mtry* = `r MULESP_best_rangergrid$mtry` et *splitrule* = `r MULESP_best_rangergrid$splitrule`), ce modèle a donné, comme lors des tests précédents, d'excellents résultats, malgré la complexité accrue du problème.

```{r, echo = FALSE}
kable(MULESP_fit_ranger_best_resultats[c(1,2,3,7,8)], digits = 5, caption = "Performances du modèle Ranger (hyperparamètres optimaux)") %>%
   kable_styling(latex_options = c("striped", "hold_position"),full_width = F)
```

\paragraph*{}
Le dernier modèle de forêt aléatoire exploité dans cette tâche de classification par espèces est Rborist.

```{r, echo = FALSE, fig.height = 4, fig.width = 5.2, fig.cap = "Performances du modèle Rborist dans une classification par espèces, en fonction de ses deux hyperparamètres (interpolation quadratique, points expérimentaux encadrés en noir)"}
plot(MULESP_fit_Rborist_kappa_graphe + theme(legend.position='right')+ theme(legend.text = element_text(angle = 0, vjust = 1, hjust = 0)))
```

\paragraph*{}
Avec des paramètres optimaux (*predFixed* = `r MULESP_best_Rboristgrid$predFixed` et *minNode* = `r MULESP_best_Rboristgrid$minNode`), la performance est estimée à :
\FloatBarrier

```{r, echo = FALSE}
kable(MULESP_fit_Rborist_best_resultats[c(1,2,6,7)], digits = 5, caption = "Performances du modèle Rborist (hyperparamètres optimaux)") %>%
   kable_styling(latex_options = c("striped", "hold_position"),full_width = F)
```
\FloatBarrier
\paragraph*{}
Le modèle Rborist a donné des résultats similaires à ceux du modèle Ranger, avec d'excellentes performances en phase d'apprentissage et optimisation.


### Résultats
Les critères et le protocole de l'évaluation sont les mêmes que ceux mentionnés pour les autres tâches de classification.

La précision finale du modèle Ranger est égale à $R = `r round(MULESP_CM_ranger_final$overall["Accuracy"], 4)`$, avec un intervalle de confiance à 95% de [`r round(MULFAM_CM_ranger_final$overall["AccuracyLower"], 4)` ; `r round(MULESP_CM_ranger_final$overall["AccuracyUpper"], 4)`]. La forêt aléatoire de type Ranger a donné d'excellents résultats, en un temps très raisonnable (`r MULFAM_temps_ranger` min).
\paragraph*{}

\FloatBarrier
La matrice de confusion, ne reprenant ici que les espèces ayant posé problème à notre modèle (`r MULESP_erreur_ranger`:`r MULESP_n_eval`), est résumée par la table \ref{tab:ESP-CM-Ranger}.


```{r ESP-CM-Ranger, echo = FALSE}
kable(MULESP_CMerreurs_ranger, caption = "Matrice de confusion des erreurs de Ranger, (prédictions à g., références en h.)") %>%
   kable_styling(latex_options = c("striped", "hold_position"),full_width = F) %>%
  row_spec(0, angle = -90)
```

\FloatBarrier

\paragraph*{}
La forêt aléatoire de type Rborist a donné des résultats très proches de ceux obtenus par le modèle ranger, avec un taux d'erreur de `r MULESP_erreur_Rborist`:`r MULESP_n_eval`.
\paragraph*{}
La précision finale de Rborist est ainsi égale à `r round(MULESP_CM_Rborist_final$overall["Accuracy"],4)`, avec un intervalle de confiance à 95% de [`r round(MULESP_CM_Rborist_final$overall["AccuracyLower"], 4)` ; `r round(MULESP_CM_Rborist_final$overall["AccuracyUpper"], 4)`]. Le modèle Rborist, donnant des résultats proches à Ranger, s'est de plus avéré assez efficient sur le plan calculatoire (`r MULESP_temps_Rborist` min).
\paragraph*{}
Nous pouvons noter que si Rborist affiche des performances marginalement supérieures, le modèle ranger s'est encore une fois avéré sensiblement plus rapide que Rborist sur des problèmes complexes.

```{r, echo = FALSE}
kable(MULESP_RF_resultat, digits = 5, caption = "Performances des modèles Ranger et Rborist (évaluation)") %>%
   kable_styling(latex_options = c("striped", "hold_position"),full_width = F)

```

\paragraph*{}

\newpage

# Robustesse de la classification

*Partie facultative, assez ambitieux, voir si cette partie est compatible (en temps) avec la création du lot de données, qui va être assez chronophage...*

*Evaluation de la robustesse, avec deux stratégies envisageables : *

*1. Robustesse "intrinsèque" : lot d'entraînement standard, lot d'évaluation avec variations. Robustesse des modèles seuls.*

*2. Robustesse "intégrée" : intégration de la robustesse dès le départ, avec lot d'entraînement intégrant des variations représentatives du lot d'évaluation.*

## Robustesse face aux déviations

*Robustesse face à des données hors-normes, sans être extrêmes pour autant.*

*Facile à coder pour valeurs quantitatives (simplement augmenter la SD du générateur...)*

*DIFFICILE à coder pour les valeurs qualitatives (i.e. trouver des proximités, soit manuellement, soit via clustering / KNN)*

*Robustesse "intrinsèque" et "intégrée" *

## Robustesse face aux erreurs

*Robustesse face à des données complètement aberrantes.*

*Facile à coder. Robustesse "intrinsèque" uniquement. *

\FloatBarrier
\newpage

# Références bibliographiques
<div id="refs"></div>

\newpage
# (APPENDIX) Appendix {-} 

# Annexe : développement d'un algorithme de génération de lot synthétique

\paragraph*{}
*Plus de détails concrets sur la méthode utilisée en pratique, avec extraits de code...*
\paragraph*{}
*Pour l'instant, l'algorithme est écrit et fonctionne, à partir des données primaires du Secondary Dataset de Dennis Wagner. C'est cet algorithme qui a servi à créer le lot de données de la classification multiclasse.*
\paragraph*{}
*Pour avoir mes propres lots de données, il ne me reste plus qu'à avoir mes propres données primaires, c'est à dire entrer manuellement les caractéristiques clés de mes 400+ champignons, un par un...*
\paragraph*{} 
La seule bibliothèque utilisée lors de la création du lot de données synthétique est le *tidyverse*[@R-tidyverse], collection de bibliothèques spécialisées dans le domaine de la *data science* et notamment dédiées au traitement, au nettoyage et à la visualisation de données.

\small
```{r, eval = FALSE}
library(tidyverse)
```
\normalsize

Notre algorithme charge ensuite le fichier zip, incluant le fichier csv contenant les caractéristiques typiques des macromycètes (type de sporophore, dimensions maximales du stipe, du chapeau, type de lames, couleur de sporée, etc.), qui est lu et attribué à un *dataframe*. Les lignes commentées correspondent à l'utilisation d'un fichier identique hébergé à distance sur un dépôt GitHub.

\small
```{r, eval = FALSE}
fichier_data <- tempfile()
#URL <- "https://github.com/EKRihani/mushrooms/raw/master/MushroomDataset.zip"
#download.file(URL, fichier_data)
fichier_data <- "~/projects/champis/MushroomDataset.zip"
fichier_data <- unzip(fichier_data, "MushroomDataset/primary_data.csv")
data_champis <- read.csv(fichier_data, 
                         header = TRUE, 
                         sep = ";", 
                         stringsAsFactors = TRUE)
```
\normalsize


etc etc.

\newpage

# Annexe : outils d'analyse exploratoire des données (EDA)

*Code EDA... A développer une fois le jeu de données primaires créé...*

\newpage


# Annexe : développement des algorithmes d'apprentissage machine

\paragraph*{}
Nous détaillerons ici principalement les algorithmes utilisés pour le classifieur binaire. Les particularités d'intérêt des classifieurs multiples seront évoquées brièvement lors des développements de cette section.

## Initialisation

\paragraph*{}
Les bibliothèques utilisées lors des étapes d'apprentissage machine sont :

* tidyverse[@R-tidyverse], collection de bibliothèques spécialisées dans le domaine de la *data science*,
* DiceDesign[@R-DiceDesign], bibliothèque spécialisée dans la création de plans d'expériences hypercubiques,
* DiceEval[@R-DiceEval], bibliothèque spécialisée dans la modélisation des résultats de plans d'expériences hypercubiques,
* caret[@R-caret], collection d'outils dédiés à l'apprentissage machine.
* twinning[@R-twinning], outils dédiés à la génération de jeux de données d'entraînement, optimisation, validation équilibrés.

\small
```{r, eval = FALSE}
library(tidyverse)
library(DiceDesign)
library(DiceEval)
library(caret)
library(twinning)
```
\normalsize

\paragraph*{}
Le chargement des données s'effectue de la même façon que lors des sections précédentes. L'argument *stringsAsFactors = TRUE* revêt une importance particulière, car la classe *factor* est essentielle au bon fonctionnement des classifieurs. Dans le cadre d'une classification binaire, nous définissons arbitrairement, à l'aide de la fonction *relevel*, la classe *"toxique"* comme étant la valeur positive. Cette définition n'est pas nécessaire pour les classifieurs multiclasses.

\small
```{r, eval = FALSE}
fichier_data <- tempfile()
fichier_data <- "~/projects/champis/MushroomDataset.zip"
fichier_data <- unzip(fichier_data, "MushroomDataset/secondary_data.csv")
dataset <- read.csv(fichier_data, 
                    header = TRUE, 
                    sep = ";", 
                    stringsAsFactors = TRUE)
dataset$class <- recode_factor(dataset$class, e = "comestible", p = "toxique")   
# /!\ recode utilisé uniquement pour le Wagner !!!
dataset$class <- relevel(dataset$class, ref = "toxique")
```
\normalsize

## Création des jeux d'entraînement, optimisation et évaluation

La création du jeu d'évaluation s'effectue en deux étapes. La première est la définition des rapports des dichotomies entre jeux d'entraînement et optimisation d'une part, et d'évaluation d'autre part. Cette définition implique l'évaluation du nombre d'individus, le calcul du nombre de coefficients $p$, puis du rapport de dichotomie $f = \sqrt(p) +1$.\footnote{cf. section \ref{chapitre:split}, page \pageref{paragraphe:split_ratio}.}

\small
```{r, eval = FALSE}
BI_n_champis <- nrow(dataset)
BI_split_p <- sqrt(BI_n_champis)
BI_split_facteur <- round(sqrt(BI_split_p)+1)
```
\normalsize

La seconde partie consiste à effectuer la scission proprement dite. Cette scission implique la définition d'une liste d'index, de fraction $1:f$ du nombre d'individus, qui servira via inclusion (jeu d'évaluation) ou exclusion (jeu d'apprentissage et d'évaluation) booléennes des lignes correspondantes, à de constituer chaque jeu de données. La fonction *set.seed* assure la reproductibilité.
\small
```{r, eval = FALSE}
set.seed(7)
index1 <- twin(data = dataset, r = BI_split_facteur)
BI_lot_appr_opti <- dataset[-index1,]
BI_lot_evaluation <- dataset[index1,]
```
\normalsize
Les lots ainsi obtenus seront ensuite utilisés pour l'entraînement, l'optimisation et l'évaluation finale des performances des modèles.

## Entraînement et optimisation des modèles

Cette partie ne prétend pas à l'exhaustivité, elle se limitera à la présentation de l'entraînement, l'optimisation et la génération de graphiques pour deux modèles : un modèle CART (rpart) et un modèle RF (Rborist). Un certain nombre de tâches telles que l'entraînement du modèle ou la génération de graphiques sont en réalité attribuées à des fonctions créées *adhoc* dans le but de clarifier l'organisation du code de l'algorithme, car elles sont effectuées à de nombreuses reprises. Nous décrirons ici le code source sans faire appel à ces fonctions.

### Arbre de classification et régression {#chapitre:code-CART}

La première étape est de définir l'indice J de Youden,\footnote{cf. section \ref{chapitre:perf}, page \pageref{chapitre:perf}} et les pondérations respectives de la sensibilité et de la spécificité. Cette définition n'est pas nécessaire pour les classifieurs multiclasse, le kappa ($\kappa$) et l'indice de Rand ($R$) étant des métriques évaluées nativement par la librairie *caret*.
\small
```{r, eval = FALSE}
BI_w <- 10
BI_RatioSens <- 2*BI_w/(BI_w+1)
BI_RatioSpec <- 2*(1-BI_w/(BI_w+1))
```
\normalsize
La seconde définition à préciser est celle de l'espace expérimental des hyperparamètres. En l'espèce le seul hyperparamètre du modèle rpart est la variable *cp*.
\small
```{r, eval = FALSE}
BI_grid_rpart_cp <- data.frame(cp = 10^seq(from = -5, to = -1, by = .5))
```
\normalsize

\label{paragraphe:train-CART}
L'étape suivante est de définir les paramètres d'entraînement et d'évaluation des performances du modèle en vue de son optimisation. La fonction *trainControl* permet ici de préciser les principaux paramètres régissant cette étape :

* *classProbs*, *[TRUE indispensable au fonctionnement...]*
* *summaryFunction*, afin d'indiquer que les métriques de performance à utiliser sont celles d'un classifieur binaire (l'argument *multiClassSummary* sera utilisé pour un classifieur multiclasse)
* *method*, afin de préciser la méthode de construction des jeux d'entraînement et d'optimisation, ici validation croisée (*CV: cross-validation*)
* *number*, afin d'indiquer le nombre de blocs de la validation croisée, calculé précédemment.

\paragraph*{}
Ici aussi, la fonction *set.seed* assure la reproductibilité du processus.
\small
```{r, eval = FALSE}
set.seed(1)
tr_ctrl <- trainControl(classProbs = TRUE,
                        summaryFunction = twoClassSummary,
                        method = "cv",
                        number = BI_split_facteur)
```
\normalsize

L'entraînement du modèle peut avoir lieu. En l'espèce, le modèle mathématique retenu est l'attribution d'une prédiction sur *class* en fonction de toutes les autres variables (*class ~ .*). Les arguments *data*, *trControl*, *tuneGrid* font appel aux éléments décrits dans les paragraphes qui précèdent.

\small
```{r, eval = FALSE}
BI_fit_rpart_cp <- train(class ~ .,
                         method = "rpart",
                         data = BI_lot_appr_opti,
                         trControl = tr_ctrl,
                         tuneGrid  = BI_grid_rpart_cp)
```
\normalsize

L'objet résultant est d'une structure relativement complexe. Notre algorithme peut notamment en extraire les résultats relatifs aux performances du modèle, et y adjoindre le calcul du J de Youden pondéré $J_{w}$. Dans le cadre des classifieurs multiclasses, ce calcul est inutile, l'objet généré à l'étape précédente contenant déjà les indicateurs de performance que nous utilisons : kappa ($\kappa$) et indice de Rand ($R$, *accuracy*).

\small
```{r, eval = FALSE}
BI_fit_rpart_cp_resultats <- BI_fit_rpart_cp$results %>% 
   mutate(Jw = Sens*BI_RatioSens + Spec*BI_RatioSpec - 1)
```
\normalsize

L'objet de type *dataframe* ainsi créé peut être appelé afin d'en extraire des résultats d'intérêt ou d'en inclure le tableau dans le rapport :

\small
```{r, echo = FALSE}
kable(BI_fit_rpart_cp_resultats, caption = "Tableau des résultats de l'entraînement de rpart") %>%
  kable_styling(font_size = 10)
```
\normalsize

L'algorithme génère également un graphique synthétisant les performances du modèle (sensibilité, spécificité, $J_{w}$, $\kappa$, $R$ ou autre indicateur d'intérêt) en fonction de son hyperparamètre :

* *ggplot* est la fonction de génération du graphique, et permet d'appeler l'objet servant à générer le graphique, ainsi que certains paramètres complémentaires via *aes*. Ici, la variable servant d’abscisse.
* *geom_point* permet de tracer le nuage de points. Ici encore, *aes* permet de préciser, pour chaque nuage de points, la variable d'ordonnée (*Sens*, *Spec* ou *Jw*), ainsi que la légende associée à la couleur des points (*Sensibilité*, *Spécificité* ou *Jw*).
* *geom_line* permet de tracer les lignes correspondant au nuage de points.
* *labs* permet de légender correctement l'attribut *color* de notre légende.
* *ylab* permet de définir la légende l'axe des ordonnées. Ici, de la supprimer, car nous avons trois variables différentes en ordonnées.
* *scale_x_log10* nous permet ici de définir un axe logarithmique décimal en abscisse.
* *theme_bw* attribue le thème(couleur de fond, d'axes, grilles) de type *bw* (*black and white*) à notre graphique.

\small
```{r, eval = FALSE}
BI_fit_rpart_cp_graphe <- ggplot(data = BI_fit_rpart_cp_resultats, aes(x = cp)) +
   geom_point(aes(y = Sens, color = "Sensibilité")) +
   geom_line(aes(y = Sens, color = "Sensibilité")) +
   geom_point(aes(y = Spec, color = "Spécificité")) +
   geom_line(aes(y = Spec, color = "Spécificité")) +
   geom_point(aes(y = Jw, color = "Jw")) +
   geom_line(aes(y = Jw, color = "Jw")) +
   labs(color = "Performance") + 
   ylab(NULL) + 
   scale_x_log10() +
   theme_bw()
```
\normalsize

Le graphique ainsi généré peut être intégré dans notre rapport :
\FloatBarrier

```{r, echo = FALSE, fig.height = 3, fig.width = 4, fig.cap = "Graphique des performances de rpart"}
plot(BI_fit_rpart_cp_graphe)
```

\FloatBarrier

### Rborist

La première étape est, comme précédemment, de définir l'espace expérimental. Ici, s'agissant d'un modèle à plusieurs hyperparamètres, l'algorithme utilisera un plan d'expériences basé sur les hypercubes latins. La fonction *nolhDesign* permet de créer un hypercube latin quasi-orthogonal (NOLH : *Near Orthogonal Latin Hypercube*), ici paramétré avec 2 dimensions, dans l'espace $[0;1]^{2}$. Le plan d'expérience en est extrait, puis inséré dans un objet de type *dataframe*, avec colonnes nommées d'après nos variables réduites $X_{1}$ et $X_{2}$.

\small
```{r, eval = FALSE}
BI_LHS <- nolhDesign(dimension = 2, range = c(0, 1))$design 
BI_LHS <- data.frame(BI_LHS)
colnames(BI_LHS) <- c("X1", "X2")
```
\normalsize

L'hypercube latin des hyperparamètres (*predFixed* et *minNode*) est généré à partir de l'hypercube latin des paramètres réduits. Ces hyperparamètres sont des valeurs entières. L'hypercube latin quasi-orthogonal de dimension 2 possédant 17 expériences équitablement réparties dans l'espace $[0;1]^{2}$, il apparaît souhaitable, pour des raisons d'homogénéité dans l'espace expérimental, que $F_{n} = k \times X_{n}$ avec $k$ multiple de 16. En pratique, nous n'avons jamais rencontré d'erreurs d'arrondi lors de cette étape mais l'usage de la fonction *round* constitue une précaution supplémentaire garantissant que le produit sera bien un entier.

\small
```{r, eval = FALSE}
BI_grid_Rborist <- data.frame(BI_LHS) %>%
   mutate(predFixed = round(1+X1*16,0)) %>%
   mutate(minNode = round(1+X2*16,0))
```
\normalsize
\FloatBarrier

```{r, echo = FALSE}
kable(BI_grid_Rborist, caption = "Plan d'expériences d'entraînement et optimisation du modèle Rborist")
```

\FloatBarrier
L'entraînement du modèle se déroule de la même façon que pour le modèle rpart.\footnote{cf. section \ref{chapitre:code-CART}, page \pageref{paragraphe:train-CART}.}

\small
```{r, eval = FALSE}
set.seed(1)
tr_ctrl <- trainControl(classProbs = TRUE,
                        summaryFunction = twoClassSummary,
                        method = "cv",
                        number = BI_split_facteur)
BI_fit_Rborist <- train(class ~ .,
                         method = "Rborist",
                         data = BI_lot_appr_opti,
                         trControl = tr_ctrl,
                         tuneGrid  = BI_grid_Rborist[c('predFixed', 'minNode')])
```
\normalsize

L'algorithme extrait les résultats relatifs aux performances du modèle et y adjoint le calcul de $J_{w}$ (ou $\kappa$ pour les classifieurs multiclasses), comme précédemment. L'objet obtenu ne contenant que les facteurs expérimentaux (non réduits) des hyperparamètres, il convient d'y adjoindre les facteurs réduits. La table *BI_grid_Rborist* générée précédemment contient toutes les informations qui permettent, via une jonction, de lier facteurs réduits et facteurs expérimentaux.

\small
```{r, eval = FALSE}
BI_fit_Rborist_resultats <- BI_fit_Rborist$results %>% 
   mutate(Jw = Sens*BI_RatioSens + Spec*BI_RatioSpec - 1) %>%
   left_join(x = .,
             y = BI_grid_Rborist,
             by = c("predFixed", "minNode"))
```
\normalsize

Nous chargeons ensuite notre algorithme de calculer le modèle quadratique avec interactions permettant d'évaluer, à partir des résultats obtenus suite à l'entraînement, la réponse $J_{w}$ en fonction des $X_{1}$ et $X_{2}$, suivant la formule :
$$ Y = b_{0} + b_{1}.X_{1} + b_{2}.X_{2} + b_{12}.X_{1}.X_{2} + b_{11}.X_{1}^{2} + b_{22}.X_{2}^{2}$$

\small
```{r, eval = FALSE}
BI_mod_Rborist_jw <-  modelFit(X = BI_fit_Rborist_resultats[,c("X1", "X2")], 
                               Y = BI_fit_Rborist_resultats$Jw,  
                               type="Kriging", 
                               formula= Y ~ X1 + X2 + X1:X2 + I(X1^2) + I(X2^2))
```
\normalsize

Ces résultats permettent notamment de modéliser les performances sur la totalité de l'espace expérimental des hyperparamètres. A cette fin, l'algorithme est chargé de générer l'ensemble des couples de valeurs $(X_{1},X_{2})$ possibles, à l'aide de la fonction *expand.grid*, avant de calculer la valeur $J_{w}$ correspondante à chaque couple de points.

\small
```{r, eval = FALSE}
CodBI_pred_Rborist <- expand.grid(CodBI_fit_Rborist_resultats[,c("X1","X2")]) %>%
   mutate(Jw = modelPredict(CodBI_mod_Rborist_jw, .[,c("X1","X2")]))
```
\normalsize

L'ensemble des données expérimentales et modélisées obtenues permettent de générer un graphique bidimensionnel des performances en fonction des hyperparamètres. Pour des raisons didactiques, nous séparerons ici le graphique résultant de l'expérimentation de celui résultant de la modélisation quadratique.
\paragraph*{}
La génération du graphique reprend des principes similaires à ceux présentés précédemment pour le graphique des performances de rpart, notamment au niveau des arguments utilisés dans *aes*. Les seules fonctions appelant à commentaires sont l'utilisation de *geom_raster* pour la modélisation, à laquelle nous superposons le graphique généré via *geom_tile* pour les points expérimentaux. L'utilisation de la gamme de couleurs proposée par *viridis* permet une visualisation plus aisée des résultats obtenus.

\small
```{r, eval = FALSE}
BI_pred_Rborist %>% ggplot() +
   geom_raster(data = BI_pred_Rborist,
               aes(x = X1, y = X2, fill = Jw), interpolate = TRUE) +
   geom_tile(data = BI_fit_Rborist_resultats,
             aes(x = X1, y = X2, fill = Jw), color = 'black', linewidth =.5) +
   scale_fill_viridis_c(option = "D", direction = 1) +
   theme(axis.text.y = element_text(angle=90, vjust=.5, hjust=.5)) +
   theme_bw()
```
\normalsize

\FloatBarrier

```{r, echo = FALSE, fig.height = 3, fig.cap = "Points expérimentaux (à gauche), modélisation (au centre) et superposition (à droite) des résultats obtenus avec Rborist"}
plot(ggarrange(
   ncol = 3, widths = c(1.05,1,1),
   CodBI_Rborist_graphe_tiles,
   CodBI_Rborist_graphe_raster + ylab(NULL),
   CodBI_Rborist_graphe_full + ylab(NULL)))
```

\FloatBarrier

L'étape suivante est d'exploiter ce modèle quadratique pour évaluer les hyperparamètres permettant de maximiser $J_{w}$. A cet effet, une table de l'ensemble des points de l'espace expérimental des facteurs réduits est générée, puis la fonction quadratique évaluée précédemment est appliquée, afin d'obtenir une prédiction approximative de $J_{w}$. Les hyperparamètres sont également calculés, afin de pouvoir être appliqués par la suite.

\small
```{r, eval = FALSE}
BI_modelquad_Rborist <- expand.grid(X1 = seq(from = 0, to = 1, length.out = 17),
                                  X2 = seq(from = 0, to = 1, length.out = 17)) %>%
   mutate(Jw = BI_mod_Rborist_jw$model@trend.coef[1] +
             BI_mod_Rborist_jw$model@trend.coef[2]*X1 +
             BI_mod_Rborist_jw$model@trend.coef[3]*X2 +
             BI_mod_Rborist_jw$model@trend.coef[4]*X1^2 +
             BI_mod_Rborist_jw$model@trend.coef[5]*X2^2 +
             BI_mod_Rborist_jw$model@trend.coef[6]*X1*X2) %>%
   mutate(predFixed = round(1+X1*16,0)) %>%
   mutate(minNode = round(1+X2*16,0))
```
\normalsize

Le $J_{w}$ théorique maximal est ensuite évalué, ainsi que les hyperparamètres qui y sont associés.
\small
```{r, eval = FALSE}
BI_modelquad_Rborist_top <- BI_modelquad_Rborist[which.max(BI_modelquad_Rborist$Jw),
                                                 c("predFixed", "minNode")]
```
\normalsize

Il est ensuite possible de relancer un entraînement, comme précédemment, avec les paramètres optimisés, et en extraire les indicateurs de performances ($J_{w}$).

\small
```{r, eval = FALSE}
set.seed(1)
BI_fit_Rborist_best <- train(class ~ .,
                 method = "Rborist",
                 data = BI_lot_appr_opti,
                 trControl = tr_ctrl,                                    
                 tuneGrid  = BI_modelquad_Rborist_top[c('predFixed', 'minNode')])

BI_fit_Rborist_best_resultats <- BI_fit_Rborist_best$results %>% 
      mutate(Jw = Sens*CodBI_RatioSens + Spec*CodBI_RatioSpec - 1)
```
\normalsize

## Évaluation des performances des modèles

L'étape finale est celle de l'évaluation des performances du modèle, ici présentée pour Rborist. Cette évaluation commence par l'extraction des valeurs réelles de comestibilité -- c'est à dire des réponses attendues de la part de notre modèle -- à partir du jeu de données d'évaluation, ainsi que leur conversion en valeurs booléennes, à fins de comparaison avec les valeurs qui seront prédites. Cette étape n'est évidemment pas nécessaire lors d'une classification multiclasse.

\small
```{r, eval = FALSE}
BI_evaluation <- BI_lot_evaluation %>%
   mutate(reference = as.factor(case_when(class == "toxique" ~ TRUE, 
                                          class == "comestible" ~ FALSE)))
```
\normalsize


Les performances du modèle peuvent être évaluées, en termes d'efficience calculatoire, par son temps d'éxécution. Un moyen de mesurer le temps d'éxécution de n'importe quelle portion de code est de mesurer l'heure de début et de fin d'éxécution du code à l'aide de *Sys.time*, puis d'en mesurer la différence via la fonction *difftime*.
\paragraph*{}
Le code exécuté correspond ici à l'entraînement du modèle (cf. *supra*) et à la prédiction sur le lot d'évaluation, enregistré dans un objet dédié.

\small
```{r, eval = FALSE}
chrono_debut <- Sys.time()
BI_fit_Rborist_final <- train(class ~ .,
                  method = 'Rborist',
                  data = BI_lot_appr_opti,
                  trControl = tr_ctrl,
                  tuneGrid  = BI_modelquad_Rborist_top[c('predFixed', 'minNode')])
BI_pred_Rborist_final <- predict(object = BI_fit_Rborist_final, 
                                 newdata = BI_lot_evaluation)
chrono_fin <- Sys.time()
CodBI_temps_Rborist <- difftime(chrono_fin, chrono_debut) %>% 
   as.numeric %>% 
   round(.,2)
```
\normalsize

L'objet correspondant aux prédictions est ensuite comparé aux valeurs références que notre modèle devait prédire, ce qui permet notamment d'obtenir la matrice de confusion associée aux prédictions.

\small
```{r, eval = FALSE}
BI_CM_Rborist_final <- confusionMatrix(data = BI_pred_Rborist_final, 
                                       reference = BI_lot_evaluation$class)
BI_CM_Rborist_final$table
```
\normalsize

Nous pouvons également extraire de cette comparaison des indicateurs de performances : sensibilité, spécificité, $J_{w}$ dans le cas d'une classification binaire, kappa et indice de Rand pour la classification multiclasse, ainsi que le temps de calcul.
\small
```{r, eval = FALSE}
BI_resultats_Rborist <- BI_CM_Rborist_final$byClass %>% 
   t(.) %>% 
   as.data.frame(.) %>% 
   select(c(Sensitivity, Specificity)) %>% 
   mutate(Jw = Sensitivity*BI_RatioSens + Specificity*BI_RatioSpec - 1) %>%
   mutate(temps = BI_temps_Rborist)
```
\normalsize

Enfin, les principaux objets volumineux qui n'ont pas vocation à être exploités par la suite -- c'est-à-dire les jeux de données, ainsi que les objets issus des fonctions *train* -- sont retirés de l'environnement, qui est ensuite sauvegardé. Cette sauvegarde contient les graphiques, tableaux et valeurs d'intérêt, à fins d'insertion automatisée dans le fichier Rmarkdown qui constitue le corps de texte de cette thèse.

\small
```{r, eval = FALSE}
rm(dataset, BI_evaluation, BI_lot_appr_opti, BI_lot_evaluation, 
   BI_fit_rpart_cp, BI_fit_Rborist, BI_fit_Rborist_best, BI_fit_Rborist_final)

save.image(file = "EKR-Champis-CodeSourceBi.RData")
```
\normalsize

\newpage
