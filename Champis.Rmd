---
#title: "Application de modèles d'Intelligence Artificielle à la classification des macromycètes"
#author: "Emir Kaïs RIHANI"
#date: "`r format(Sys.time(), '%d %B, %Y')`"
lang: fr
geometry: "left=2.5cm,right=2.5cm,top=1.5cm,bottom=2cm"        # Imposé par la fac
fontsize: 12pt          # Imposé par la fac
output: 
  bookdown::pdf_document2: 
    number_sections: yes
    extra_dependencies: float
    toc: yes
    toc_depth: 3
    includes:
      before_body: couverture.tex
      after_body: quatrieme.tex
header-includes:
  - \renewcommand{\familydefault}{\sfdefault}   # Police sans serif sur tout le doc
  - \usepackage{pdfpages}   # Pour ajout PDF listes des profs / disclaimer
  - \usepackage{placeins}   # pour bloquer ces %#@$§£ de floats
  - \usepackage{amssymb}   # Symboles mathématiques (loi normale...)
  - \setlength{\abovecaptionskip}{-10pt plus 3pt minus 2pt}    # Espacement des légendes (above/below)
indent: true
bibliography: [packages.bib, Champis.bib]
csl: https://www.zotero.org/styles/vancouver-superscript
---

```{r setup, include = FALSE, warning=FALSE}
load("EKR-Champis-Intro.RData")      # Chargement des résultats INTRO
library(ggpubr)   # Combiner graphes (ggarrange)
library(rmarkdown)
library(knitr)
library(tidyverse)
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, fig.pos = "!H")
knitr::write_bib(c("tidyverse", "microbenchmark",  "caret",  "rmarkdown", "GGally", "plyr", "MASS", "mda", "rpart", "C50", "party", "ranger", "Rborist", "e1071", "rFerns", "knitr", "ggpubr"), "packages.bib")
```
\pagestyle{plain}
\newpage
# Introduction
## Propos liminaire

L'identification des macromycètes est un sujet difficile, ne devant évidemment pas être pris à la légère. Les espèces rencontrées varient considérablement d'un écosystème à un autre, d'un continent à un autre, et aucun lot de données ni ouvrage sur les champignons ne saurait couvrir toute la diversité du monde fongique.
\paragraph*{}
Le lot de données mycologiques constitué dans cette étude, bien que constituant l'un des lots en libre accès les plus complets du domaine de la *data science*, n'est bien entendu pas exhaustif.
\paragraph*{}
Ce lot se concentre exclusivement sur les champignons habituellement rencontrés au Nord de la France. Plusieurs genres, parfois très connus, ne sont pas présents, parmi lesquels nous pouvons par exemple citer le genre  *psylocybe*, connu pour ses propriétés psychédéliques. Certains critères pourront également varier de manière considérable selon le stade de maturité du champignon : alors que les chapeaux vert-olive de l'*Amanita phalloides* mature sont faciles à reconnaître, les spécimens jeunes sont blancs et pourraient facilement être confondus avec des espèces comestibles (par exemple du genre *Agaricus*).
\paragraph*{}
L'ingestion de certains de ces champignons est *mortelle*, même à de petites doses. Le diagnostique de l'intoxication fongique peut être difficile, et parfois trop tardif pour un traitement efficace. Des composés toxiques tels que les amanitines ne sont pas altérés ou détruits par cuisson ou congélation, et seront absorbés par l'intestin, avant de passer dans la circulation sanguine afin d'être filtrés par le foi, détruisant les cellules hépatiques, puis excrétées dans l'intester, réabsorbées, refiltrées... chaque passe détruisant les cellules hépatiques ayant survécu à la précédente, dans un cycle connu sous le nom de réabsorption hépato-entérique.
\paragraph*{}
Il ne faut jamais, *sous aucune circonstance*, utiliser ce type de lot de données afin de déterminer si un champignon est comestible ou non.

## But de l'étude
\paragraph*{}
L'identification des plantes et champignons est un problème de classification classique, qui est habituellement effectué manuellement à l'aide de clés d'identification. La plupart de ces clés sont basées sur un processus utilisant des arbres décisionnels, ce qui semble logique car rappelant la logique en arbre de l'évolution. Toutefois, cet argument rencontre quelques limites :
\paragraph*{}
La première limite est le nombre de chaînons manquants. Certaines espèces sont évidemment éteintes, ce qui signifie que certaines branches et noeuds de l'arbre phylogénétique sont manquants, ce qui peut compliquer l'analyse quand deux espèces apparentées ont un nombre élevé de chaînons et noeuds communs manquants. Certaines similarités entre espèces peuvent également ne pas être identifiées.
\paragraph*{}
La seconde limite, plus profonde, est la logique inhérente au processus évolutionnaire. Deux phénomènes antagonistes sont en jeu : convergence et divergence évolutives. Ces deux phénomènes sont liés à la nécessaire adaptation des espèces à leurs environnements. La divergence évolutive explique par exemple la diversité des mammifères : les chauves-souris, baleines et chevaux sont apparentés, mais ont un aspect très différent en raison de leur adaptation à des environnements très différents. D'un autre côté, la convergence évolutive explique la similarité entre l'aile de la chave-souris et l'aile de l'abeille. Toutefois, malgré leur apparente dissimilarité, l'aile de la chauve-souris est plus proche de la main humaine ou de la nageoire de la baleine que de l'aile de l'abeille. La façon la plus fiable pour évaluer le processus évolutionnaire et trouver les liens phylogénétiques de la manière la plus précise est l'analyse des génomes : les caractéristiques visibles peuvent être trompeuses. Malheureusement, ces caractéristiques sont souvent les seules aisément observables.
\paragraph*{}
Le troisième problème est le critère principal de la classification. Ce critère peut être lié ou non au processus évolutionnaire ou aux critères visible, surtout si ce critère principal est vague. Le critère de comestibilité ou de non-comestibilité retenu pour les lots de données mycologiques usuellement utilisés en *data science* souffre de ce problème : il est essentiellement centré sur la toxicité contre les humains, de nombreux mécanismes de toxicité peuvent exister, et une toxicité ou non-toxicité d'un métabolite fongique ou végétal peut être liée à des variations métaboliques très ténues entre une espèce et une autre.
\paragraph*{}
Pour ces raisons parmi d'autres, la logique arborescente, bien qu'utilisée habituellement dans l'identification des champignons et des plantes, et souvent justifiée par la nature arborescente du processus évolutif, pourrait ne pas nécessairement être l'approche optimale à la classification des espèces basée sur des critères macroscopiques. Le but de cette étude est d'effectuer cette tâche de classification basée sur des indices visuels limités, et d'évaluer les performances relatives de différentes stratégies de classification.

## Etat de l'art des lots de données mycologiques
Le tout premier lot de données mycologiques en libre accès mentionné en data science est probablement le *Mushroom Dataset* créé par Jeff Schlimmer en 1987.[@schlimmer_mushroom_1987]
\paragraph*{}
Un lot de données plus conséquent a été publié par Dennis Wagner en 2021[@wagner_mushroom_2021] et mis en libre accès sous le nom de *Secondary Mushroom Dataset*.

\newpage
# Création du lot de données
## Configuration matérielle et logicielle
\paragraph*{}
\FloatBarrier
Le code d'apprentissage machine, les méthodes d'évaluation, ainsi que cette thèse ont été rédigés sur l'équipement suivant :

* CPU : AMD Ryzen 5 5600G
* RAM : 2x16 Go DDR4-3200
* SSD : Crucial P5 M2 NVMe
* OS : Xubuntu Linux 20.04 LTS
* R : version `r paste0(R.version$major, ".", R.version$minor, " (", R.version$year, ")")`
* RStudio : version `r paste0(rstudioapi::versionInfo()$version, ' "', rstudioapi::versionInfo()$release_name, '"')`
* Librairies : tidyverse[@R-tidyverse] (v`r packageVersion("tidyverse")`), microbenchmark[@R-microbenchmark] (v`r packageVersion("microbenchmark")`), SPlit[@R-SPlit] (v`r packageVersion("SPlit")`),, MASS[@R-MASS] (v`r packageVersion("MASS")`), caret[@R-caret] (v`r packageVersion("caret")`), ?GGally?[@R-GGally] (v`r packageVersion("GGally")`), ?mda?[@R-mda] (v`r packageVersion("mda")`), rpart[@R-rpart] (v`r packageVersion("rpart")`), ?plyr?[@R-plyr] (v`r packageVersion("plyr")`), C50[@R-C50] (v`r packageVersion("C50")`), party[@R-party] (v`r packageVersion("party")`), ranger[@R-ranger] (v`r packageVersion("ranger")`), e1071[@R-e1071] (v`r packageVersion("e1071")`), rFerns[@R-rFerns] ((v`r packageVersion("rFerns")`)), Rborist[@R-Rborist] (v`r packageVersion("Rborist")`),  rmarkdown[@R-rmarkdown] (v`r packageVersion("rmarkdown")`), knitr[@R-knitr] (v`r packageVersion("knitr")`), ggpubr[@R-ggpubr] (v`r packageVersion("ggpubr")`).

\FloatBarrier
## Conception d'un lot de données synthétiques
### Principes généraux{#generation-data}
\paragraph*{}
Un lot de données synthétiques est un lot de données généré par un algorithme, par opposition aux lots de données issus d'une collecte effectuée en "vie réelle". 
\paragraph*{}
\FloatBarrier
Trois stratégies sont usuellement utilisées :

* Données factices (*dummy data*) : l'ensemble des données est généré aléatoirement.
* Données générées à partir de règles (*rule-based data*) : l'ensemble des données est généré suivant des lois définies au préalable (distribution, valeurs moyennes, minimales, maximales...)
* Données générées par l'IA (*AI generated*) : l'ensemble des données est généré suivant des lois extraites par l'IA suite à l'analyse d'un échantillon de données obtenues en "vie réelle".

\FloatBarrier
\paragraph*{}
Les données générées par ces stratégies peuvent être de type variés, que nous pouvons grossièrement regrouper en données alphanumériques (quantitatives et qualitatives) et en données d'imagerie.
\paragraph*{}
Pour des raisons pratiques, la méthode retenue pour créer le lot de données exploité dans notre étude sera la génération de données alphanumériques à partir de règles, extraites d'ouvrages mycologiques de référence.[@courtecuisse_cle_1986; @courtecuisse_champignons_2013; @courtecuisse_initiation_2020]

### Génération des paramètres quantitatifs
\paragraph*{}
\FloatBarrier
Dans le cadre de cette étude, les variables quantitatives générées aléatoirement sont :

* La longueur du stipe $L_{S}$,
* Le diamètre du stipe $D_{S}$,
* Le diamètre du chapeau $D_{C}$.

\FloatBarrier
\paragraph*{}
En première approximation, nous pouvons considérer que toutes ces valeurs sont intrinsèquement liées à la croissance du champignon. Ces trois variables peuvent, dans l'absolu, être susceptibles de varier indépendamment des autres au cours de la croissance du champignon, les variables $L_{S}$, $D_{S}$ et $D_{C}$ obéissant alors aux lois suivantes :

$$\left \{
\begin{array}{l}
L_{S} = L_{Smax}.F_{Ls} \\
D_{S} = D_{Smax}.F_{Ds} \\
D_{C} = D_{Cmax}.F_{Dc} \\
\end{array}
\right.$$

\FloatBarrier
Avec :

* $L_{Smax}$, $D_{Smax}$ et $D_{Cmax}$ les valeurs maximales de longueur de stipe, diamètre du stipe et diamètre de chapeau de chaque variété de champignon, extraites de la littérature, 
* $F_{Ls}$, $F_{Ds}$, $F_{Dc}$ des variables générées aléatoirement dans l'intervalle ]0;1], et représentatives de la croissance du spécimen.

\FloatBarrier

Toutefois, la recherche bibliographique sur la cinétique de croissance des sporophores n'ayant pas permis de distinguer de différences de la cinétique de croissance de chacun de ces trois paramètres, nous supposerons en première approximation que la croissance du stipe en longueur, en largeur, ainsi que la croissance du chapeau s'effectuent à des vitesses identiques, nous obtenons donc :

$$F_{Ls} = F_{Ds} = F_{Dc} = F_{T}$$
Avec $F_{T}$ un facteur représentatif de la taille globale de chaque spécimen généré aléatoirement.

\paragraph*{}
Ainsi, le problème de génération de nos trois variables aléatoires se simplifie en un problème de génération d'une seule variable aléatoire : le facteur de taille de chaque spécimen. Un certain nombre de distributions d'intérêt sont susceptibles d'être utilisées afin de générer des facteurs de taille $F_{T}$ aléatoires, il convient donc de définir le cahier des charges de la distribution la plus adaptée au sujet de cette étude.
\paragraph*{}
\FloatBarrier
Les critères de sélection retenus afin de choisir la loi la plus appropriée sont :

* Efficience calculatoire,
* Distribution continue,
* Distribution bornée, ou aisément normalisable sur un intervalle [0;1],
* Distribution asymétrique.

\FloatBarrier
\paragraph*{}
Le premier critère n'est, en pratique, pas un facteur limitant, les temps de calcul pour la génération d'un nombre de facteurs de taille $F_{T}$ suffisant étant typiquement inférieurs à `r chrono_typique` ms (pour `r n_chrono` itérations) avec la plupart des distributions d'intérêt (voir figure \@ref(fig:Lots-Chrono)).


```{r Lots-Chrono, echo = FALSE, fig.height = 4, fig.cap = paste0("Temps de calcul des principales distributions d'intérêt pour ", n_chrono, " itérations")}
plot(chrono_distrib)
```

\paragraph*{}
Les critères de continuité et de normalité n'appellent que peu de commentaires. Ces critères permettent simplement de garantir la possibilité d'une infinité de valeurs dimensionnelles dans l'intervalle considéré. Le critère de continuité proscrit toutefois l'utilisation de lois de distributions discrètes telles que la loi binomiale ou la loi de Poisson, et celui de normalité écarte des distributions telles que la loi de Weibull, dont la normalisation est parfois délicate.
\paragraph*{}
\FloatBarrier
Le critère d'asymétrie est un critère permettant de tenir compte des différents paramètres pouvant impacter la distribution de taille des spécimens prélevés, parmi lesquels :

* Différences de cinétique de croissance d'une famille à une autre,
* Particularités de la croissance fongique, notamment par la croissance hyphale, [@money_insights_2008; @porter_hyphal_2022]
* Probabilité de prélèvement variable selon la taille du spécimen (par difficulté de détection, considérations éthiques, intérêt mycologique ou gastronomique...).

\FloatBarrier
\paragraph*{}
Le premier paramètre évoqué précédemment n'a pu être exploité dans le cadre de cette étude en raison du manque de données concernant les cinétiques relatives de croissance des sporophores des différentes familles de macromycètes. Le modèle que nous proposons permet toutefois des développements ultérieurs dans ce domaine.
\paragraph*{}
Les deux derniers paramètres permettent de supposer que la distribution de taille des spécimens d'une même espèce à l'issue d'une récolte en vie réelle ne sera pas symétrique, d'une part en raison de la rapidité de la croissance fongique, et d'autre part parce que le prélèvement se fera préférentiellement en épargnant les spécimens de petite taille.
\paragraph*{}
Ainsi, la génération de la variable aléatoire $F_{T}$ obéira idéalement à une loi de distribution asymétrique vers la droite ($G_{1} < 0$). Ce critère d'asymétrie écarte par conséquent les lois de distribution symétriques telles que la loi normale ou la loi uniforme.

```{r Lots-DistribSym, echo = FALSE, fig.height = 3, fig.cap = "Exemples de distributions de la loi uniforme (à gauche), binomiale (au centre) et normale (à droite)"}
plot(ggarrange(
   ncol = 3,
   distrib_uniforme + ylab("Nombre"),
   distrib_binomiale,
   distrib_normale))
```

```{r Lots-DistribAsym, echo = FALSE, fig.height = 3, fig.cap = "Exemples de distributions de la loi de Poisson (à gauche), de Weibull (au centre) et bêta (à droite)"}
plot(ggarrange(
   ncol = 3,
   distrib_poisson + ylab("Nombre"),
   distrib_weibull,
   distrib_beta
   )
)
```

\paragraph*{}
En raison des contraintes imposées précédemment ainsi que de par sa grande polyvalence[@johnson_continuous_1995], la loi retenue dans le cadre cette étude pour la génération des facteurs de taille aléatoires ($F_{T}$) est une loi bêta non-centrale, définie comme la fonction de distribution de[@johnson_continuous_1995;@r_core_team_r_2021] :
$$ X = \frac{\chi^{2}_{2 \alpha} (\lambda)} {\chi^{2}_{2 \alpha} (\lambda) + \chi^{2}_{2 \beta}}$$

Avec, comme paramètres définis empiriquement pour cette étude : 
$$\left \{
\begin{array}{l c c}
\alpha = 6 F_{c} & & (shape1)\\
\beta = 4  & & (shape2)\\
\lambda = F_{c}/2  & & (ncp)\\
\end{array}
\right.$$

$F_{c}$ est ici défini comme un facteur de croissance permettant de rendre compte de la cinétique de croissance de chaque variété d'une part, et du prélèvement préférentiel des spécimens de plus grande taille d'autre part, comme l'illustre la figure \@ref(fig:Lots-LoisBeta).

```{r Lots-LoisBeta, echo = FALSE, fig.height = 4, fig.cap = "Distribution de différentes lois bêta, en fonction du facteur de croissance Fc"}
plot(lois_beta)
```

Le modèle défini à ce stade impose une stricte proportionnalité entre diamètre du chapeau $D_{c}$, diamètre du stipe $D_{s}$ et longueur du stipe $L_{s}$.

Dans un souci de réalisme, il apparaît souhaitable d'améliorer ce modèle mathématique en y ajoutant un facteur de dispersion, afin de proposer le modèle suivant :

$$\left \{
\begin{array}{l}
L_{S} = L_{Smax}.F_{T}.\delta_{Ls} ~~~~~~~~avec~~ \delta_{Ls} \sim \mathcal{N}(\mu = 1 ; \sigma = 0.05) \\
D_{S} = D_{Smax}.F_{T}.\delta_{Ds} ~~~~~~avec~~ \delta_{Ds} \sim \mathcal{N}(\mu = 1 ; \sigma = 0.05) \\
D_{C} = D_{Cmax}.F_{T}.\delta_{Dc} ~~~~~~avec~~ \delta_{Dc} \sim \mathcal{N}(\mu = 1 ; \sigma = 0.05) \\
\end{array}
\right.$$


L'impact de la dispersion sur la distribution des paramètres de taille $L_{S}$, $D_{S}$ et $D_{C}$ est illustré par les figures \@ref(fig:Lots-Dispersion3D) et \@ref(fig:Lots-Dispersion2D).

```{r Lots-Dispersion3D, echo = FALSE, fig.height = 3, fig.cap = "Paramètres de taille sans dispersion (à gauche) et avec dispersion (à droite)"}
plot(ggarrange(
   ncol = 2,
   scatter3Ddouble,
   scatter3Dsimple
   )
)
```

```{r Lots-Dispersion2D, echo = FALSE, fig.height = 3, fig.cap = "Nuage de points et densité de 2 paramètres de taille, avec dispersion"}
plot(ggarrange(
   ncol = 2, 
   widths = c(3, 3.8),
   scatter2d,
   densite2d
   )
)
```

Une simulation de Monte Carlo unidimensionnelle effectuée sur `r  n_champis` spécimens nous permet d’évaluer la proportion de spécimens "hors normes" dépassant la valeur dimensionnelle maximale extraite de la littérature à environ `r outliers_diam` % (cf. figure \@ref(fig:HorsNormes)), et la proportion de spécimens dépassant de plus de 10% cette valeur maximale est inférieure à `r Superoutliers_diam` %.

```{r HorsNormes, echo = FALSE, fig.height = 3, fig.cap = paste0("Distribution du diamètre de stipe Ds, pour Dsmax = ", Chap.Diam)}
plot(distrib_diametre)
```

### Génération des paramètres qualitatifs
La génération des paramètres qualitatifs, tels que la couleur des spores ou le type d'hyménophore, est nettement moins complexe que celle des paramètres quantitatifs.

L'ensemble des valeurs quantitatives possibles pour un critère et pour une variété donnée est insérée dans un vecteur de valeur, et une valeur sera tirée aléatoirement parmi celles de ce vecteur pour caractériser chaque spécimen.

\FloatBarrier
\newpage
# Principes de l'apprentissage machine
## Jeux de données
L'évaluation de l'apprentissage machine se décompose conceptuellement en trois étapes :

1. Entraînement : le modèle d'apprentissage est exposé à un *jeu de données d'entraînement* (*training data set*), censé être représentatif (cf. section \@ref(generation-data)) des données auquel le modèle sera exposé en utilisation réelle.
2. Validation : le modèle d'apprentissage développé à l'étape précédente, sera soumis à un *jeu de données de validation* (*validation data set*). Les prédictions (ex: comestibilité, espèce) proposées par le modèle d'apprentissage sur la base des informations continues dans le lot de données de validation (ex : dimensions, couleurs, morphologie du champignon...) sont comparées avec les valeurs réelles (ex : comestibilité, espèce...), ce qui permet d'évaluer les performances du modèle proposé en fonction des indicateurs retenus (spécificité, sensibilité, F1-score, temps de calcul, etc.). Les étapes d'apprentissage et de validation sont répétées de manière itérative en explorant l'ensemble des paramètres de configuration du modèle (*hypermaramètres*) -- idéalement en suivant un plan d'expériences -- afin d'optimiser le modèle.
3. Test : les performances du meilleur modèle, avec hyperparamètres optimaux, sélectionné à l'issue de l'étape de validation sont évaluées vis-à-vis d'un *jeu de données test* (*test* ou *holdout data set*).

\paragraph*{}
La séparation entre étapes d'optimisation et de test peut sembler artificielle. Le problème est en partie lié à un flou sémantique : si l'étape initiale d'entraînement ou d'apprentissage ne pose que peu de problèmes conceptuels, l'étape intermédiaire, dite de *validation* correspond en réalité à une étape d'*optimisation* du modèle et de ses hyperparamètres. Par ailleurs, l'étape finale de *test* est parfois qualifiée d'étape de *validation* dans la littérature.[@brownlee_what_2017]

\paragraph*{}
Une distinction sémantique plus nette entre phases d'*apprentissage*, d'*optimisation* et de *test* permet de comprendre plus aisément le fondement épistémologique de cette troisième phase : l'optimisation effectuée lors de l'étape de validation aboutit à un modèle potentiellement biaisé (problème dit d'*overfitting*). Seule une comparaison avec des données n'ayant jamais servi pour l'entraînement ou l'optimisation permettra d'évaluer avec précision le caractère prédictif du modèle, donc sa validité.
\paragraph*{}
Dans un souci de clarté, nous utiliserons les termes lots et de phases d'entraînement, d'optimisation et d'évaluation dans la suite de cette étude.
\paragraph*{}
Les phases d'entraînement, d'optimisation et d'évaluation utilisent chacune un lot de données spécifique. Chacun de ces lots de données est habituellement obtenu suite à dichotomies successives du lot de données intial, avec des proportions variables :
1. Découpage du jeu de données initial, en un jeu d'évaluation d'une part, et un jeu d'entraînement & optimisation d'autre part,
2. Découpage du jeu de données entraînement & optimisation, en un jeu d'entraînement et un jeu d'optimisation.
[Schéma Split Apprentissage/Optimisation/Validation]

\paragraph*{}
Le rapport de taille entre jeux de données entraînement, optimisation, évaluation fixé dans cette étude suit une loi $p : \sqrt{p} : \sqrt{p}+1$, avec $p$ le nombre de coefficients du modèle.[@joseph_optimal_2022]
\paragraph*{}
Pour un nombre de coefficients compris entre 100 et 200, cette règle nous conduit à retenir :

$$\left \{
\begin{array}{l}
R_{entr} = 85 \pm 2 \% \\
R_{opti} = 7 \pm 1 \% \\
R_{eval} = 8 \pm 1 \% \\
\end{array}
\right.$$

\paragraph*{}
Ce rapport 85:7:8 peut en pratique être obtenu par deux divisions successives avec un rapport 92:8, assez proche des valeurs empiriques communément utilisées en apprentissage machine (double découpage 90:10).
\paragraph*{}
Le découpage des jeux de données de cette étude utilise une méthode de découpage basée sur les points-supports[@mak_support_2018] (*support-points based splitting*) qui vise à optimiser la représentativité des jeux de données par rapport à un découpage purement aléatoire, à l'aide d'un algorithme du plus proche voisin (NN : *Nearest Neighbour*), basé sur un arbre Kd (*k-dimensional tree*). [@joseph_split_2022]




\FloatBarrier
## Modèles utilisés


\FloatBarrier
\newpage
# Apprentissage machine et classification binaire

texte

\FloatBarrier
\newpage
# Apprentissage machine et classification multiclasse
texte

\FloatBarrier
\newpage
# Robustesse de la classification
texte

\FloatBarrier
\newpage

# Références bibliographiques
