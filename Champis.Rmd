---
#title: "Application de modèles d'Intelligence Artificielle à la classification des macromycètes"
#author: "Emir Kaïs RIHANI"
#date: "`r format(Sys.time(), '%d %B, %Y')`"
lang: fr
geometry: "left=2.5cm,right=2.5cm,top=1.5cm,bottom=2cm"        # Imposé par la fac
fontsize: 12pt          # Imposé par la fac
output: 
  bookdown::pdf_document2: 
    number_sections: yes
    extra_dependencies: float
    toc: yes
    toc_depth: 3
    includes:
      before_body: couverture.tex
      after_body: quatrieme.tex
header-includes:
  - \renewcommand{\familydefault}{\sfdefault}   # Police sans serif sur tout le doc
  - \usepackage{pdfpages}   # Pour ajout PDF listes des profs / disclaimer
  - \usepackage{placeins}   # pour bloquer ces %#@$§£ de floats
  - \usepackage{amssymb}   # Symboles mathématiques (loi normale...)
  - \linespread{1.15}
#  - \setlength{\baselineskip}{24pt}      #MARCHE PAS !!!
#  - \setlength{\parskip}{1.2ex plus 1pt}       # Espacements sans ajouter des\paragraph*{} partout      #MARCHE PAS
#  - \setlength{\abovecaptionskip}{-10pt plus 3pt minus 2pt}    # Espacement des légendes (above/below) POUR WINDOWS
indent: true
bibliography: [packages.bib, Champis.bib]
csl: https://www.zotero.org/styles/vancouver-superscript
---

```{r setup, include = FALSE, warning=FALSE}
load("EKR-Champis-Intro.RData")      # Chargement des résultats INTRO
load("EKR-Champis-EDA.RData")            # Chargement des résultats ANALYSE EXPLORATOIRE
load("EKR-Champis-AnalyseBi.RData")       # Chargement des résultats CLASSIFICATION BINAIRE
load("EKR-Champis-AnalyseMulti.RData")       # Chargement des résultats CLASSIFICATION MULTICLASSE

library(ggpubr)   # Combiner graphes (ggarrange)
library(rmarkdown)
library(knitr)
library(tidyverse)
library(bookdown)
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, fig.pos = "!H")
knitr::write_bib(c("tidyverse", "microbenchmark",  "caret",  "rmarkdown", "GGally", "plyr", "MASS", "mda", "rpart", "C50", "party", "ranger", "Rborist", "e1071", "rFerns", "knitr", "ggpubr", "SPlit", "DiceDesign", "DiceEval", "DiceKriging", "Bookdown"), "packages.bib")
```
\pagestyle{plain}

\newpage
# Liste des abréviations
\begin{flushleft}
AI : *Artificial Intelligence* (intelligence artificielle)

AUC : *Area Under Curve* (aire sous la courbe)

CART : *Classification And Regression Tree* (arbre de classification et de régression)

DOE : *Design of Experiments* (plan d'expériences)

EDA : *Exploratory Data Analysis* (analyse exploratoire des données)

ESE : *Enhanced Stochastic Evolutionnary* ([algorithme] évolutionnaire stochastique amélioré)

GAM : *Generalized Additive Model* (modèle additif généralisé)

IA : Intelligence Artificielle  

Kd-tree : *K-dimensional tree* (arbre k-dimensionel)

LDA : *Linear Discriminant Analysis* (analyse linéaire discriminante)

LHS : *Latin Hypercube Sample* (échantillonnage par hypercube latin)

LOESS : *LOcally Estimated Scatterplot Smoothing* (régression locale)

NN : *Nearest Neighbour* (plus proche voisin)

NOLH : *Nearly Orthogonal Latin Hypercube* (hypercube latin quasi orthogonal)

PDA : *Penalized Discriminant Analysis* (analyse discriminante pénalisée)

RF : *Random Forest* (forêt aléatoire)

ROC : *Receiver Operating Characteristic* (fonction d'efficacité du récepteur)

XGB : *eXtreme Gradient Boosting*
\end{flushleft}

\newpage
# Introduction
## Propos liminaire
\paragraph*{}
L'identification des macromycètes est un sujet difficile, ne devant évidemment pas être pris à la légère. Les espèces rencontrées varient considérablement d'un écosystème à un autre, d'un continent à un autre, et aucun lot de données ni ouvrage sur les champignons ne saurait couvrir toute la diversité du monde fongique.
\paragraph*{}
Le lot de données mycologiques constitué dans cette étude, bien que constituant l'un des lots en libre accès les plus complets du domaine de la *data science*, n'est bien entendu pas exhaustif.
\paragraph*{}
Ce lot se concentre exclusivement sur les champignons habituellement rencontrés au Nord de la France. Plusieurs genres, parfois très connus, ne sont pas présents, parmi lesquels nous pouvons par exemple citer le genre  *psylocybe*, connu pour ses propriétés psychédéliques. Certains critères pourront également varier de manière considérable selon le stade de maturité du champignon : alors que les chapeaux vert-olive de l'*Amanita phalloides* mature sont faciles à reconnaître, les spécimens jeunes sont blancs et pourraient facilement être confondus avec des espèces comestibles (par exemple du genre *Agaricus*).
\paragraph*{}
L'ingestion de certains de ces champignons est *mortelle*, même à de petites doses. Le diagnostic de l'intoxication fongique peut être difficile, et parfois trop tardif pour un traitement efficace. Des composés toxiques tels que les amanitines ne sont pas altérés ou détruits par cuisson ou congélation, et seront absorbés par l'intestin, avant de passer dans la circulation sanguine afin d'être filtrés par le foie, détruisant les cellules hépatiques, puis excrétées dans l'intestin, réabsorbées, refiltrées... chaque passe détruisant les cellules hépatiques ayant survécu à la précédente, dans un cycle connu sous le nom de réabsorption hépato-entérique.
\paragraph*{}
Il ne faut jamais, *sous aucune circonstance*, utiliser ce type de lot de données afin de déterminer si un champignon est comestible ou non.

## But de l'étude
\paragraph*{}
L'identification des plantes et champignons est un problème de classification classique, qui est habituellement effectué manuellement à l'aide de clés d'identification. La plupart de ces clés sont basées sur un processus utilisant des arbres décisionnels, ce qui semble logique car rappelant la logique en arbre de l'évolution. Quoique séduisant, cet argument rencontre quelques limites :
\paragraph*{}
La première limite est le nombre de chaînons manquants. Certaines espèces sont évidemment éteintes, ce qui signifie que certaines branches et n\oe{}uds de l'arbre phylogénétique sont manquants, ce qui peut compliquer l'analyse quand deux espèces apparentées ont un nombre élevé de chaînons et n\oe{}uds communs manquants. Certaines similarités entre espèces peuvent également ne pas être identifiables de façon macroscopique.
\paragraph*{}
La seconde limite, plus profonde, est la logique inhérente au processus évolutionnaire. Deux phénomènes antagonistes sont en jeu : convergence et divergence évolutives. Ces deux phénomènes sont liés à la nécessaire adaptation des espèces à leurs environnements. La divergence évolutive explique par exemple la diversité des mammifères : les chauves-souris, baleines et chevaux sont apparentés, mais ont des aspects très dissemblables en raison de leur adaptation à des environnements très différents. D'un autre côté, la convergence évolutive explique la similarité entre l'aile de la chauve-souris et l'aile de l'abeille. Toutefois, malgré leur apparente dissimilarité, l'aile de la chauve-souris est plus proche de la main humaine ou de la nageoire de la baleine que de l'aile de l'abeille. La façon la plus fiable pour évaluer le processus évolutionnaire et trouver les liens phylogénétiques de la manière la plus précise possible est l'analyse des génomes : les caractéristiques visibles peuvent être trompeuses. Malheureusement, ces caractéristiques sont souvent les seules aisément identifiables.
\paragraph*{}
Le troisième problème est le critère principal de la classification. Ce critère peut être lié ou non au processus évolutionnaire ou aux critères visible, surtout si ce critère principal est vague. Le critère de comestibilité ou de non-comestibilité retenu pour les lots de données mycologiques usuellement utilisés en *data science* souffre de ce problème : il est essentiellement centré sur la toxicité contre les humains, or de nombreux mécanismes de toxicité peuvent exister, et une toxicité ou non-toxicité d'un métabolite fongique ou végétal peut être liée à des variations métaboliques très ténues entre une espèce et une autre.
\paragraph*{}
Pour ces raisons parmi d'autres, la logique arborescente, bien qu'utilisée habituellement dans l'identification des champignons et des plantes, et souvent justifiée par la nature arborescente du processus évolutionnaire, pourrait ne pas nécessairement être l'approche optimale à la classification des espèces basée sur des critères macroscopiques. Le but de cette étude est d'effectuer cette tâche de classification basée sur des indices visuels limités, et d'évaluer les performances relatives de différentes stratégies de classification.

## Etat de l'art des lots de données mycologiques
Le tout premier lot de données mycologiques en libre accès mentionné en data science est probablement le *Mushroom Dataset* créé par Jeff Schlimmer en 1987.[@schlimmer_mushroom_1987]
\paragraph*{}
Un lot de données plus conséquent a été publié par Dennis Wagner en 2021[@wagner_mushroom_2021] et mis en libre accès sous le nom de *Secondary Mushroom Dataset*.

\newpage
# Création du lot de données
## Configuration matérielle et logicielle
\paragraph*{}
\FloatBarrier
Le code d'apprentissage machine, les méthodes d'évaluation, ainsi que cette thèse ont été rédigés sur l'équipement suivant :

* CPU : AMD Ryzen 5 5600G
* RAM : 2x16 Go DDR4-3200
* SSD : Crucial P5 M2 NVMe
* OS : Xubuntu Linux 20.04.1 LTS
* R : version `r paste0(R.version$major, ".", R.version$minor, " (", R.version$year, ")")`
* RStudio : version `r paste0(rstudioapi::versionInfo()$version, ', "', rstudioapi::versionInfo()$release_name, '"')`
* Librairies : tidyverse[@R-tidyverse] (v`r packageVersion("tidyverse")`), microbenchmark[@R-microbenchmark] (v`r packageVersion("microbenchmark")`), SPlit[@R-SPlit] (v`r packageVersion("SPlit")`), MASS[@R-MASS] (v`r packageVersion("MASS")`), caret[@R-caret] (v`r packageVersion("caret")`), ?GGally?[@R-GGally] (v`r packageVersion("GGally")`), ?mda?[@R-mda] (v`r packageVersion("mda")`), rpart[@R-rpart] (v`r packageVersion("rpart")`), ?plyr?[@R-plyr] (v`r packageVersion("plyr")`), C50[@R-C50] (v`r packageVersion("C50")`), party[@R-party] (v`r packageVersion("party")`), ranger[@R-ranger] (v`r packageVersion("ranger")`), e1071[@R-e1071] (v`r packageVersion("e1071")`), rFerns[@R-rFerns] (v`r packageVersion("rFerns")`), Rborist[@R-Rborist] (v`r packageVersion("Rborist")`),  rmarkdown[@R-rmarkdown] (v`r packageVersion("rmarkdown")`), knitr[@R-knitr] (v`r packageVersion("knitr")`), ggpubr[@R-ggpubr] (v`r packageVersion("ggpubr")`), DiceDesign[@R-DiceDesign] (v`r packageVersion("DiceDesign")`), DiceEval[@R-DiceEval] (v`r packageVersion("DiceEval")`, bookdown[@R-bookdown] (v`r packageVersion("bookdown")`).

\FloatBarrier
## Principes de conception d'un lot de données synthétiques
### Principes généraux{#generation-data}
\paragraph*{}
Un lot de données synthétiques est un lot de données généré par un algorithme, par opposition aux lots de données issus d'une collecte effectuée en "vie réelle". 
\paragraph*{}
\FloatBarrier
Trois stratégies sont usuellement utilisées :

* Données factices (*dummy data*) : l'ensemble des données est généré aléatoirement.
* Données générées à partir de règles (*rule-based data*) : l'ensemble des données est généré suivant des lois définies au préalable (distribution, valeurs moyennes, minimales, maximales...)
* Données générées par intelligence artificielle (*AI generated*) : l'ensemble des données est généré suivant des lois extraites par l'IA suite à l'analyse d'un échantillon de données obtenues en "vie réelle".

\FloatBarrier
\paragraph*{}
Les données générées par ces stratégies peuvent être de type variés, que nous pouvons grossièrement regrouper en données alphanumériques (quantitatives et qualitatives) et en données d'imagerie.
\paragraph*{}
Pour des raisons pratiques et de maturité des technologies disponibles à l'heure actuelle, la méthode retenue pour créer le lot de données exploité dans notre étude sera la génération de données alphanumériques à partir de règles, extraites d'ouvrages mycologiques de référence.[@courtecuisse_cle_1986; @courtecuisse_champignons_2013; @courtecuisse_initiation_2020]

### Principes de génération des paramètres quantitatifs
\paragraph*{}
\FloatBarrier
Dans le cadre de cette étude, les variables quantitatives générées aléatoirement sont :

* La longueur du stipe $L_{S}$,
* Le diamètre du stipe $D_{S}$,
* Le diamètre du chapeau $D_{C}$.

\FloatBarrier
\paragraph*{}
En première approximation, nous pouvons considérer que toutes ces valeurs sont intrinsèquement liées à la croissance du champignon. Ces trois variables peuvent, dans l'absolu, être susceptibles de varier indépendamment des autres au cours de la croissance du champignon, les variables $L_{S}$, $D_{S}$ et $D_{C}$ obéissant alors aux lois suivantes :

$$\left \{
\begin{array}{l}
L_{S} = L_{Smax}.F_{Ls} \\
D_{S} = D_{Smax}.F_{Ds} \\
D_{C} = D_{Cmax}.F_{Dc} \\
\end{array}
\right.$$

Avec :

* $L_{Smax}$, $D_{Smax}$ et $D_{Cmax}$ les valeurs maximales de longueur de stipe, diamètre du stipe et diamètre de chapeau de chaque variété de champignon, extraites de la littérature, 
* $F_{Ls}$, $F_{Ds}$, $F_{Dc}$ des variables générées aléatoirement dans l'intervalle $\left] 0 ; 1 \right]$, et représentatives de la croissance du spécimen.

\paragraph*{}
Toutefois, la recherche bibliographique sur la cinétique de croissance des sporophores n'a pas permis de distinguer de différences de la cinétique de croissance de chacun de ces trois paramètres. Nous supposerons donc, en première approximation, que la croissance du stipe en longueur et en largeur, ainsi que la croissance du chapeau s'effectuent à des vitesses identiques. Nous obtenons par conséquent :

$$F_{Ls} = F_{Ds} = F_{Dc} = F_{T}$$
Avec $F_{T}$ un facteur représentatif de la taille globale de chaque spécimen généré aléatoirement.

\paragraph*{}
Ainsi, le problème de génération de nos trois variables aléatoires se simplifie en un problème de génération d'une seule variable aléatoire : le facteur de taille de chaque spécimen. Un certain nombre de distributions d'intérêt sont susceptibles d'être utilisées afin de générer des facteurs de taille $F_{T}$ aléatoires, il convient donc de définir le cahier des charges de la distribution la plus adaptée au sujet de cette étude.
\paragraph*{}
Les critères de sélection retenus afin de choisir la loi la plus appropriée sont :

* Efficience calculatoire,
* Distribution continue,
* Distribution bornée, ou aisément normalisable sur un intervalle $\left[ 0 ; 1 \right]$,
* Distribution asymétrique.

\FloatBarrier
\paragraph*{}
Le premier critère n'est, en pratique, pas un facteur limitant, les temps de calcul pour la génération d'un nombre de facteurs de taille $F_{T}$ suffisant étant typiquement inférieurs à `r chrono_typique` ms (pour `r n_chrono` facteurs générés) avec la plupart des distributions d'intérêt (voir figure \@ref(fig:Lots-Chrono)).


```{r Lots-Chrono, echo = FALSE, fig.height = 4, fig.cap = paste0("Temps de calcul des principales distributions d'intérêt pour ", n_chrono, " facteurs, (", fois_chrono, " iter.)")}
plot(chrono_distrib)
```

\paragraph*{}
Les critères de continuité et de normalité n'appellent que peu de commentaires. Ces critères permettent simplement de garantir la possibilité d'une infinité de valeurs dimensionnelles, dans l'intervalle considéré. Le critère de continuité proscrit toutefois l'utilisation de lois de distributions discrètes telles que la loi binomiale ou la loi de Poisson, et celui de normalité écarte des distributions telles que la loi de Weibull, dont la normalisation est parfois délicate.
\paragraph*{}
\FloatBarrier
Le critère d'asymétrie est un critère permettant de tenir compte des différents paramètres pouvant impacter la distribution de taille des spécimens prélevés, parmi lesquels :

* Différences de cinétique de croissance d'une famille à une autre,
* Particularités de la croissance fongique, notamment par la croissance hyphale, [@money_insights_2008; @porter_hyphal_2022]
* Probabilité de prélèvement variable selon la taille du spécimen (par difficulté de détection, considérations éthiques, intérêt mycologique ou gastronomique...).

\FloatBarrier
\paragraph*{}
Le premier paramètre évoqué précédemment n'a pu être exploité dans le cadre de cette étude en raison du manque de données concernant les cinétiques relatives de croissance des sporophores des différentes familles de macromycètes. Le modèle que nous proposons permet toutefois des développements ultérieurs dans ce domaine.
\paragraph*{}
Les deux derniers paramètres permettent de supposer que la distribution de taille des spécimens d'une même espèce à l'issue d'une récolte en vie réelle ne sera pas symétrique, d'une part en raison de la rapidité de la croissance fongique, et d'autre part parce que le prélèvement se fera préférentiellement en épargnant les spécimens de petite taille.
\paragraph*{}
Ainsi, la génération de la variable aléatoire $F_{T}$ obéira idéalement à une loi de distribution asymétrique vers la droite ($G_{1} < 0$). Ce critère d'asymétrie écarte par conséquent les lois de distribution symétriques telles que la loi normale ou la loi uniforme.
\paragraph*{}

```{r Lots-DistribSym, echo = FALSE, fig.height = 3, fig.cap = "Exemples de distributions de la loi uniforme (à gauche), binomiale (au centre) et normale (à droite)"}
plot(ggarrange(
   ncol = 3,
   distrib_uniforme + ylab("Nombre"),
   distrib_binomiale,
   distrib_normale))
```

```{r Lots-DistribAsym, echo = FALSE, fig.height = 3, fig.cap = "Exemples de distributions de la loi de Poisson (à gauche), de Weibull (au centre) et bêta (à droite)"}
plot(ggarrange(
   ncol = 3,
   distrib_poisson + ylab("Nombre"),
   distrib_weibull,
   distrib_beta
   )
)
```

\paragraph*{}
En raison des contraintes imposées précédemment ainsi que de par sa grande polyvalence[@johnson_continuous_1995], la loi retenue dans le cadre de cette étude pour la génération des facteurs de taille aléatoires ($F_{T}$) est une loi bêta non-centrale, définie comme la fonction de distribution de :[@johnson_continuous_1995;@r_core_team_r_2021]
$$ X = \frac{\chi^{2}_{2 \alpha} (\lambda)} {\chi^{2}_{2 \alpha} (\lambda) + \chi^{2}_{2 \beta}}$$

Avec, comme paramètres définis empiriquement pour cette étude : 
$$\left \{
\begin{array}{l c c}
\alpha = 6 \, F_{c} & & (shape1)\\
\beta = 4  & & (shape2)\\
\lambda = F_{c}/2  & & (ncp)\\
\end{array}
\right.$$

$F_{c}$ est ici défini comme un facteur de croissance permettant de rendre compte de la cinétique de croissance de chaque variété d'une part, et du prélèvement préférentiel des spécimens de plus grande taille d'autre part, comme l'illustre la figure \@ref(fig:Lots-LoisBeta).

```{r Lots-LoisBeta, echo = FALSE, fig.height = 4, fig.cap = "Distribution de différentes lois bêta, en fonction du facteur de croissance Fc"}
plot(lois_beta)
```

Le modèle défini à ce stade impose une stricte proportionnalité entre diamètre du chapeau $D_{c}$, diamètre du stipe $D_{s}$ et longueur du stipe $L_{s}$.
\paragraph*{}
Dans un souci de réalisme, il apparaît souhaitable d'améliorer ce modèle mathématique en y ajoutant un facteur de dispersion, afin de proposer le modèle suivant :

$$\left \{
\begin{array}{ll} 
L_{S} = L_{Smax}.F_{T}.\delta_{Ls} & ~~~~avec~~ \delta_{Ls} \sim \mathcal{N}(\mu = 1 ; \sigma = 0.05) \\
D_{S} = D_{Smax}.F_{T}.\delta_{Ds} & ~~~~avec~~ \delta_{Ds} \sim \mathcal{N}(\mu = 1 ; \sigma = 0.05) \\
D_{C} = D_{Cmax}.F_{T}.\delta_{Dc} & ~~~~avec~~ \delta_{Dc} \sim \mathcal{N}(\mu = 1 ; \sigma = 0.05) \\
\end{array}
\right.$$

\paragraph*{}
L'impact de la dispersion sur la distribution des paramètres de taille $L_{S}$, $D_{S}$ et $D_{C}$ est illustré par les figures \@ref(fig:Lots-Dispersion2D) et  \@ref(fig:Lots-DispersionDensite).
\paragraph{}*

```{r Lots-Dispersion2D, echo = FALSE, fig.height = 3, fig.cap = paste0("Nuages de points de 2 paramètres de taille (Ls et Dc), sans dispersion (à gauche) et avec dispersion (à droite), pour ", n_reduit, " champignons")}
plot(ggarrange(
   ncol = 2,
   nuage_sansdispersion,
   nuage_avecdispersion
   )
)
```


```{r Lots-DispersionDensite, echo = FALSE, fig.height = 4, fig.cap = "Diagramme de densité de 2 paramètres de taille, avec dispersion"}
plot(densite2d)
```

\paragraph*{}
Une simulation de Monte Carlo unidimensionnelle effectuée sur `r  n_champis` spécimens nous permet d’évaluer la proportion de spécimens "hors normes" dépassant la valeur dimensionnelle maximale à environ `r taux_gros_diam` % (cf. figure \@ref(fig:HorsNormes)). La proportion de spécimens dépassant de plus de 10% cette valeur maximale sera quant à elle inférieure à `r taux_supergros_diam` %.
\paragraph*{}

```{r HorsNormes, echo = FALSE, fig.height = 3, fig.cap = paste0("Distribution du diamètre de stipe Ds, pour Dsmax = ", Chap.Diam)}
plot(distrib_diametre)
```

\FloatBarrier

### Principes de génération des paramètres qualitatifs
\paragraph*{}
La génération des paramètres qualitatifs, tels que la couleur des spores ou le type d'hyménophore, est nettement moins complexe que celle des paramètres quantitatifs.

L'ensemble des valeurs quantitatives possibles pour un critère et pour une variété donnée est insérée dans un vecteur de valeurs, et une valeur sera tirée aléatoirement parmi celles de ce vecteur pour caractériser chaque spécimen.

## Développement d'un algorithme de génération de lot synthétique

\paragraph*{}
*Plus de détails concrets sur la méthode utilisée en pratique...*
\paragraph*{}
*L'algorithme est écrit et fonctionne, à partir des données primaires du Secondary Dataset de Dennis Wagner. C'est cet algorithme qui a servi à créer le lot de données de la classification multiclasse.*
\paragraph*{}
*Pour avoir mes propres lots de données, il ne me reste plus qu'à avoir mes propres données primaires, c'est à dire entrer manuellement les caractéristiques clés de mes 400+ champignons, un par un...*

\newpage
\FloatBarrier

# Principes de l'apprentissage machine
## Jeux de données
\paragraph*{}
Le déroulement de l'apprentissage machine se décompose conceptuellement en trois étapes, mettant en jeu trois lots de données distincts :

1. Entraînement : le modèle d'apprentissage est exposé à un *jeu de données d'entraînement* (*training data set*), censé être représentatif (cf. section \@ref(generation-data)) des données auquel le modèle sera exposé en utilisation réelle.
2. Validation : le modèle d'apprentissage développé à l'étape précédente, sera soumis à un *jeu de données de validation* (*validation data set*). Les prédictions (ex: comestibilité, espèce...) proposées par le modèle d'apprentissage sur la base des informations contenues dans le lot de données de validation (ex : dimensions, couleurs, morphologie du champignon...) sont comparées avec les valeurs réelles (ex : comestibilité, espèce...), ce qui permet d'évaluer les performances prédictives du modèle proposé en fonction des indicateurs retenus (spécificité, sensibilité, F1-score, temps de calcul...). Les étapes d'apprentissage et de validation sont répétées de manière itérative en explorant l'ensemble des paramètres de configuration du modèle (hyperparamètres) -- idéalement en suivant un plan d'expériences -- à fins d'optimisation.
3. Test : les performances du meilleur modèle, avec hyperparamètres optimaux, sélectionné à l'issue de l'étape de validation sont évaluées vis-à-vis d'un *jeu de données test* (*test* ou *holdout data set*).

\paragraph*{}
La séparation entre étapes d'optimisation et de test peut sembler artificielle. Le problème est en partie lié à un flou sémantique : si l'étape initiale d'entraînement ou d'apprentissage ne pose que peu de problèmes conceptuels, l'étape intermédiaire, dite de *validation* correspond en réalité à une étape d'*optimisation* du modèle et de ses hyperparamètres. Par ailleurs, l'étape finale de *test* est parfois qualifiée d'étape de *validation* dans la littérature.[@brownlee_what_2017]
\paragraph*{}
Une distinction sémantique plus nette entre phases d'*apprentissage*, d'*optimisation* et de *test* permet de comprendre plus aisément le fondement épistémologique de cette dernière phase : l'optimisation effectuée lors de l'étape de validation aboutit à un modèle potentiellement biaisé (problème dit d'*overfitting*) vis-à-vis du jeu de données utilisé comme référence lors de cette étape. Seule une exposition du modèle à des données n'ayant jamais servi à son entraînement ou son optimisation permettra réellement d'évaluer avec précision son caractère prédictif, donc sa validité.
\paragraph*{}
Dans un souci de clarté, nous utiliserons les termes lots et de phases d'entraînement, d'optimisation et d'évaluation dans la suite de cette étude.
\paragraph*{}
Les phases d'entraînement, d'optimisation et d'évaluation utilisent chacune un lot de données spécifique. Chacun de ces lots de données est habituellement obtenu suite à dichotomies successives du lot de données intial, avec des proportions variables :

1. Découpage du jeu de données initial, en un jeu d'évaluation d'une part, et un jeu d'entraînement & optimisation d'autre part,
2. Découpage du jeu de données entraînement & optimisation, en un jeu d'entraînement et un jeu d'optimisation.

[Schéma Split Apprentissage/Optimisation/Validation]

\paragraph*{}
Le rapport de taille entre jeux de données entraînement, optimisation, évaluation de cette étude suit la loi $p : \sqrt{p} : \sqrt{p}+1$, avec $p$ le nombre de coefficients du modèle.[@joseph_optimal_2022]
\paragraph*{}
Pour un nombre de coefficients compris entre 100 et 200, cette règle nous conduit à retenir :

$$\left \{
\begin{array}{l}
R_{entr} = 85 \pm 2 \% \\
R_{opti} = 7 \pm 1 \% \\
R_{eval} = 8 \pm 1 \% \\
\end{array}
\right.$$

\paragraph*{}
Ce rapport 85:7:8 peut, dans la pratique, être obtenu par réalisation de deux découpages successifs suivant des rapports 92:8.
\paragraph*{}
Dans cette étude, la division de ces trois jeux de données utilise une méthode de découpage basée sur les points-supports[@mak_support_2018] (*support-points based splitting*) exploitant un algorithme du plus proche voisin (NN : *Nearest Neighbour*), basé sur un arbre Kd (*k-dimensional tree*), afin d'optimiser la représentativité des jeux de données par rapport à ceux pouvant être obtenus par un découpage aléatoire.[@joseph_split_2022]

\FloatBarrier

## Modèles utilisés
### Analyses discriminantes (lda2, pda)
[discriminant correspondence analysis???]

https://rpubs.com/markloessi/505575

https://en.wikipedia.org/wiki/Altman_Z-score

https://towardsdatascience.com/linear-discriminant-analysis-explained-f88be6c1e00b

https://scikit-learn.org/stable/modules/lda_qda.html
\paragraph*{}
Cette étude propose plusieurs classifieurs linéaires s'appuyant sur des méthodes d'analyse discriminante :

* un modèle basé sur l'analyse discriminante linéaire (*Linear Discriminant Analysis*, LDA),
* un modèle basé sur l'analyse discriminante pénalisée (*Penalized Discriminant Analysis*, PDA).

\paragraph*{}
L'analyse linéaire discriminante (LDA) est une méthode utilisée en statistiques et en data science pour trouver une combinaison linéaire d'éléments qui caractérisent des éléments, afin de créer un classifieur linéaire, ou d'effectuer des réductions de dimensionnalité. Cet algorithme fonctionne en créant des combinaisons linéaires (fonctions discriminantes) de prédicteurs. [A FINIR]
\paragraph*{}
L'analyse discriminante pénalisée [A FINIR]

### Modèle additif généralisé
gamLoess

### Arbres de décision
rpart, Ctree???, c50tree, Rpartcost

### Forêts aléatoires
rFerns, Rborist, ranger

## Optimisation par plans d'expérience (DOE)

Certains modèles nécessiteront une optimisation de leurs hyperparamètres, qui relève du domaine des plans d'expérience. De nombreux plans et stratégies sont envisageables, le choix dépendra en partie des caractéristiques du processus à optimiser.
\paragraph*{}
En effet, l'optimisation des paramètres d'un modèle informatique présente quelques particularités notables :

* La réalisation d'une expérience supplémentaire a un coût faible,
* Il peut exister plusieurs métriques coexistantes,
* La fonction de réponse peut s'avérer relativement complexe.

\paragraph*{}
Ces particularités imposent d'explorer de manière méthodique la totalité de l'espace expérimental. Il existe une multitude de méthodes permettant de générer des plans expérimentaux, dits SFD (*Space Filling Design*), permettant d'optimiser l'occupation de l'espace expérimental. La méthode retenue pour cette étude sera celle des hypercubes latins, en raison de son utilisation répandue[citation SANTIAGO] et de sa simplicité conceptuelle.
[http://www.azurad.fr/medias/133-documentation--6-construction-of-space-filling.pdf]
\paragraph*{}
La méthode des hypercubes latins est une extension du principe des carrés latins. Un carré latin est une grille $n \times n$, remplie de $n$ éléments distincts arrangés de sorte que chaque ligne et chaque colonne ne contienne qu’un seul exemplaire de chacun des $n$ éléments. Dans le domaine des plans d'expériences, l'application des carrés latins revient à diviser un domaine expérimental bidimensionnel en une grille $n \times n$, et à placer une expérience et une seule sur chaque ligne et chaque colonne.
\paragraph*{}
L'application du concept de carré latin dans un domaine expérimental à trois dimensions aboutit au cube latin. La généralisation dans un espace n-dimensionnel mène au concept d'hypercube latin.
\paragraph*{}
De nombreux plans expérimentaux basés sur les hypercubes latins peuvent être générés. Nous pouvons citer principalement trois types d'hypercubes latins :

* Aléatoires,
* Optimisés, afin d'optimiser l'occupation spatiale,
* Orthogonaux, visant à minimiser la corrélation des estimateurs des effets principaux.

```{r Carres-Latins, echo = FALSE, fig.height = 2.5, fig.cap = "Carré latin aléatoire (à gauche), carré latin avec optimisation évolutive ESE maximin (au milieu), carré latin quasi-orthogonal (à droite)"}
plot(ggarrange(
   ncol = 3,
   graphe_LHS + ylab("X2"),
   graphe_optiLHS,
   graphe_NOHLD
   )
)
```

\FloatBarrier
## Evaluation des performances des modèles

L'optimisation des modèles ainsi que la comparaison des performances des modèles entre eux implique nécessairement de définir quel sera le critère vis-à-vis duquel cette performance sera évaluée.
\paragraph*{}
De nombreux critères sont utilisables, en fonction du cahier des charges, mais également du type de tâche effectuée : régression, classification binaire, classification multiclasse.
\paragraph*{}
Dans une tâche de classification binaire, les critères usuels sont la spécificité, la sensibilité, et l'aire sous la courbe de fonction d'efficacité du récepteur (*AUC ROC*, parfois abrégé en *ROC*). Il conviendra bien évidemment, avant d'utiliser des indicateurs tels que la spécificité et la sensibilité, de définir la notion de test positif et test négatif.
\paragraph*{}
D'autres indicateurs d'intérêt existent, nous retiendrons ici l'index J de Youden pondéré, qui permet de pondérer la spécificité et la sensibilité au sein d'un index synthétique. Cet indicateur présente un intérêt particulier lorsqu'il apparaît souhaitable de tenir compte de la différence d'impact entre un faux positif et un faux négatif, sans pour autant autoriser des sensibilités ou spécificités nulles.

https://acsjournals.onlinelibrary.wiley.com/doi/10.1002/1097-0142(1950)3:1%3C32::AID-CNCR2820030106%3E3.0.CO;2-3
https://www.tandfonline.com/doi/full/10.1080/03610926.2018.1435809?scroll=top&needAccess=true&role=tab
\paragraph*{}
En l'espèce, l'index J de Youden pondéré nous permet donc de construire un indice synthétique tenant compte du fait qu'il est plus grave de classer à tort comme comestible un champignon toxique que d'écarter à tort un champignon parfaitement comestible, sans pour autant autoriser le modèle à écarter un nombre inconsidéré de champignons comestibles.
\paragraph*{}
L'index J de Youden pondéré est donné par :
$ S_{w} = Sen^{2w} . Spe^{2.(1-w)} ~~~~ avec~ 0  \in \left[ 0 ; 1 \right] $
En posant arbitrairement $w = 3$, nous obtenons :
$S_{w} = Sen^{6} . Spe^{-4}$
Ce qui revient à fixer dix ordres de grandeur entre l'importance accordée à la sensibilité et à la spécificité.
\paragraph*{}
Dans les tâches de classification multiclasse, d'autres indicateurs d'intérêt peuvent être utilisés, tels que le kappa de Cohen, l'indice de Rand (*accuracy*), la sensibilité et la spécificité moyennes.
Nous retiendrons ici le kappa de Cohen, calculé à partir de la matrice de confusion, et donné par :
$ \kappa{} = \frac{p_{0} - p_ {e}}{1 - p_{e}} $
Avec $p_{0} la probabilité d'accord entre notre modèle et la classe réelle du champignon, et p_{e} la probablité d'un même accord résultant du pur hasard.

[ INSERER SCHEMA MATRICE DE CONFUSION ]

\newpage

# Apprentissage machine et classification binaire

*Brouillon, le lot de données utilisé ici est le Secondary Mushroom Dataset de D.Wagner.*

## Analyse exploratoire des données (EDA)

\FloatBarrier
\paragraph*{}
La structure du lot de données est la suivante :

```{r out.width = "90%", echo = FALSE}
kable(structure_dataset, caption = "Dataset structure")
```

\paragraph*{}
Le lot de données d'origine a été découpé deux fois avec un rapport 92/8, comme décrit dans la partie. (cf. § et p(ref!!!)) 
\paragraph*{}
Toutes les distributions des variables du lot d'entraînement ont ensuite été tracées par histogrammes pour les variables numériques, et diagrammes en barres pour les variables alphabétiques et catégorielles :

```{r, eval = FALSE}
for (n in 1:ncol(BI_lot_apprentissage)){
  graph <- BI_lot_apprentissage %>%
    ggplot(aes_string(x = colnames(BI_lot_apprentissage)[n]))
  if(structure_dataset$Type[n] %in% c("integer", "numeric"))
  {graph <- graph + geom_histogram()}
  else
  {graph <- graph + geom_bar()}
  nom_graph <- paste0("distrib_", colnames(BI_lot_apprentissage)[n])
  assign(nom_graph, graph)
}
```

L'utilisation d'*aes_string* à la place de *aes* permet d'utiliser une chaîne de caractères en argument.
\paragraph*{}
Les diagrammes en barres n'ont rien illustré de particulièrement remarquable et n'ont pas été inclus dans le rapport. Toutefois, les distributions dimensionnelles sont plus intéressantes : à première vue, elles semblent suivre une courbe en cloche (fig. REF), avec une longue queue à droite. Une transformation logarithmique (fig. REF) montre plus nettement la forme de cette queue.

```{r, echo = FALSE, fig.height = 2.5, fig.cap = "Distribution des diamètres de chapeau, longueur de stipe, diamètre de stipe"}
plot(ggarrange(
   ncol = 3,
   study_distrib_cap.diameter + ggtitle("") + ylab("") + scale_y_continuous(labels = NULL),
   study_distrib_stem.height + ggtitle("") + ylab("") + scale_y_continuous(labels = NULL),
   study_distrib_stem.width + ggtitle("") + ylab("") + scale_y_continuous(labels = NULL)
   )
)
```

```{r, echo = FALSE, fig.height = 2.5, fig.cap = "Distribution des diamètres de chapeau, longueur de stipe, diamètre de stipe (échelle log en Y)"}
plot(ggarrange(
   ncol = 3,
   study_distrib_cap.diameter + ggtitle("") + ylab("") + scale_y_log10(labels = NULL),
   study_distrib_stem.height + ggtitle("") + ylab("") + scale_y_log10(labels = NULL),
   study_distrib_stem.width + ggtitle("") + ylab("") + scale_y_log10(labels = NULL)
   )
)
```

La distribution du diamètre du chapeau $D_{C}$ a l'apparence d'une courbe en cloche, avec une longue queue à droite, mais est en réalité bimodale, avec un mode principal à 5cm, et un mode secondaire beaucoup plus petit pour $D_{C} \approx 50~cm$. Cette taille exceptionnelle est attribuable à des variétés telles que *Polyporus squamosus*.[@courtecuisse_champignons_2013]
\paragraph*{}
La distribution de la longueur de stipe $L_{S}$ a également une forme de courbe en clochavec une longue queue à droite, un mode principal à 5 cm et un mode secondaire à 0 cm. Cette valeur peut également sembler surprenante, mais certains champignons n'ont pas de stipe, ce qui explique cette valeur.
\paragraph*{}
La distribution du diamètre de stipe $D_{S}$ a aussi l'apparence d'une courbe en cloche avec une longueur queue à droite, et un pic à $D_{S} \approx 10-15$mm. Dans toutes ces distributions, la longue queue à droite peut probablement s'expliquer par l'utilisation, dans le *Secondary Mushroom Dataset*, d'une distribution normale pour chaque variété, associée à l'impossibilité d'avoir des valeur dimensionnelles négatives.

\newpage
## Modèles de la librairie *caret* : optimisation et sélection
\paragraph*{}
La librairie *caret* fournit une plateforme très pratique et efficiente pour la modélisation de données et l'inférence par apprentissage machine. Cette section expliquera la stratégie utilisée pour l'évaluation de certains de ces modèles. Les modèles sélectionnés sont de types variés :

* Analyse discriminante linéaire (LDA) : *Linear Discriminant Analysis* (lda2), *Penalized Discriminant Analysis* (pda)
* Modèle additif généralisé (GAM) : *Generalized Additive Model using LOESS* (gamLoess)
* Modèle arborescent : *Classification And Regression Tree* (CART) (rpart, rpartCost), *Single C5.0 Tree* (ctree)
* Forêt aléatoire : *Random Ferns* (rferns), *Random Forest* (ranger, Rborist)

\paragraph*{}
La première étape est de construire une fonction d'évaluation et de régression, afin de rationnaliser notre travail. En effet, l'évaluation et la régression seront effectuées très fréquemment au cours de cette étude, il est donc souhaitable d'assigner une fonction dédiée à ces tâches. La librairie caret permet de la définir très simplement par :  

[A MODIFIER EN COHERENCE AVEC LE FICHIER R]

```{r, eval = FALSE}
set.seed(1)
tr_ctrl <- trainControl(classProbs = TRUE, 
                        summaryFunction = twoClassSummary, 
                        method = "cv", number = 10)
train(class ~ .,
      method = [METHODE],
      data = BI_lot_appr_opti,
      trControl = tr_ctrl,
      metric = 'Spec',
      tuneGrid = data.frame([PARAMETRES]))
```
La fonction *set.seed* assure la reproductibilité.

La fonction *trainControl* permet de contrôler divers paramètres d'entraînement et de validation à fins d'optimisation ; dans cet exemple, d'utiliser un critère tel que le ROC, la sensibilité ou la spécificité, et d'utiliser une validation croisée (*cross validation*) à 10 blocs (*10-folds*).

La fonction *train* lance le processus d'apprentissage et d'évaluation, tout en permettant l'utilisation de différents paramaètres tels que la méthode de sélection des jeux d'entraînement et de validation, la métrique utilisée pour l'évaluation (sensibilité, spécificité, ROC...) ainsi que la grille des paramètres utilisés par le modèle.
\paragraph*{}
Ce bloc de code a été inclus dans une fonction pour facilité l'accessiblité du code et la reproductibilité. Cette fonction renvoie une liste qui peut ensuite être utilisée pour générer un graphique, ou pour extraire différentes données d'intérêt, contenues dans .\$results (pour une classification binaire : AUC de ROC, sensibilité, spécificité), .\$bestTune (paramètres donnant la meilleure performance sur la métrique utilisée) et .\$finalModel  (informations diverses pouvant parfois être utilisées dans des graphiques, tels que des arbres décisionnels).
\FloatBarrier

### Modèles d'analyse discriminante linéaire
\paragraph*{}
Les deux modèles d'analyse discriminante linéaire (LDA) choisis pour cette étude sont lda2 (*Linear Discriminant Analysis*) et pda (*Penalized Discriminant Analysis*). Le modèle lda2 dispose d'un hyperparamètre (*dimen*, nombre de fonctions discriminantes). Le modèle pda a également un unique hyperparamètre (*lambda*, pénalité de réduction des coefficients).  

```{r, echo = FALSE, fig.height = 3, fig.cap = "Spécificité des modèles lda2 (à gauche) et pda (à droite)"}
plot(ggarrange(
   ncol = 2,
   BI_fit_lda2_dim_graphe + theme_bw(),
   BI_fit_pda_lambda_graphe +  ylab("") + theme_bw()
   )
)
```

\paragraph*{}
Le paramètre *dimen* du modèle lda2 ne semble pas avoir d'effet significatif sur la spécificité ($Spec =$ `r round(mean(BI_fit_lda2_dim_results[,"Spec"]), 3)`). 
\paragraph*{}
Le paramètre *lambda* du modèle pda impacte sa spécificité de façon marginale, avec des lambdas faibles donnant une légère amélioration des résultats ($Spec_{max} =$ `r round(max(BI_fit_pda_lambda_results["Spec"]))`).
\paragraph*{}
Toutefois, la spécificité de ces deux modèles est nettement insuffisante pour notre étude ($Spec \approx$ `r round(mean(c(BI_fit_lda2_dim_results$Spec, BI_fit_pda_lambda_results$Spec)),2)`), et leurs sensiblités n'ont rien de remarquable non plus ($Sens \approx$ `r round(mean(c(BI_fit_lda2_dim_results$Sens, BI_fit_pda_lambda_results$Sens)), 3)`).
\paragraph*{}
Ces performances médiocres s'expliquent par le fonctionnement même des modèles LDA qui, s'ils peuvent analyser des données qualitatives à fins de classifications, ne peuvent le faire que si une quantification sous-jacente est possible, par exemple :

* Données binaires ou booléennes
* Données catégorielles basées sur des données numériques

\FloatBarrier
### Modèle additif généralisé  
\paragraph*{}
Le seul modèle additif généralisé choisi pour cette étude est gamLoess (*Generalized Additive Model using Locally Weighted Linear Regression*). La documentation de la librairie indique que le modèle gamLoess dispose de deux hyperparamètres : *span* (fraction de points utilisés dans l'environnement local) and *degree* (degré de linéarisation).

```{r, echo = FALSE, fig.height = 3, fig.cap = "Spécificité de gamLoess en fonction du span (gauche) and du degré (droite)"}
plot(ggarrange(
   ncol = 2,
   BI_fit_gamLoess_span_graphe + theme_bw(),
   BI_fit_gamLoess_degree_graphe +  ylab("") + theme_bw()
   )
)
```

\paragraph*{}
L'hyperparamètre *degree* du modèle gamLoess ne semble pas avoir d'effet significatif sur la spécificité, avec $\Delta Spec =$ `r round(max(BI_fit_gamLoess_degree_results[,"Spec"]) - min(BI_fit_gamLoess_degree_results[,"Spec"]), 3)`. 
\paragraph*{}
L'hyerparamètre *span* affecte marginalement la spécificité de gamLoess, avec une valeur optimale de *span* = `r BI_fit_gamLoess_span_results[which.max(BI_fit_gamLoess_span_results[,"Spec"]), "span"]`, résultant en $Spec_{max} =$ `r round(max(BI_fit_gamLoess_span_results["Spec"]), 3)`.
\paragraph*{}
La spécificité de ce modèle n'atteint pas le critère posé pour notre étude. Le modèle additif généralisé s'est avéré inférieur aux modèles d'analyse discriminante linéaire, aussi bien en spécificité (`r round(max(BI_fit_gamLoess_span_results["Spec"]), 3)` vs `r round(mean(c(BI_fit_lda2_dim_results$Spec, BI_fit_pda_lambda_results$Spec)), 3)`) qu'en sensibilité (`r round(max(BI_fit_gamLoess_span_results["Sens"]), 3)` vs `r round(mean(c(BI_fit_lda2_dim_results$Sens, BI_fit_pda_lambda_results$Sens)), 3)`).

\FloatBarrier
### Modèles d'arbres de décision
\paragraph*{}
Les modèles basés sur des arbres de décision ont un intérêt tout particulier pour cette étude, pour ceux raisons majeures :

* La logique en arbre de décision est habituellement usitée pour la classification manuelle des champignons,
* Les arbres de décision obtenus peuvent être tracés, et facilement interprétés par l'humain.

\paragraph*{}
Les premiers modèles présentés dans le cadre de notre étude sont deux modèles CART (*Classification And Regression Tree*). Le modèle CART basique (rpart) n'a qu'un hyperparamètre  : *cp* (complexité).

```{r, echo = FALSE}
kable(BI_fit_rpart_cp_results[,1:4], digits = 5, caption = "Performance du modèle CART (rpart)")
```

Le modèle CART le plus simple n'atteint jamais la spécificité requise $Spec = 1$. Toutefois, ce modèle s'en approche, et donne de très bons résultats globaux, avec ($Sens_{max} =$ `r round(max(BI_fit_rpart_cp_results["Sens"]),3)` et $Spec_{max} =$ `r round(max(BI_fit_rpart_cp_results["Spec"]),3)`).

Le second modèle CART utilisé dans cette étude (rpartCost) associe des hyperparamètres de complexité (*cp*) et de coût (*Cost*).

```{r, echo = FALSE, fig.height = 3, fig.cap = "Spécificité (à gauche) et sensibilité (à droite) de rpartCost en fonction de la complexité et du coût (interpolation quadratique, points expérimentaux encadrés en noir)"}
plot(ggarrange(
   ncol = 2, widths = c(8,7),
   BI_fit_rpartcost_spec_graphe + theme(legend.position="bottom"),
   BI_fit_rpartcost_sens_graphe + theme(legend.position="bottom") + ylab(NULL)
   )
)
```

Les performances maximales sont atteintes pour *cp =* `r BI_best_rpartcostgrid['cp']` et *Cost = * `r BI_best_rpartcostgrid['Cost']`.

```{r, echo = FALSE}
kable(BI_fit_rpartcost_best_results[,c(1:2,4:5)], digits = 5, caption = "Performance du modèle CART (rpartCost)")
```

Les performances du modèle rpartCost, quoi qu'excellentes, ne permettent pas d'atteindre la spécificité requise.
\paragraph*{}
Le dernier modèle d'arbre décisionnel est C5.0 tree (c50tree). Ce modèle ne dispose d'aucun hyperparamètre.

```{r, echo = FALSE}
kable(BI_fit_c50tree_results[,2:4], digits = 5, caption = "Performance du modèle C5.0 tree")
```

De manière assez surprenante, bien que ne disposant d'aucun hyperparamètre, ce modèle a donné d'excellents résultats sans optimisation nécessaire, avec de très hautes sensibilité et spécificité. Toutefois, le modèle C5.0 tree n'a pas rempli l'objectif posé par le critère $Spec = 1$.

### Forêts aléatoires
\paragraph*{}
Le premier modèle de forêt aléatoire évalué dans cette étude est le modèle de fougères aléatoires rFerns (*Random Ferns*). Ce modèle ne possède qu'un seul hyperparamètre, la profondeur (*depth*).

\paragraph*{}
```{r, echo = FALSE, fig.height = 3, fig.cap = "Spécificité du modèle de fougères aléatoires"}
BI_fit_rFerns_depth_graphe + theme_bw()
```

\paragraph*{}
Quoique très efficient sur le plan calculatoire, le modèle de fougères aléatoire a fourni des résultats peu satisfaisants, avec une spécificité maximale de $Spec_{max} =$ `r round(max(BI_fit_rFerns_depth_results["Spec"]), 3)`. La sensibilité maximale n'est pas très élevée non plus ($Sens_{max} =$ `r round(max(BI_fit_rFerns_depth_results["Sens"]), 3)`).

\paragraph*{}
Le second modèle de forêt aléatoire que nous évaluons dans cette étude est le modèle ranger. La documentation de la librairie caret mentionne trois hyperparamètres : la taille minimale de n\oe{}ud (*min.node.size*), le nombre de caractéristiques à séparer à chaque n\oe{}ud (*mtry*) et la règle contrôlant cette séparation (*splitrule*).

```{r, echo = FALSE, fig.height = 3, fig.cap = "Spécificité (à gauche) et sensibilité (à droite) du modèle Ranger, en fonction des 2 hyperparamètres (algorithme de scission : gini)"}
plot(ggarrange(
   ncol = 2, widths = c(8,7),
   BI_fit_ranger_Gini_spec_graphe,
   BI_fit_ranger_Gini_sens_graphe + ylab(NULL)
   )
)
```

```{r, echo = FALSE, fig.height = 3, fig.cap = "Spécificité (à gauche) et sensibilité (à droite) du modèle Ranger, en fonction des 2 hyperparamètres (algorithme de scission : extratrees)"}
plot(ggarrange(
   ncol = 2, widths = c(8,7),
   BI_fit_ranger_ET_spec_graphe,
   BI_fit_ranger_ET_sens_graphe + ylab(NULL)
   )
)
```

Les étapes préliminaires de l'optimisation du modèle se sont avérées prometteuses : même avec un très faible nombre d'arbres (*n* = 6), la spécificité requise était déjà atteinte à plusieurs reprises lors de l'optimisation uniparamètre. L'optimisation de la totalité des hyperparamètres (*min.node.size* = `r BI_best_rangergrid$min.node.size`, *mtry* = `r BI_best_rangergrid$mtry` et *splitrule* = `r BI_best_rangergrid$splitrule`) a donné d'excellents résultats.

```{r, echo = FALSE}
kable(BI_fit_ranger_best_results[1:6], digits = 5, caption = "Performances du modèle Ranger (hyperparamètres optimaux)")
```

Ce modèle s'est comporté de façon excellente, donnant une spécificité et une sensibilité remarquables dans cette phrase d'évaluation.
\paragraph*{}
Le dernier modèle de forêt aléatoire est Rborist. Deux hyperparamètres régissent ce modèle : le nombre de prédicteurs testés pour une scission (*predFixed*) et le nombre minimal de lignes-références distinctes avant de scinder un n\oe{}ud (*minNode*).

```{r, echo = FALSE, fig.height = 3, fig.cap = "Spécificité (à gauche) et sensibilité (à droite) du modèle Rborist en fonction de ses deux hyperparamètres (interpolation quadratique, points expérimentaux encadrés en noir)"}
plot(ggarrange(
   ncol = 2, widths = c(8,7),
   BI_fit_Rborist_spec_graphe,
   BI_fit_Rborist_sens_graphe + ylab(NULL)
   )
)
```

\paragraph*{}
Ici encore, les étapes d'optimisation ont montré des résultats prometteurs : sur ce modèle également, la spécificité requise a été atteintes sur plusieurs occurences, en utilisant seulement une optimisation monoparamétrique. 
\paragraph*{}
Avec des paramètres optimaux (*predFixed* = `r BI_best_Rboristgrid$predFixed` et *minNode* = `r BI_best_Rboristgrid$minNode`), la performance est estimée à :
\FloatBarrier

```{r, echo = FALSE}
kable(BI_fit_Rborist_best_results[1:5], digits = 5, caption = "Performances du modèle Rborist (hyperparamètres optimaux)")
```
\FloatBarrier
\paragraph*{}
Le modèle Rborist a donné des résultats similaires à ceux du modèle Ranger, avec une sensibilité et une spécificité excellentes.
\paragraph*{}
Ces résultats soulignent un fait intéressant : tous les modèles de forêts aléatoires ne sont pas égaux. Notre étude montre une différence considérable en sensibilité et spécificité entre les forêts aléatoires de type rFerns, Ranger et Rborist. Lors des étapes préliminaires de cette étude, d'autres modèles de forêts aléatoires disponibles dans la librairie caret se sont également montrés extrêmement inefficients sur le plan calculatoire, alors que d'autres se sont avérés sensiblement plus rapides.
\paragraph*{}
La vitesse des algorithmes sera l'objet de la section suivante. La durée d'exécution de n'importe quelle portion de code R peut facilement être mesurée par :
```{r, eval = FALSE}
temps_debut <- Sys.time()
[Code à évaluer]
temps_fin <- Sys.time()
duree <- difftime(temps_fin, temps_debut)
```

## Résultats
### Protocole d'évaluation
\paragraph*{}
Les modèles ayant atteint le critère de spécificité ($Spec = 1$) lors de l'étape d'optimisation ont été choisis pour l'évaluation. Les deux modèles choisis sont deux forêts aléatoires :

* Forêt aléatoire de type Ranger,
* Forêt aléatoire de type Rborist.

\paragraph*{}
Tous les modèles ont été entraînés sur le jeu de données d'apprentissage, réglés avec les meilleurs hyperparamètres obtenus par mesure des performances face au jeu de données d'optimisation. Leurs performances face au jeu de données d'évaluation seront analysées avec les mêmes critères que précédemment :

* La spécificité *doit* être égale à 1.
* La sensibilité doit être la plus haute possible.

### Performances des modèles de forêts aléatoires  

\FloatBarrier
L'évaluation finale du modèle ranger donne la matrice de confusion suivante :

```{r out.width = "100%", echo = FALSE}
kable(BI_CM_ranger_final$table, caption = "Matrice de confusion du modèle Ranger")
```  

La précision finale est égale à `r round(BI_CM_ranger_final$overall["Accuracy"], 4)`, avec un intervalle de confiance à 95% de [`r round(BI_CM_ranger_final$overall["AccuracyLower"], 4)` ; `r round(BI_CM_ranger_final$overall["AccuracyUpper"], 4)`]. La forêt aléatoire de type Ranger a donné d'excellents résultats, en un temps très contenu (`r BI_temps_ranger` min), preuve de sa grande efficience calculatoire.
\paragraph*{}
La forêt aléatoire de type Rborist a donné des résultats similaires, avec une précision finale égale à `r BI_CM_Rborist_final$overall["Accuracy"]`, avec un intervalle de confiance à 95% de [`r round(BI_CM_Rborist_final$overall["AccuracyLower"], 4)` ; `r round(BI_CM_Rborist_final$overall["AccuracyUpper"], 4)`]. Le modèle Rborist, donnant des résultats sensiblement identiques à Ranger, s'est avéré extrêmement efficient sur le plan calculatoire (`r BI_temps_Rborist` min).

```{r out.width = "100%", echo = FALSE}
kable(BI_RF_resultat, digits = 5, caption = "Performances des modèles Ranger et Rborist (évaluation)")
```

\FloatBarrier

\newpage
# Apprentissage machine et classification multiclasse

*Brouillon, le lot de données utilisé ici est un lot synthétique créé par moi-même, mais à partir des données primaires du Secondary Mushroom Dataset de D.Wagner.*
\paragraph*{}
Etant données des performances qu'ont montré les différents modèles lors de la classification binaire, seuls les modèles basés sur les arbres décisionnels et les forêts aléatoires seront évalués dans cette section.
\FloatBarrier
## Classification par familles

### Modèles d'arbres de décision
\paragraph*{}

\paragraph*{}
Les premiers modèles présentés dans le cadre de notre étude sont deux modèles CART (*Classification And Regression Tree*). Le modèle CART basique (rpart) n'a qu'un hyperparamètre  : *cp* (complexité).

```{r, echo = FALSE}
kable(MUL_fit_rpart_cp_results[,1:4], digits = 5, caption = "Performance du modèle CART (rpart)")
```

Le modèle CART le plus simple n'atteint jamais la spécificité requise $Spec = 1$. Toutefois, ce modèle s'en approche, et donne de très bons résultats globaux, avec ($Sens_{max} =$ `r round(max(MUL_fit_rpart_cp_results["Sens"]),3)` et $Spec_{max} =$ `r round(max(MUL_fit_rpart_cp_results["Spec"]),3)`).

Le second modèle CART utilisé dans cette étude (rpartCost) associe des hyperparamètres de complexité (*cp*) et de coût (*Cost*).

```{r, echo = FALSE, fig.height = 3, fig.cap = "Spécificité (à gauche) et sensibilité (à droite) de rpartCost en fonction de la complexité et du coût (interpolation quadratique, points expérimentaux encadrés en noir)"}
plot(ggarrange(
   ncol = 2, widths = c(8,7),
   MUL_fit_rpartcost_spec_graphe,
   MUL_fit_rpartcost_sens_graphe + ylab(NULL)
   )
)
```

Les performances maximales sont atteintes pour *cp =* `r MUL_best_rpartcostgrid['cp']` et *Cost = * `r MUL_best_rpartcostgrid['Cost']`.

```{r, echo = FALSE}
kable(MUL_fit_rpartcost_best_results[,c(1:2,4:5)], digits = 5, caption = "Performance du modèle CART (rpartCost)")
```

Les performances du modèle rpartCost, quoi qu'excellentes, ne permettent pas d'atteindre la spécificité requise.
\paragraph*{}
<!-- Le dernier modèle d'arbre décisionnel est C5.0 tree (c50tree). Ce modèle ne dispose d'aucun hyperparamètre. -->

<!-- ```{r, echo = FALSE} -->
<!-- kable(MUL_fit_c50tree_results[,2:4], digits = 5, caption = "Performance du modèle C5.0 tree") -->
<!-- ``` -->

<!-- De manière assez surprenante, bien que ne disposant d'aucun hyperparamètre, ce modèle a donné d'excellents résultats sans optimisation nécessaire, avec de très hautes sensibilité et spécificité. Toutefois, le modèle C5.0 tree n'a pas rempli l'objectif posé par le critère $Spec = 1$. -->

### Forêts aléatoires

\paragraph*{}
Le premier modèle de forêt aléatoire évalué dans cette partie est le modèle ranger, qui possède trois hyperparamètres : la taille minimale de n\oe{}ud (*min.node.size*), le nombre de caractéristiques à séparer à chaque n\oe{}ud (*mtry*) et la règle contrôlant cette séparation (*splitrule*).

```{r, echo = FALSE, fig.height = 3, fig.cap = "Spécificité (à gauche) et sensibilité (à droite) du modèle Ranger, en fonction des 2 hyperparamètres (algorithme de scission : gini)"}
plot(ggarrange(
   ncol = 2, widths = c(8,7),
   MUL_fit_ranger_Gini_spec_graphe,
   MUL_fit_ranger_Gini_sens_graphe + ylab(NULL)
   )
)
```

```{r, echo = FALSE, fig.height = 3, fig.cap = "Spécificité (à gauche) et sensibilité (à droite) du modèle Ranger, en fonction des 2 hyperparamètres (algorithme de scission : extratrees)"}
plot(ggarrange(
   ncol = 2, widths = c(8,7),
   MUL_fit_ranger_ET_spec_graphe,
   MUL_fit_ranger_ET_sens_graphe + ylab(NULL)
   )
)
```

Les étapes préliminaires de l'optimisation du modèle se sont avérées prometteuses : même avec un très faible nombre d'arbres (*n* = 6), la spécificité requise était déjà atteinte à plusieurs reprises lors de l'optimisation uniparamètre. L'optimisation de la totalité des hyperparamètres (*min.node.size* = `r MUL_best_rangergrid$min.node.size`, *mtry* = `r MUL_best_rangergrid$mtry` et *splitrule* = `r MUL_best_rangergrid$splitrule`) a donné d'excellents résultats.

```{r, echo = FALSE}
kable(MUL_fit_ranger_best_results[1:6], digits = 5, caption = "Performances du modèle Ranger (hyperparamètres optimaux)")
```

Ce modèle s'est comporté de façon excellente, donnant une spécificité et une sensibilité remarquables dans cette phrase d'évaluation.
\paragraph*{}
Le dernier modèle de forêt aléatoire est Rborist. Deux hyperparamètres régissent ce modèle : le nombre de prédicteurs testés pour une scission (*predFixed*) et le nombre minimal de lignes-références distinctes avant de scinder un n\oe{}ud (*minNode*).

```{r, echo = FALSE, fig.height = 3, fig.cap = "Spécificité (à gauche) et sensibilité (à droite) du modèle Rborist en fonction de ses deux hyperparamètres (interpolation quadratique, points expérimentaux encadrés en noir)"}
plot(ggarrange(
   ncol = 2, widths = c(8,7),
   MUL_fit_Rborist_spec_graphe,
   MUL_fit_Rborist_sens_graphe + ylab(NULL)
   )
)
```

\paragraph*{}
Ici encore, les étapes d'optimisation ont montré des résultats prometteurs : sur ce modèle également, la spécificité requise a été atteintes sur plusieurs occurences, en utilisant seulement une optimisation monoparamétrique. 
\paragraph*{}
Avec des paramètres optimaux (*predFixed* = `r MUL_best_Rboristgrid$predFixed` et *minNode* = `r MUL_best_Rboristgrid$minNode`), la performance est estimée à :
\FloatBarrier

```{r, echo = FALSE}
kable(MUL_fit_Rborist_best_results[1:5], digits = 5, caption = "Performances du modèle Rborist (hyperparamètres optimaux)")
```
\FloatBarrier
\paragraph*{}
Le modèle Rborist a donné des résultats similaires à ceux du modèle Ranger, avec une sensibilité et une spécificité excellentes.
\paragraph*{}
Ces résultats soulignent un fait intéressant : tous les modèles de forêts aléatoires ne sont pas égaux. Notre étude montre une différence considérable en sensibilité et spécificité entre les forêts aléatoires de type rFerns, Ranger et Rborist. Lors des étapes préliminaires de cette étude, d'autres modèles de forêts aléatoires disponibles dans la librairie caret se sont également montrés extrêmement inefficients sur le plan calculatoire, alors que d'autres se sont avérés sensiblement plus rapides.
\paragraph*{}
La vitesse des algorithmes sera l'objet de la section suivante. La durée d'exécution de n'importe quelle portion de code R peut facilement être mesurée par :
```{r, eval = FALSE}
temps_debut <- Sys.time()
[Code à évaluer]
temps_fin <- Sys.time()
duree <- difftime(temps_fin, temps_debut)
```

### Résultats
Les critères et le protocole de l'évaluation sont les mêmes que ceux évoqués précédemment.

\FloatBarrier
L'évaluation finale du modèle ranger donne la matrice de confusion suivante :

```{r out.width = "100%", echo = FALSE}
kable(MUL_CM_ranger_final$table, caption = "Matrice de confusion du modèle Ranger")
```  

La précision finale est égale à `r round(MUL_CM_ranger_final$overall["Accuracy"], 4)`, avec un intervalle de confiance à 95% de [`r round(MUL_CM_ranger_final$overall["AccuracyLower"], 4)` ; `r round(MUL_CM_ranger_final$overall["AccuracyUpper"], 4)`]. La forêt aléatoire de type Ranger a donné d'excellents résultats, en un temps très contenu (`r MUL_temps_ranger` min), preuve de sa grande efficience calculatoire.
\paragraph*{}
La forêt aléatoire de type Rborist a donné des résultats similaires, avec une précision finale égale à `r MUL_CM_Rborist_final$overall["Accuracy"]`, avec un intervalle de confiance à 95% de [`r round(MUL_CM_Rborist_final$overall["AccuracyLower"], 4)` ; `r round(MUL_CM_Rborist_final$overall["AccuracyUpper"], 4)`]. Le modèle Rborist, donnant des résultats sensiblement identiques à Ranger, s'est avéré extrêmement efficient sur le plan calculatoire (`r MUL_temps_Rborist` min).

```{r out.width = "100%", echo = FALSE}
kable(MUL_RF_resultat, digits = 5, caption = "Performances des modèles Ranger et Rborist (évaluation)")
```

\FloatBarrier

## Classification par espèce

\newpage
# Robustesse de la classification
texte

\FloatBarrier
\newpage

# Références bibliographiques
<div id="refs"></div>

# (APPENDIX) Appendix {-} 

# Annexes A
Les trucs de l'annexe A

# Annexes B
Les trucs de l'annexe B
